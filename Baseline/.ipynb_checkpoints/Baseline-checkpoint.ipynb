{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89452ce3-52cd-4270-b80a-833d3402ea15",
   "metadata": {},
   "source": [
    "# Runing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a7ad6-670e-4dd1-828d-4ee498a9fcba",
   "metadata": {},
   "source": [
    "# DQN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5709b2ed-10b1-4e5c-9e5d-9d223cf9462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import USER_STREAM_CONTEXT, ITEM_DF, ITEM_STREAM_DF, REAL_BOUGHT_DF, LAST_BOUGHT_STREAM, LB_ITEMS, USER_LIST, LB_CE, STREAM_LIST\n",
    "from utils import gen_exist_series, get_full_state, get_reward, calculate_interest_change, get_input, model_predict_top10, INPUT_DF_COL\n",
    "from replay import ReplayBuffer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6f911b-1f0b-4c9a-ab83-338449cf7bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:      /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:\\\n",
    "      {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2f337-3ba6-4bca-8de1-514ccefeb20e",
   "metadata": {},
   "source": [
    "## Train DQN model\n",
    "* Input: `user_df` 253, `item_df` 231(BERT: 768), interact (?), `reward` 1\n",
    "* Output: recommend a list of items\n",
    "* Methods Needed\n",
    "    * Environment Function\n",
    "    * Choose Action\n",
    "    * Store Transition\n",
    "    * Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adba99bf-3034-444c-be67-a43efd5a273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Process\n",
    "\n",
    "def train(model, exp_replay, epochs, batch_size, num_episode=1000, verbose=1, reward_set='strict'):\n",
    "  # total_actions = ITEM_DF.shape[0]\n",
    "  total_episodes = len(USER_LIST)\n",
    "  # Reset win counter\n",
    "  win_cnt = 0\n",
    "  win_hist = []\n",
    "\n",
    "  for e in range(epochs):\n",
    "    loss = 0.\n",
    "    # TODO/MAIN: Apply user preference changes as epsilon\n",
    "    # epsilon for exploration - dependent inversely on the training epoch\n",
    "    epsilon = 4 / ((e + 1) ** (1 / 2))\n",
    "\n",
    "    # handling episodes by assigning users from USER_LIST\n",
    "    # Each user represent an Episode\n",
    "    episodes = random.sample(range(total_episodes), num_episode)\n",
    "\n",
    "    print(f'Epoch {e} started.   Time: {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
    "    # ------------------- Episode (User) -------------------------------\n",
    "    for user_episode in episodes:\n",
    "      # game_over = False\n",
    "      # get episode data by user phone number\n",
    "      user_phone = USER_LIST[user_episode]\n",
    "      user_all_streams = USER_STREAM_CONTEXT.xs(user_phone, level=\"聯絡電話\")\n",
    "      stream_list = user_all_streams.index\n",
    "      final_stream = LAST_BOUGHT_STREAM.loc[user_phone, '場次']\n",
    "      \n",
    "      \n",
    "      # ----------------- Runs (User x All_Stream) ---------------------\n",
    "      for i, stream in enumerate(stream_list):          \n",
    "        game_over = stream == final_stream\n",
    "                \n",
    "        # Get full state: current_state = user_stream + item_stream\n",
    "        # 用上一場紀錄預測下一場直播會購買的商品\n",
    "        current_state = get_full_state(user_all_streams, stream_list, i)\n",
    "        stream_items = current_state['cand_item']\n",
    "        \n",
    "        # --------------- Explore/Exploit Section ----------------------\n",
    "        if np.random.rand() <= epsilon:\n",
    "          # Explore by randomly select 10/n items from candidate_items\n",
    "          # Get all items from the stream\n",
    "          sample_actions = random.sample(stream_items, 10) if len(stream_items) > 10 else stream_items\n",
    "          action_ids = gen_exist_series(sample_actions, stream_items)\n",
    "        else:\n",
    "          # Exploit by choosing action from the model's prediction\n",
    "          pred_actions = model_predict_top10(model, current_state)\n",
    "          action_ids = gen_exist_series(pred_actions, stream_items)\n",
    "\n",
    "        # --------------- Get next state & info to store ---------------\n",
    "        reward = get_reward(user_phone, stream, action_ids)\n",
    "        next_state = get_full_state(user_all_streams, stream_list, i+1) if not game_over else []\n",
    "\n",
    "        if sum(reward) > 0:\n",
    "          win_cnt += 1\n",
    "\n",
    "        # --------------- Calculating Interest Changes -----------------\n",
    "        interest_score = calculate_interest_change(user_all_streams, stream_list, i)\n",
    "\n",
    "        # --------------- Store Experience -----------------------------\n",
    "        exp_replay.remember(interest_score,\n",
    "                            [current_state, action_ids, reward, next_state],\n",
    "                            game_over)\n",
    "        \n",
    "\n",
    "        # --------------- Load batch of experiences --------------------\n",
    "        inputs, targets = exp_replay.get_batch(model, batch_size=batch_size)\n",
    "        # train model on experiences\n",
    "        batch_loss = model.train_on_batch(inputs, targets)\n",
    "        loss += batch_loss\n",
    "            \n",
    "    if verbose > 0:\n",
    "      print(f'Epoch: {e}/{epochs} | Loss {loss} | Win count {win_cnt} | Time {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
    "    \n",
    "    # Track win history to later check if our model is improving at the game over time.\n",
    "    win_hist.append(win_cnt)\n",
    "  return win_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d28e144-e732-4036-9765-8386ca3fbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# parameters\n",
    "MAX_MEMORY = 1000  # Maximum number of experiences we are storing\n",
    "BATCH_SIZE = 5  # Number of experiences we use for training per batch\n",
    "EPOCH = 50\n",
    "TOTAL_ACTIONS = 1 # probability of ordering\n",
    "NUM_EPISODE = 100\n",
    "HIDDEN_SIZE = 512\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd4b39-e518-4b08-8356-bf61ce94210b",
   "metadata": {},
   "source": [
    "### Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0f1af-977d-40b8-aad5-8e5771c55fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.   Time: 15:59:35\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f33b472d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f33b472d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "exp_replay = ReplayBuffer(max_memory=MAX_MEMORY)# Our model's architecture parameters\n",
    "input_size = 473 # The input shape for model - this comes from the output shape of the CNN Mobilenet\n",
    "\n",
    "# Setting up the model with keras.\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(HIDDEN_SIZE, input_shape=(input_size,), activation='relu'))\n",
    "model.add(Dense(HIDDEN_SIZE, activation='tanh'))\n",
    "model.add(Dense(TOTAL_ACTIONS))\n",
    "model.compile(Adam(learning_rate=.000001), \"mse\")\n",
    "\n",
    "\n",
    "# Training the model\n",
    "hist = train(model, \n",
    "             exp_replay, \n",
    "             epochs=EPOCH, \n",
    "             batch_size=BATCH_SIZE, \n",
    "             num_episode=NUM_EPISODE, \n",
    "             verbose=1, \n",
    "             reward_set='strict')\n",
    "plt.plot(range(EPOCH), hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa601d70-1d40-4fbe-a289-5478a8353291",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(50), hist)\n",
    "plt.title('Cumulated hit at each epoch(buy > 25)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cumulated hit count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280dd8b1-b7d0-4342-88a6-e92bed5e6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ = hist[1:]\n",
    "result = [105]\n",
    "hist_ = [a - b for a, b in zip(hist_, hist)]\n",
    "for a in hist_: result.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee17527-267b-4a68-b6ba-5034f0afa785",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(50), result)\n",
    "plt.title('Hit at each epoch(buy > 25)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Hit count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51470049-d8a5-4f6e-8876-dec66edd2e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7242218-4656-498f-933d-23cbf2456655",
   "metadata": {},
   "outputs": [],
   "source": [
    "[105, 110, 109, 106, 134, 109, 117, 126, 102, 147, 98, 123, 131, 108, 106, 109, 87, 92, 105, 88, 128, 108, 64, 116, 79, 85, 95, 74, 89, 89, 69, 81, 71, 88, 81, 91, 96, 70, 94, 63, 98, 49, 66, 71, 70, 52, 59, 93, 48, 54]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f809375-88a9-4195-b0eb-3220f526d3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "984abe6d-e19d-4a57-bd77-c97e952e10f1",
   "metadata": {},
   "source": [
    "## Experiment Result\n",
    "When `buy_threshold` = 9, the average `win_cnt` of the first 3 epoches is 77(80/??/232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd9583-625b-4d9b-a67e-caf8f4e3ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f186de8-df64-4ff1-a0df-2457a36a1037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa523669-c179-45c0-af95-2ae273770a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7419220-7f26-4476-8011-5dfe4b1cda80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c6b18-e88b-436e-a34a-1e8ebb527c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471c923-0953-4fb6-adcb-1aab4796136c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b60988-b8fb-4035-b19b-ee73fb6c2f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f64715-795b-4508-9ce6-77438898f63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b49b19-994d-4717-9eee-b2555f466a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c3b40-cff1-4d05-98d1-209c4a72f050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8c5f0-10ea-446b-9b78-997eb4062b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5d26d15f81c32561881a39c85bdcf5a2542c694b6b4a6d5e9280707d5ee0206"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
