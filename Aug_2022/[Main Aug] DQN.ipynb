{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89452ce3-52cd-4270-b80a-833d3402ea15",
   "metadata": {},
   "source": [
    "# Runing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a7ad6-670e-4dd1-828d-4ee498a9fcba",
   "metadata": {},
   "source": [
    "# DQN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5709b2ed-10b1-4e5c-9e5d-9d223cf9462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import USER_STREAM_CONTEXT, ITEM_DF, ITEM_STREAM_DF, REAL_BOUGHT_DF, LAST_BOUGHT_STREAM, LB_ITEMS, USER_LIST, LB_CE, STREAM_LIST\n",
    "from utils import gen_exist_series, get_full_state, get_reward, calculate_interest_change, get_input, model_predict_top10, INPUT_DF_COL\n",
    "from replay import ReplayBuffer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2f337-3ba6-4bca-8de1-514ccefeb20e",
   "metadata": {},
   "source": [
    "## Train DQN model\n",
    "* Input: `user_df` 253, `item_df` 231(BERT: 768), interact (?), `reward` 1\n",
    "* Output: recommend a list of items\n",
    "* Methods Needed\n",
    "    * Environment Function\n",
    "    * Choose Action\n",
    "    * Store Transition\n",
    "    * Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adba99bf-3034-444c-be67-a43efd5a273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Process\n",
    "\n",
    "def train(model, exp_replay, epochs, batch_size, num_episode=1000, verbose=1, reward_set='strict'):\n",
    "  # total_actions = ITEM_DF.shape[0]\n",
    "  total_episodes = len(USER_LIST)\n",
    "  # Reset win counter\n",
    "  win_cnt = 0\n",
    "  win_hist = []\n",
    "\n",
    "  for e in range(epochs):\n",
    "    loss = 0.\n",
    "    # TODO/MAIN: Apply user preference changes as epsilon\n",
    "    # epsilon for exploration - dependent inversely on the training epoch\n",
    "    epsilon = 4 / ((e + 1) ** (1 / 2))\n",
    "\n",
    "    # handling episodes by assigning users from USER_LIST\n",
    "    # Each user represent an Episode\n",
    "    episodes = random.sample(range(total_episodes), num_episode)\n",
    "\n",
    "    print(f'Epoch {e} started.')\n",
    "    # ------------------- Episode (User) -------------------------------\n",
    "    for user_episode in episodes:\n",
    "      # game_over = False\n",
    "      # get episode data by user phone number\n",
    "      user_phone = USER_LIST[user_episode]\n",
    "      user_all_streams = USER_STREAM_CONTEXT.xs(user_phone, level=\"聯絡電話\")\n",
    "      stream_list = user_all_streams.index\n",
    "      final_stream = LAST_BOUGHT_STREAM.loc[user_phone, '場次']\n",
    "      \n",
    "      \n",
    "      # ----------------- Runs (User x All_Stream) ---------------------\n",
    "      for i, stream in enumerate(stream_list):          \n",
    "        game_over = stream == final_stream\n",
    "                \n",
    "        # Get full state: current_state = user_stream + item_stream\n",
    "        # 用上一場紀錄預測下一場直播會購買的商品\n",
    "        current_state = get_full_state(user_all_streams, stream_list, i)\n",
    "        stream_items = current_state['cand_item']\n",
    "        \n",
    "        # --------------- Explore/Exploit Section ----------------------\n",
    "        if np.random.rand() <= epsilon:\n",
    "          # Explore by randomly select 10/n items from candidate_items\n",
    "          # Get all items from the stream\n",
    "          sample_actions = random.sample(stream_items, 10) if len(stream_items) > 10 else stream_items\n",
    "          action_ids = gen_exist_series(sample_actions, stream_items)\n",
    "        else:\n",
    "          # Exploit by choosing action from the model's prediction\n",
    "          pred_actions = model_predict_top10(model, current_state)\n",
    "          action_ids = gen_exist_series(pred_actions, stream_items)\n",
    "\n",
    "        # --------------- Get next state & info to store ---------------\n",
    "        reward = get_reward(user_phone, stream, action_ids)\n",
    "        next_state = get_full_state(user_all_streams, stream_list, i+1) if not game_over else []\n",
    "\n",
    "        if sum(reward) > 0:\n",
    "          win_cnt += 1\n",
    "\n",
    "        # --------------- Calculating Interest Changes -----------------\n",
    "        interest_score = calculate_interest_change(user_all_streams, stream_list, i)\n",
    "\n",
    "        # --------------- Store Experience -----------------------------\n",
    "        exp_replay.remember(interest_score,\n",
    "                            [current_state, action_ids, reward, next_state],\n",
    "                            game_over)\n",
    "        \n",
    "\n",
    "        # --------------- Load batch of experiences --------------------\n",
    "        inputs, targets = exp_replay.get_batch(model, batch_size=batch_size)\n",
    "        # train model on experiences\n",
    "        batch_loss = model.train_on_batch(inputs, targets)\n",
    "        loss += batch_loss\n",
    "            \n",
    "    if verbose > 0:\n",
    "      print(\"Epoch: {:03d}/{:03d} | Loss {:.4f} | Win count {}\".format(e, epochs, loss, win_cnt))\n",
    "    \n",
    "    # Track win history to later check if our model is improving at the game over time.\n",
    "    win_hist.append(win_cnt)\n",
    "  return win_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d28e144-e732-4036-9765-8386ca3fbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# parameters\n",
    "MAX_MEMORY = 1000  # Maximum number of experiences we are storing\n",
    "BATCH_SIZE = 10  # Number of experiences we use for training per batch\n",
    "EPOCH = 50\n",
    "TOTAL_ACTIONS = 1 # probability of ordering\n",
    "NUM_EPISODE = 100\n",
    "HIDDEN_SIZE = 512\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd4b39-e518-4b08-8356-bf61ce94210b",
   "metadata": {},
   "source": [
    "### Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0f1af-977d-40b8-aad5-8e5771c55fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.\n",
      "Epoch: 000/050 | Loss 69.3638 | Win count 86\n",
      "Epoch 1 started.\n",
      "Epoch: 001/050 | Loss 48.5766 | Win count 160\n",
      "Epoch 2 started.\n",
      "Epoch: 002/050 | Loss 46.8541 | Win count 232\n",
      "Epoch 3 started.\n"
     ]
    }
   ],
   "source": [
    "exp_replay = ReplayBuffer(max_memory=MAX_MEMORY)# Our model's architecture parameters\n",
    "input_size = 473 # The input shape for model - this comes from the output shape of the CNN Mobilenet\n",
    "\n",
    "# Setting up the model with keras.\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(HIDDEN_SIZE, input_shape=(input_size,), activation='relu'))\n",
    "model.add(Dense(HIDDEN_SIZE, activation='tanh'))\n",
    "model.add(Dense(TOTAL_ACTIONS))\n",
    "model.compile(Adam(learning_rate=.000001), \"mse\")\n",
    "\n",
    "\n",
    "# Training the model\n",
    "hist = train(model, \n",
    "             exp_replay, \n",
    "             epochs=EPOCH, \n",
    "             batch_size=BATCH_SIZE, \n",
    "             num_episode=NUM_EPISODE, \n",
    "             verbose=1, \n",
    "             reward_set='strict')\n",
    "plt.plot(range(EPOCH), hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa601d70-1d40-4fbe-a289-5478a8353291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280dd8b1-b7d0-4342-88a6-e92bed5e6025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb737c7a-7340-4cdd-9770-bdf426bec4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd9583-625b-4d9b-a67e-caf8f4e3ac37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f186de8-df64-4ff1-a0df-2457a36a1037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa523669-c179-45c0-af95-2ae273770a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7419220-7f26-4476-8011-5dfe4b1cda80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c6b18-e88b-436e-a34a-1e8ebb527c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471c923-0953-4fb6-adcb-1aab4796136c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b60988-b8fb-4035-b19b-ee73fb6c2f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f64715-795b-4508-9ce6-77438898f63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b49b19-994d-4717-9eee-b2555f466a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c3b40-cff1-4d05-98d1-209c4a72f050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8c5f0-10ea-446b-9b78-997eb4062b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5d26d15f81c32561881a39c85bdcf5a2542c694b6b4a6d5e9280707d5ee0206"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
