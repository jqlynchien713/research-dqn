{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Target Network + DDQN] Main Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import line_profiler\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "  np.random.seed(seed)  \n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "CONTEXT_REPS = pd.read_pickle('../../data/w_final_context.pkl')\n",
    "STREAM_ITEM_DICT = pd.read_pickle('../../data/stream_item_dict.pkl')\n",
    "BERT_BY_IDX_DF = pd.read_pickle('../../data/bert_by_idx_pca.pkl')\n",
    "BOUGHT_DICT = pd.read_pickle('../../data/bought_dict.pkl')\n",
    "USER_ALL_STREAM_INIT = CONTEXT_REPS.describe().loc['50%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1397141, 219), 7701, (162189, 160), 79207)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_REPS.shape, len(STREAM_ITEM_DICT), BERT_BY_IDX_DF.shape, len(BOUGHT_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "USER_LIST = CONTEXT_REPS.index.get_level_values('asid').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "LB_ITEMS = ['item_id'] + [f'i{x}' for x in range(160)]\n",
    "INPUT_DF_COL__USR = CONTEXT_REPS.columns.to_list()\n",
    "INPUT_DF_COL = INPUT_DF_COL__USR + LB_ITEMS\n",
    "\n",
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "Convert state format to model input format\n",
    "'''\n",
    "def get_input_tensor(input_state, current_stream, with_tensor=False):\n",
    "  # Get item feats\n",
    "  # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list].reset_index().rename(columns={'index': 'item_id'})\n",
    "\n",
    "  # Fill in other context\n",
    "  stream_item_feat = pd.DataFrame([input_state]*len(item_list)).reset_index(drop=True)\n",
    "  \n",
    "  # Merge with items\n",
    "  stream_item_feat = stream_item_feat.merge(item_feat, left_index=True, right_index=True).astype('float32')\n",
    "  \n",
    "  # Convert to tensor\n",
    "  if with_tensor: \n",
    "    stream_item_feat_tensor = df_to_tensor(stream_item_feat)\n",
    "    return stream_item_feat_tensor, stream_item_feat\n",
    "  else:\n",
    "    return stream_item_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "\n",
    "Generate series: whether elements in A existed in list B\n",
    "A, B: List\n",
    "return: pd.Series\n",
    "example:\n",
    "  A: [1, 2, 4, 5]\n",
    "  B: [1, 2, 3, 4, 5, 6, 7]\n",
    "  return: Series([1, 1, 0, 1, 1, 0, 0], index=[1, 2, 3, 4, 5, 6, 7])\n",
    "'''\n",
    "def gen_exist_series(A, B):\n",
    "  return [int(item in A) for item in B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_tensor(input_df):\n",
    "  return torch.tensor(input_df.values).to(DEVICE).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "  def __init__(self, max_memory=100000, discount=.9, model_output_shape=1):\n",
    "    \"\"\"\n",
    "    Setup\n",
    "    max_memory: the maximum number of experiences we want to store\n",
    "    memory: a list of experiences\n",
    "    discount: the discount factor for future experience\n",
    "    In the memory the information whether the game ended at the state is stored seperately in a nested array\n",
    "    [...\n",
    "    [experience, game_over]\n",
    "    [experience, game_over]\n",
    "    ...]\n",
    "    \"\"\"\n",
    "    self.max_memory = max_memory\n",
    "    self.memory = list()\n",
    "    self.discount = discount\n",
    "    self.model_output_shape = model_output_shape\n",
    "\n",
    "  def remember(self, states, game_over):\n",
    "    # Save a state to memory\n",
    "    self.memory.append([states, game_over])\n",
    "    # We don't want to store infinite memories, so if we have too many, we just delete the oldest one\n",
    "    if len(self.memory) > self.max_memory:\n",
    "      del self.memory[0]\n",
    "\n",
    "  def get_batch(self, eval_net, target_net, batch_size=10):\n",
    "    # How many experiences do we have?\n",
    "    len_memory = len(self.memory)\n",
    "\n",
    "    # Calculate the number of actions that can possibly be taken in the game.\n",
    "    # Actions: 0 = not recommend, 1 = recommend\n",
    "    num_actions = self.model_output_shape\n",
    "\n",
    "    # Dimensions of our observed states, ie, the input to our model.\n",
    "    # Memory:  [\n",
    "    #   [ [ [stream, next_stream], [...state], action, reward, next_state_idx], game_over],\n",
    "    #   [ [ [stream, next_stream], [...state], action, reward, nexr_state_idx], game_over],\n",
    "    #   ...\n",
    "    # ]\n",
    "    env_dim = len(INPUT_DF_COL)\n",
    "\n",
    "    inputs = pd.DataFrame()\n",
    "    targets = torch.tensor([], dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    \n",
    "    # We draw states to learn from randomly\n",
    "    for i, idx in enumerate(np.random.randint(0, len_memory, size=min(len_memory, batch_size))):  \n",
    "      # Here we load one transition <s, a, r, s'> from memory\n",
    "      streams, state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
    "      current_stream, next_stream = streams\n",
    "      game_over = self.memory[idx][1]\n",
    "\n",
    "      '''\n",
    "      修改倒入 state 的方式 input = (state - item) + item_feat\n",
    "      拆掉 model_predict 成 function\n",
    "      \n",
    "      here should be state_t * all_items\n",
    "      '''\n",
    "      state_tensor, state_t = get_input_tensor(state_t, current_stream, with_tensor=True)\n",
    "      # puts state into input\n",
    "      inputs = pd.concat([inputs, state_t], axis=0)\n",
    "      \n",
    "      # use target_net to predict target for eval_net to learn\n",
    "      current_target = target_net(state_tensor).detach().view(len(reward_t), 1)\n",
    "\n",
    "      selected_ids = np.where(action_t > 0)[0]\n",
    "      reward_t = df_to_tensor(reward_t).view(len(reward_t), 1)\n",
    "      \n",
    "      '''\n",
    "      每個 actions 都會被 predict 一個成績/reward\n",
    "      '''\n",
    "      # if the game ended, the reward is the final reward\n",
    "      if game_over:  # if game_over is True\n",
    "        current_target[selected_ids] = reward_t[selected_ids]\n",
    "      else:\n",
    "        # DIFF btw current_stream & next_stream\n",
    "        state_tp1, _ = get_input_tensor(state_tp1, next_stream, with_tensor=True)\n",
    "        # Double DQN\n",
    "        _, selected_actions = eval_net(state_tp1).max(dim=0, keepdim=True)\n",
    "        Q_sa = target_net(state_tp1).gather(dim=0, index=selected_actions)\n",
    "\n",
    "        # r + gamma * max Q(s',a')\n",
    "        # current_target = reward_t + self.discount * Q_sa\n",
    "        current_target[selected_ids] = reward_t[selected_ids] + Q_sa * self.discount\n",
    "        \n",
    "      targets = torch.cat((targets, current_target), 0)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "\n",
    "class Epsilon(ABC):\n",
    "  @abstractmethod\n",
    "  def clear(self):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def get_epsilon(self, key):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def update_at_step(self, key, data):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def update_at_epoch(self, data):\n",
    "    pass\n",
    "  \n",
    "  # @abstractmethod\n",
    "  # def update_at_epsisode():\n",
    "  #   pass\n",
    "\n",
    "\n",
    "class Decay(Epsilon):\n",
    "  # Ref: Decay(0.5, 0.85)\n",
    "  '''\n",
    "  Epsilon Decay EE method with update/decay at epoch\n",
    "  '''\n",
    "  def __init__(self, initial, epoch_decay, step_decay):\n",
    "    self.initial = initial\n",
    "    self.epoch_decay, self.step_decay = epoch_decay, step_decay\n",
    "    self.epsilon = self.initial\n",
    "    \n",
    "  def clear(self):\n",
    "    self.epsilon = self.initial # should be 4 for origin setting\n",
    "    \n",
    "  def get_epsilon(self, key):\n",
    "    return self.epsilon\n",
    "  \n",
    "  def update_at_step(self, key, data):\n",
    "    # origin setting\n",
    "    pass\n",
    "    # exponentially\n",
    "    # self.epsilon *= self.step_decay\n",
    "    \n",
    "  def update_at_epoch(self, data):\n",
    "    # origin settings\n",
    "    epoch = data\n",
    "    self.epsilon = 4 / ((epoch + 1) ** (1 / 2))\n",
    "    # exponentially\n",
    "    # self.epsilon *= self.epoch_decay\n",
    "\n",
    "\n",
    "class VDBE(Epsilon):\n",
    "  # VDBE(0.5, 0.01)\n",
    "  def __init__(self, initial, sigma):\n",
    "    self.initial = initial\n",
    "    self.sigma = sigma\n",
    "\n",
    "  def clear(self):\n",
    "    self.epsilon = defaultdict(lambda: self.initial)\n",
    "\n",
    "  def get_epsilon(self, key):\n",
    "    return self.epsilon[key]\n",
    "  \n",
    "  def update_at_step(self, key, data, delta):\n",
    "    td_error = data\n",
    "    coeff = math.exp(-abs(td_error) / self.sigma)\n",
    "    f = (1.0 - coeff) / (1.0 + coeff)\n",
    "    self.epsilon[key] = delta * f + (1.0 - delta) * self.epsilon[key]\n",
    "  \n",
    "  def update_at_epoch(self, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(object):\n",
    "  def __init__(self, exp_replay, epsilon, num_episode, epochs, batch_size, lr, switch_param_threshold):\n",
    "    self.eval_net, self.target_net = Net(), Net()\n",
    "    self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=lr)\n",
    "    self.loss_fn = nn.MSELoss()\n",
    "    self.exp_replay = exp_replay\n",
    "    self.epsilon = epsilon\n",
    "    self.num_episode = num_episode\n",
    "    self.epochs = epochs\n",
    "    self.batch_size = batch_size\n",
    "    self.switch_param_threshold = switch_param_threshold\n",
    "    self.user_all_stream_init = USER_ALL_STREAM_INIT\n",
    "    self.hist = []\n",
    "    self.c_hist = []\n",
    "    self.rec_list = []\n",
    "    self.ep_score_list = []\n",
    "    self.learn_step_counter = 0\n",
    "\n",
    "  # Environment Methods\n",
    "  def __episodes(self):\n",
    "    # return USER_LIST[:self.num_episode]\n",
    "    return np.random.choice(USER_LIST, self.num_episode, replace=False)\n",
    "  \n",
    "  def __user_episode_context(self):\n",
    "    self.user_all_streams = CONTEXT_REPS.xs(self.asid, level=\"asid\")\n",
    "    self.stream_list = self.user_all_streams.index\n",
    "    self.final_stream = max(self.stream_list)\n",
    "  \n",
    "  def __full_state(self, i):\n",
    "    '''\n",
    "    retrieve full state -> should be exported to pickle\n",
    "    '''\n",
    "    if (i - 1) == -1:\n",
    "      user_part = self.user_all_stream_init.copy()\n",
    "      user_part.name = self.stream_list[i]\n",
    "    else:\n",
    "      user_part = self.user_all_streams.loc[self.stream_list[(i - 1)]]\n",
    "    return user_part\n",
    "\n",
    "  def reward(self):\n",
    "    '''\n",
    "    Comparison function for reward, 考慮「所有」歷史購買紀錄\n",
    "    '''\n",
    "    real_bought_ids = BOUGHT_DICT[self.asid]\n",
    "    real_bought_ids_series = gen_exist_series(real_bought_ids, self.stream_items)\n",
    "    \n",
    "    reward_list = [a & b for a, b in zip(real_bought_ids_series, self.action_ids)]\n",
    "    # Reward Count \n",
    "    self.rec_cnt += 1\n",
    "    if sum(reward_list) > 0:\n",
    "      self.c_win_cnt += 1\n",
    "      self.win_cnt += 1\n",
    "      self.ep_score += sum(reward_list)\n",
    "    # return list(map(lambda x: x * sum(reward_list), reward_list))\n",
    "    return pd.Series(list(map(lambda x: x * sum(reward_list), reward_list)), index=self.stream_items)\n",
    "\n",
    "  # Agent Methods\n",
    "  def __choose_actions(self):\n",
    "    if np.random.rand() <= self.epsilon.get_epsilon(self.asid):\n",
    "    # if len(self.exp_replay.memory) < 1:\n",
    "      # Explore by randomly select 10/n items from candidate_items\n",
    "      # Get all items from the stream\n",
    "      self.explore += 1\n",
    "      selected_actions = random.sample(self.stream_items, 10) if len(self.stream_items) > 10 else self.stream_items\n",
    "    else:\n",
    "      # Exploit by choosing action from the model's prediction\n",
    "      self.exploit += 1\n",
    "      selected_actions = self.__agent_predict()\n",
    "    x = pd.Series(0, index=self.stream_items)\n",
    "    x.loc[selected_actions] = 1\n",
    "    return x\n",
    "    \n",
    "  def q_value(self): \n",
    "    if type(self.epsilon) == Decay: return 0\n",
    "\n",
    "    predicts = self.eval_net(self.full_input).flatten()    \n",
    "    actions_idx = np.where(self.action_ids.values == 1)[0]\n",
    "    q_val = predicts[actions_idx].mean()\n",
    "    return q_val\n",
    "\n",
    "  def __agent_predict(self):\n",
    "    predicts = self.eval_net(self.full_input).flatten()\n",
    "    if len(predicts) > 10:\n",
    "      top10_idx = torch.topk(predicts, 10).indices.cpu()\n",
    "      actions = self.candidate_actions.iloc[top10_idx]['item_id'].values\n",
    "    else:\n",
    "      actions = self.candidate_actions['item_id'].values\n",
    "    return actions\n",
    "\n",
    "  def __train_agent_batch(self, inputs, targets):\n",
    "    self.optimizer.zero_grad()\n",
    "    outputs = self.eval_net(inputs)\n",
    "    loss = self.loss_fn(outputs, targets)\n",
    "    # Add CL Regularization Term\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "  # MAIN TRAIN\n",
    "  def train(self):\n",
    "    self.eval_net.to(DEVICE)\n",
    "    self.target_net.to(DEVICE)\n",
    "    self.c_win_cnt = 0\n",
    "    self.eval_net.train(True)\n",
    "    self.epsilon.clear()\n",
    "    self.explore = 0\n",
    "    self.exploit = 0\n",
    "\n",
    "    for e in self.epochs:\n",
    "      self.rec_cnt = 0\n",
    "      self.win_cnt = 0\n",
    "      self.loss = 0.\n",
    "      self.ep_score = 0\n",
    "\n",
    "      print(f'Epoch {e} started.   Time: {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
    "      # ------------------- Episode (User) -------------------------------\n",
    "      for asid in tqdm(self.__episodes()):\n",
    "        self.asid = asid\n",
    "        self.__user_episode_context()\n",
    "\n",
    "        # ----------------- Runs (User x All_Stream) ---------------------\n",
    "        for i, stream in enumerate(self.stream_list):\n",
    "          game_over = stream == self.final_stream\n",
    "          self.current_stream = stream\n",
    "          self.current_state = self.__full_state(i)\n",
    "          self.stream_items = STREAM_ITEM_DICT[self.current_stream]\n",
    "          self.full_input, self.candidate_actions = get_input_tensor(self.current_state, self.current_stream, with_tensor=True)\n",
    "\n",
    "          # --------------- Explore/Exploit Section ----------------------\n",
    "          self.action_ids = self.__choose_actions()\n",
    "\n",
    "          # --------------- Get next state & info to store ---------------\n",
    "          reward = self.reward()\n",
    "          next_state = self.__full_state(i+1) if not game_over else []\n",
    "          next_stream = 0 if (i + 1) == len(self.stream_list) else self.stream_list[i + 1]\n",
    "          self.exp_replay.remember([[stream, next_stream], self.current_state, self.action_ids, reward, next_state], game_over)\n",
    "          self.learn_step_counter += 1\n",
    "          if self.learn_step_counter % self.switch_param_threshold == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "\n",
    "\n",
    "          # --------------- Load batch of experiences --------------------\n",
    "          inputs, targets = self.exp_replay.get_batch(self.eval_net, self.target_net, batch_size=self.batch_size)\n",
    "          inputs = df_to_tensor(inputs)\n",
    "          # store pre-training value for td_error\n",
    "          old_Q = self.q_value()\n",
    "          batch_loss = self.__train_agent_batch(inputs, targets)\n",
    "          # store post-training value for td_error\n",
    "          new_Q = self.q_value()\n",
    "          self.loss += batch_loss\n",
    "\n",
    "          # --------------- Update with TD error -------------------------\n",
    "          self.epsilon.update_at_step(self.asid, (new_Q - old_Q), len(self.stream_items))\n",
    "\n",
    "      # Track win history to later check if our model is improving at the game over time.\n",
    "      self.hist.append(self.win_cnt)\n",
    "      self.c_hist.append(self.c_win_cnt)\n",
    "      self.rec_list.append(self.rec_cnt)\n",
    "      self.ep_score_list.append(self.ep_score)\n",
    "\n",
    "      print(f'Epoch: {e}/{len(self.epochs)} | Loss {self.loss} | Epoch Hit Rate {self.win_cnt/self.rec_cnt} | \\\n",
    "              Cumulative Hit Rate {self.c_win_cnt/sum(self.rec_list)} | Explore {self.explore} | Exploit {self.exploit} | \\\n",
    "              Score {self.ep_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# parameters\n",
    "MAX_MEMORY = 1000  # Maximum number of experiences we are storing\n",
    "BATCH_SIZE = 2  # Number of experiences we use for training per batch\n",
    "EPOCH = range(100)\n",
    "TOTAL_ACTIONS = 1 # probability of ordering\n",
    "NUM_EPISODE = 100\n",
    "HIDDEN_SIZE = 512\n",
    "LR = 1.0e-4\n",
    "SWITCH_PARAM_THRESHOLD = 100\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(380, 512)\n",
    "    self.fc2 = nn.Linear(512, 256)\n",
    "    self.fc3 = nn.Linear(256, 128)\n",
    "    self.fc4 = nn.Linear(128, 64)\n",
    "    self.fc5 = nn.Linear(64, 1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.tanh = nn.Tanh()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc4(x)\n",
    "    x = self.tanh(x)\n",
    "    x = self.fc5(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.   Time: 12:26:44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4124e403cde24d0ebc8a9cbcc1208fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100 | Loss 440.95246748544105 | Epoch Hit Rate 0.5280851063829787 |               Cumulative Hit Rate 0.5280851063829787 | Explore 2320 | Exploit 2380 |               Score 3602\n",
      "Epoch 1 started.   Time: 12:33:51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803fa48eed4b4931bced494ba59e52a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 | Loss 685.2494558972703 | Epoch Hit Rate 0.5565144180172595 |               Cumulative Hit Rate 0.542376468098614 | Explore 4660 | Exploit 4791 |               Score 4005\n",
      "Epoch 2 started.   Time: 12:40:53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7fa799722340308ee32a848e0730e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100 | Loss 372.5466829305951 | Epoch Hit Rate 0.527647190508171 |               Cumulative Hit Rate 0.5376490875125737 | Explore 6864 | Exploit 7054 |               Score 3416\n",
      "Epoch 3 started.   Time: 12:47:39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d440ed713a8944a4a3e3a8ad652fc17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100 | Loss 476.2152346841676 | Epoch Hit Rate 0.5312627707396812 |               Cumulative Hit Rate 0.5359876674463109 | Explore 9281 | Exploit 9531 |               Score 3907\n",
      "Epoch 4 started.   Time: 12:54:52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a09f10186e4963a836aa382fdefe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100 | Loss 509.09786919287944 | Epoch Hit Rate 0.5475980608197444 |               Cumulative Hit Rate 0.5382441113490364 | Explore 11496 | Exploit 11854 |               Score 3723\n",
      "Epoch 5 started.   Time: 13:01:29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcadd898f0d34089955c5bc8d63db131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100 | Loss 778.5603531216766 | Epoch Hit Rate 0.5642404455540618 |               Cumulative Hit Rate 0.5429842070245474 | Explore 13682 | Exploit 14875 |               Score 4566\n",
      "Epoch 6 started.   Time: 13:08:49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5231d6f76ef44e2eac99dfc69391f00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100 | Loss 485.3543034451286 | Epoch Hit Rate 0.553311120366514 |               Cumulative Hit Rate 0.5444707575167121 | Explore 16048 | Exploit 17311 |               Score 4028\n",
      "Epoch 7 started.   Time: 13:15:53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1df8ff3b66442ffaab96f8371163326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100 | Loss 402.43019782014017 | Epoch Hit Rate 0.5483432916892993 |               Cumulative Hit Rate 0.5448557004400529 | Explore 17860 | Exploit 19181 |               Score 3094\n",
      "Epoch 8 started.   Time: 13:21:17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034694ad05e643ccab2f56e955e9c5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100 | Loss 405.2411690707104 | Epoch Hit Rate 0.5384985563041386 |               Cumulative Hit Rate 0.5442143845425638 | Explore 19899 | Exploit 21298 |               Score 3178\n",
      "Epoch 9 started.   Time: 13:27:10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722327b3995d4f8b9ff2aeaa0ec24a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100 | Loss 462.17244941349054 | Epoch Hit Rate 0.5359015272395714 |               Cumulative Hit Rate 0.5434143559143559 | Explore 22050 | Exploit 23534 |               Score 3562\n",
      "Epoch 10 started.   Time: 13:33:55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ec68664ca041d9ba564a2a49a5fcd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100 | Loss 452.8299147592552 | Epoch Hit Rate 0.525997310623039 |               Cumulative Hit Rate 0.5418614874315629 | Explore 24223 | Exploit 25823 |               Score 3373\n",
      "Epoch 11 started.   Time: 13:40:14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da2efc1627140aca6c27a73aff19764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100 | Loss 621.7565842086842 | Epoch Hit Rate 0.5451412818745692 |               Cumulative Hit Rate 0.5421239361017666 | Explore 26229 | Exploit 28170 |               Score 3714\n",
      "Epoch 12 started.   Time: 13:46:27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806f63f95e8e49b89664ee0d8e30c06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100 | Loss 534.8464327650581 | Epoch Hit Rate 0.5555032925682032 |               Cumulative Hit Rate 0.5430938943922525 | Explore 28311 | Exploit 30340 |               Score 3588\n",
      "Epoch 13 started.   Time: 13:52:27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae64739ca3b40c6bd61593abf765ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100 | Loss 474.57376471415046 | Epoch Hit Rate 0.5106433867495814 |               Cumulative Hit Rate 0.540934555640438 | Explore 30369 | Exploit 32463 |               Score 3121\n",
      "Epoch 14 started.   Time: 13:58:23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a91fcce42f44a79d82bea42b19ec1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100 | Loss 471.12908887706544 | Epoch Hit Rate 0.5574121679520138 |               Cumulative Hit Rate 0.542074074074074 | Explore 32670 | Exploit 34830 |               Score 3781\n",
      "Epoch 15 started.   Time: 14:04:48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd6efe1356b4954bed994437eb80aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100 | Loss 603.7181027504448 | Epoch Hit Rate 0.5734383792909398 |               Cumulative Hit Rate 0.5443698425121171 | Explore 35297 | Exploit 37534 |               Score 4575\n",
      "Epoch 16 started.   Time: 14:12:04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2284c52f3345299a82e5f96e977aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100 | Loss 337.45464555435683 | Epoch Hit Rate 0.5111920874544508 |               Cumulative Hit Rate 0.5427073415674357 | Explore 37180 | Exploit 39493 |               Score 2878\n",
      "Epoch 17 started.   Time: 14:17:40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b7c6d74db845878252fc2af3d0a509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100 | Loss 300.07727680321295 | Epoch Hit Rate 0.5212992545260916 |               Cumulative Hit Rate 0.5417075930323639 | Explore 39018 | Exploit 41411 |               Score 3036\n",
      "Epoch 18 started.   Time: 14:23:26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d515330bb23045bda5f0029c1a57e616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100 | Loss 473.27052414250466 | Epoch Hit Rate 0.5373898791231305 |               Cumulative Hit Rate 0.5414605556206775 | Explore 41437 | Exploit 43873 |               Score 3912\n",
      "Epoch 19 started.   Time: 14:30:33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41daf9e42b184dfc974d1929ced04610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100 | Loss 561.9610948918889 | Epoch Hit Rate 0.5568913696865607 |               Cumulative Hit Rate 0.5422594700337898 | Explore 43733 | Exploit 46235 |               Score 3859\n",
      "Epoch 20 started.   Time: 14:37:29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a38881e6649434db11e6cf922b05cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100 | Loss 415.05576175526585 | Epoch Hit Rate 0.542747358309318 |               Cumulative Hit Rate 0.5422810521395487 | Explore 45786 | Exploit 48346 |               Score 3312\n",
      "Epoch 21 started.   Time: 14:43:42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ae41ee94b84313a382c2f4a45daad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100 | Loss 525.9035925519474 | Epoch Hit Rate 0.5428885630498533 |               Cumulative Hit Rate 0.542314335060449 | Explore 48263 | Exploit 51325 |               Score 4183\n",
      "Epoch 22 started.   Time: 14:51:05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4317fa672e4a658965f585564a4572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100 | Loss 587.0707690700292 | Epoch Hit Rate 0.5481781376518219 |               Cumulative Hit Rate 0.5425914587478953 | Explore 50711 | Exploit 53817 |               Score 4162\n",
      "Epoch 23 started.   Time: 14:57:49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a696558517f24797a779718d8e2f7528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100 | Loss 419.3191148557926 | Epoch Hit Rate 0.5246659815005139 |               Cumulative Hit Rate 0.5419479800774765 | Explore 52620 | Exploit 55800 |               Score 2956\n",
      "Epoch 24 started.   Time: 15:03:39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f0e257111a48e6a6321c3240a46620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100 | Loss 471.8564597787263 | Epoch Hit Rate 0.5503461918892186 |               Cumulative Hit Rate 0.5423220973782772 | Explore 54906 | Exploit 58569 |               Score 3957\n",
      "Epoch 25 started.   Time: 15:10:34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2727bdde9f341129f9e1118b2b4fc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100 | Loss 763.4364221809992 | Epoch Hit Rate 0.5721509140412291 |               Cumulative Hit Rate 0.5436151647740206 | Explore 57284 | Exploit 61333 |               Score 4420\n",
      "Epoch 26 started.   Time: 15:17:33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be936564e46348d19db373bcc6c05a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100 | Loss 480.1556563668855 | Epoch Hit Rate 0.5493119266055045 |               Cumulative Hit Rate 0.5438171365377266 | Explore 59321 | Exploit 63656 |               Score 3468\n",
      "Epoch 27 started.   Time: 15:23:41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a25f51f99a44f5f882bfd60e6b4172f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "exp_replay = ReplayBuffer(max_memory=MAX_MEMORY)\n",
    "epsilon = VDBE(0.5, 0.01)\n",
    "dqn = DQN(exp_replay, epsilon, NUM_EPISODE, EPOCH, BATCH_SIZE, LR, SWITCH_PARAM_THRESHOLD)\n",
    "dqn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline100 = pd.read_pickle('../Experiment/baseline-100ep-res.pkl')\n",
    "target100 = pd.read_pickle('../Experiment/vdbe_100_max_target.pkl')\n",
    "# '../Experiment/vdbe_100_max_target.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "res = [a/b for a, b in zip(dqn.hist, dqn.rec_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe30d0980f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(res, label='hit@10')\n",
    "plt.plot(pd.Series(res).rolling(30).mean(), c='r', label='VDBE + DDQN hit@10 ma 30')\n",
    "plt.plot(pd.Series(target100).rolling(30).mean(), label='Target hit@10 ma 30')\n",
    "plt.plot(pd.Series(baseline100).rolling(30).mean(), label='Baseline hit@10 ma 30')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Hit Ratio')\n",
    "plt.title('Hit@10 Comparison')\n",
    "# plt.ylim([0.4, 0.6])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Models/vdbe_100_ddqn.pkl', 'wb') as file_pi:\n",
    "  pickle.dump(dqn, file_pi, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n請不要關掉這ㄍ分頁 乾蝦哈咪搭\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "請不要關掉這ㄍ分頁 乾蝦哈咪搭\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "# %reload_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 13.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "exp_replay2 = ReplayBuffer(max_memory=MAX_MEMORY)\n",
    "epsilon2 = VDBE(0.5, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.6 s, sys: 146 ms, total: 8.74 s\n",
      "Wall time: 8.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dqn2 = DQN(exp_replay2, epsilon2, 5, range(2), BATCH_SIZE, LR, SWITCH_PARAM_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Chasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.   Time: 15:11:50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b440ae02fd4549e4883526f3e5241182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/2 | Loss 30.55317629570345 | Epoch Hit Rate 0.592896174863388 |               Cumulative Hit Rate 0.592896174863388 | Explore 174 | Exploit 192 | Score 315\n",
      "Epoch 1 started.   Time: 15:12:37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70f628110bf4a87ba89a1fdf7f8535d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 60.3371 s\n",
       "File: <ipython-input-13-35d26399f5ef>\n",
       "Function: train at line 102\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   102                                             def train(self):\n",
       "   103         1    1439657.0 1439657.0      0.0      self.eval_net.to(DEVICE)\n",
       "   104         1     502707.0 502707.0      0.0      self.target_net.to(DEVICE)\n",
       "   105         1        983.0    983.0      0.0      self.c_win_cnt = 0\n",
       "   106         1      43602.0  43602.0      0.0      self.eval_net.train(True)\n",
       "   107         1       3875.0   3875.0      0.0      self.epsilon.clear()\n",
       "   108         1        468.0    468.0      0.0      self.explore = 0\n",
       "   109         1        306.0    306.0      0.0      self.exploit = 0\n",
       "   110                                           \n",
       "   111         2       1601.0    800.5      0.0      for e in self.epochs:\n",
       "   112         2        842.0    421.0      0.0        self.rec_cnt = 0\n",
       "   113         2        427.0    213.5      0.0        self.win_cnt = 0\n",
       "   114         2        622.0    311.0      0.0        self.loss = 0.\n",
       "   115         2        555.0    277.5      0.0        self.ep_score = 0\n",
       "   116                                           \n",
       "   117         2     139880.0  69940.0      0.0        print(f'Epoch {e} started.   Time: {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
       "   118                                                 # ------------------- Episode (User) -------------------------------\n",
       "   119        10  400310936.0 40031093.6      0.7        for asid in tqdm(self.__episodes()):\n",
       "   120        10      13728.0   1372.8      0.0          self.asid = asid\n",
       "   121        10   25829562.0 2582956.2      0.0          self.__user_episode_context()\n",
       "   122                                           \n",
       "   123                                                   # ----------------- Runs (User x All_Stream) ---------------------\n",
       "   124       484    1164459.0   2405.9      0.0          for i, stream in enumerate(self.stream_list):\n",
       "   125       484     317647.0    656.3      0.0            game_over = stream == self.final_stream\n",
       "   126       484     182125.0    376.3      0.0            self.current_stream = stream\n",
       "   127       484  231048429.0 477372.8      0.4            self.current_state = self.__full_state(i)\n",
       "   128       484     753662.0   1557.2      0.0            self.stream_items = STREAM_ITEM_DICT[self.current_stream]\n",
       "   129       484 10181947303.0 21037081.2     16.9            self.full_input, self.candidate_actions = get_input_tensor(self.current_state, self.current_stream, with_tensor=True)\n",
       "   130                                           \n",
       "   131                                                     # --------------- Explore/Exploit Section ----------------------\n",
       "   132       484  605461815.0 1250954.2      1.0            self.action_ids = self.__choose_actions()\n",
       "   133                                           \n",
       "   134                                                     # --------------- Get next state & info to store ---------------\n",
       "   135       484 2656283319.0 5488188.7      4.4            reward = self.reward()\n",
       "   136       484  192899038.0 398551.7      0.3            next_state = self.__full_state(i+1) if not game_over else []\n",
       "   137       484    1989203.0   4109.9      0.0            next_stream = 0 if (i + 1) == len(self.stream_list) else self.stream_list[i + 1]\n",
       "   138       484    1814537.0   3749.0      0.0            self.exp_replay.remember([[stream, next_stream], self.current_state, self.action_ids, reward, next_state], game_over)\n",
       "   139       484     277462.0    573.3      0.0            self.learn_step_counter += 1\n",
       "   140       480     326020.0    679.2      0.0            if self.learn_step_counter % self.switch_param_threshold == 0:\n",
       "   141         4    1105934.0 276483.5      0.0              self.target_net.load_state_dict(self.eval_net.state_dict())\n",
       "   142                                           \n",
       "   143                                           \n",
       "   144                                                     # --------------- Load batch of experiences --------------------\n",
       "   145       484 44009833102.0 90929407.2     72.9            inputs, targets = self.exp_replay.get_batch(self.eval_net, self.target_net, batch_size=self.batch_size)\n",
       "   146       484  166667983.0 344355.3      0.3            inputs = df_to_tensor(inputs)\n",
       "   147                                                     # store pre-training value for td_error\n",
       "   148       484  225928609.0 466794.6      0.4            old_Q = self.q_value()\n",
       "   149       484 1355745209.0 2801126.5      2.2            batch_loss = self.__train_agent_batch(inputs, targets)\n",
       "   150                                                     # store post-training value for td_error\n",
       "   151       484  227307089.0 469642.7      0.4            new_Q = self.q_value()\n",
       "   152       484     650177.0   1343.3      0.0            self.loss += batch_loss\n",
       "   153                                           \n",
       "   154                                                     # --------------- Update with TD error -------------------------\n",
       "   155       484   47013315.0  97134.9      0.1            self.epsilon.update_at_step(f'{self.asid}-{self.current_stream}', (new_Q - old_Q), len(self.stream_items))\n",
       "   156                                           \n",
       "   157                                                 # Track win history to later check if our model is improving at the game over time.\n",
       "   158         2       2287.0   1143.5      0.0        self.hist.append(self.win_cnt)\n",
       "   159         2       1978.0    989.0      0.0        self.c_hist.append(self.c_win_cnt)\n",
       "   160         2       1453.0    726.5      0.0        self.rec_list.append(self.rec_cnt)\n",
       "   161         2       1135.0    567.5      0.0        self.ep_score_list.append(self.ep_score)\n",
       "   162                                           \n",
       "   163         2        664.0    332.0      0.0        print(f'Epoch: {e}/{len(self.epochs)} | Loss {self.loss} | Epoch Hit Rate {self.win_cnt/self.rec_cnt} | \\\n",
       "   164         2     105182.0  52591.0      0.0                Cumulative Hit Rate {self.c_win_cnt/sum(self.rec_list)} | Explore {self.explore} | Exploit {self.exploit} | Score {self.ep_score}')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2 | Loss 15.90636516964878 | Epoch Hit Rate 0.5 |               Cumulative Hit Rate 0.5702479338842975 | Explore 236 | Exploit 248 | Score 99\n"
     ]
    }
   ],
   "source": [
    "%lprun -f dqn2.train dqn2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### old profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0665795 s\n",
       "File: <ipython-input-35-467d7b91a616>\n",
       "Function: get_batch at line 26\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    26                                             def get_batch(self, eval_net, target_net, batch_size=10):\n",
       "    27                                               # How many experiences do we have?\n",
       "    28         1       1060.0   1060.0      0.0      len_memory = len(self.memory)\n",
       "    29                                           \n",
       "    30                                               # Calculate the number of actions that can possibly be taken in the game.\n",
       "    31                                               # Actions: 0 = not recommend, 1 = recommend\n",
       "    32         1        316.0    316.0      0.0      num_actions = self.model_output_shape\n",
       "    33                                           \n",
       "    34                                               # Dimensions of our observed states, ie, the input to our model.\n",
       "    35                                               # Memory:  [\n",
       "    36                                               #   [ [ [stream, next_stream], [...state], action, reward, next_state_idx], game_over],\n",
       "    37                                               #   [ [ [stream, next_stream], [...state], action, reward, nexr_state_idx], game_over],\n",
       "    38                                               #   ...\n",
       "    39                                               # ]\n",
       "    40         1        367.0    367.0      0.0      env_dim = len(INPUT_DF_COL)\n",
       "    41                                           \n",
       "    42         1     468472.0 468472.0      0.7      inputs = pd.DataFrame()\n",
       "    43         1      49257.0  49257.0      0.1      targets = torch.tensor([], dtype=torch.float32).to(DEVICE)\n",
       "    44                                               \n",
       "    45                                               \n",
       "    46                                               # We draw states to learn from randomly\n",
       "    47         2      44269.0  22134.5      0.1      for i, idx in enumerate(np.random.randint(0, len_memory, size=min(len_memory, batch_size))):  \n",
       "    48                                                 # Here we load one transition <s, a, r, s'> from memory\n",
       "    49         2       8022.0   4011.0      0.0        streams, state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
       "    50         2        815.0    407.5      0.0        current_stream, next_stream = streams\n",
       "    51         2        707.0    353.5      0.0        game_over = self.memory[idx][1]\n",
       "    52                                           \n",
       "    53                                                 '''\n",
       "    54                                                 修改倒入 state 的方式 input = (state - item) + item_feat\n",
       "    55                                                 拆掉 model_predict 成 function\n",
       "    56                                                 \n",
       "    57                                                 here should be state_t * all_items\n",
       "    58                                                 '''\n",
       "    59         2   27359636.0 13679818.0     41.1        state_t = get_input_tensor(state_t, current_stream)\n",
       "    60                                                 # puts state into input\n",
       "    61         2    1239977.0 619988.5      1.9        inputs = pd.concat([inputs, state_t], axis=0)\n",
       "    62                                           \n",
       "    63                                                 '''\n",
       "    64                                                 每個 actions 都會被 predict 一個成績/reward\n",
       "    65                                                 '''\n",
       "    66                                                 # if the game ended, the reward is the final reward\n",
       "    67         2        572.0    286.0      0.0        if game_over:  # if game_over is True\n",
       "    68                                                   current_target = torch.tensor(reward_t).to(DEVICE).view(len(reward_t), 1).float()\n",
       "    69                                                 else:\n",
       "    70                                                   # DIFF btw current_stream & next_stream\n",
       "    71         2   35643211.0 17821605.5     53.5          state_tp1, _ = get_input_tensor(state_tp1, next_stream, with_tensor=True)\n",
       "    72                                                   # TODO: DDQN\n",
       "    73                                                   # 先用 `eval_net` 決定最好的 actions\n",
       "    74                                                   # 再用 `target_net` 去算他的 Q value\n",
       "    75                                                   \n",
       "    76         2     849835.0 424917.5      1.3          _, selected_actions = eval_net(state_tp1).max(dim=0, keepdim=True)\n",
       "    77         2     628980.0 314490.0      0.9          Q_sa = target_net(state_tp1).gather(dim=0, index=selected_actions)\n",
       "    78         2     106967.0  53483.5      0.2          reward_tensor = torch.tensor(reward_t).to(DEVICE).view(len(reward_t), 1).float()\n",
       "    79                                           \n",
       "    80                                           \n",
       "    81                                                   # r + gamma * max Q(s',a')\n",
       "    82                                                   # current_target = reward_t + self.discount * Q_sa\n",
       "    83         2      90634.0  45317.0      0.1          current_target = torch.add(reward_tensor, Q_sa * self.discount)\n",
       "    84         2      86173.0  43086.5      0.1        targets = torch.cat((targets, current_target), 0)\n",
       "    85         1        256.0    256.0      0.0      return inputs, targets"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f exp_replay2.get_batch exp_replay2.get_batch(dqn2.eval_net, dqn2.target_net, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0143567 s\n",
       "File: <ipython-input-8-0d98a1c59d51>\n",
       "Function: get_input_tensor at line 9\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     9                                           def get_input_tensor(input_state, current_stream, with_tensor=False):\n",
       "    10                                             # Get item feats\n",
       "    11                                             # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
       "    12         1       2209.0   2209.0      0.0    item_list = STREAM_ITEM_DICT[current_stream]\n",
       "    13         1    2067577.0 2067577.0     14.4    item_feat = BERT_BY_IDX_DF.loc[item_list].reset_index().rename(columns={'index': 'item_id'})\n",
       "    14                                           \n",
       "    15                                             # Fill in other context\n",
       "    16         1   10489675.0 10489675.0     73.1    stream_item_feat = pd.DataFrame([input_state]*len(item_list)).reset_index(drop=True)\n",
       "    17                                             \n",
       "    18                                             # Merge with items\n",
       "    19         1    1433205.0 1433205.0     10.0    stream_item_feat = stream_item_feat.merge(item_feat, left_index=True, right_index=True).astype('float32')\n",
       "    20                                             \n",
       "    21                                             # Convert to tensor\n",
       "    22         1        225.0    225.0      0.0    if with_tensor: \n",
       "    23         1     363501.0 363501.0      2.5      stream_item_feat_tensor = df_to_tensor(stream_item_feat)\n",
       "    24         1        279.0    279.0      0.0      return stream_item_feat_tensor, stream_item_feat\n",
       "    25                                             else:\n",
       "    26                                               return stream_item_feat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f get_input_tensor get_input_tensor(CONTEXT_REPS.iloc[0], CONTEXT_REPS.iloc[0].name[1], with_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleansing\n",
    "Original Version:\n",
    "```python\n",
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "\n",
    "Convert state format to model input format\n",
    "'''\n",
    "def get_input(input_state, current_stream):\n",
    "  # Get item feats\n",
    "  # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list]\n",
    "\n",
    "  # Create new df\n",
    "  stream_item_feat = pd.DataFrame(columns=INPUT_DF_COL)\n",
    "\n",
    "  # Fill in other context\n",
    "  stream_item_feat = stream_item_feat.append([input_state]*len(item_list),ignore_index=True)\n",
    "  \n",
    "  # stream_item_feat\n",
    "  stream_item_feat[LB_ITEMS] = item_feat.reset_index()\n",
    "  \n",
    "  return stream_item_feat.astype('float32')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "Convert state format to model input format\n",
    "\n",
    "LB_ITEMS = ['item_id'] + [f'i{x}' for x in range(160)]\n",
    "INPUT_DF_COL__USR = CONTEXT_REPS.columns.to_list()\n",
    "INPUT_DF_COL = INPUT_DF_COL__USR + LB_ITEMS\n",
    "'''\n",
    "input_state = CONTEXT_REPS.iloc[0]\n",
    "current_stream = CONTEXT_REPS.iloc[0].name[1]\n",
    "def new_get_input(input_state, current_stream):\n",
    "  # Get item feats\n",
    "  # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list]\n",
    "  \n",
    "  input_state = pd.DataFrame(input_state).transpose()\n",
    "  # input_state['item_feat'] = item_feat\n",
    "  # input_state = input_state.explode('item_feat')\n",
    "  \n",
    "  return item_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i0',\n",
       " 'i1',\n",
       " 'i2',\n",
       " 'i3',\n",
       " 'i4',\n",
       " 'i5',\n",
       " 'i6',\n",
       " 'i7',\n",
       " 'i8',\n",
       " 'i9',\n",
       " 'i10',\n",
       " 'i11',\n",
       " 'i12',\n",
       " 'i13',\n",
       " 'i14',\n",
       " 'i15',\n",
       " 'i16',\n",
       " 'i17',\n",
       " 'i18',\n",
       " 'i19',\n",
       " 'i20',\n",
       " 'i21',\n",
       " 'i22',\n",
       " 'i23',\n",
       " 'i24',\n",
       " 'i25',\n",
       " 'i26',\n",
       " 'i27',\n",
       " 'i28',\n",
       " 'i29',\n",
       " 'i30',\n",
       " 'i31',\n",
       " 'i32',\n",
       " 'i33',\n",
       " 'i34',\n",
       " 'i35',\n",
       " 'i36',\n",
       " 'i37',\n",
       " 'i38',\n",
       " 'i39',\n",
       " 'i40',\n",
       " 'i41',\n",
       " 'i42',\n",
       " 'i43',\n",
       " 'i44',\n",
       " 'i45',\n",
       " 'i46',\n",
       " 'i47',\n",
       " 'i48',\n",
       " 'i49',\n",
       " 'i50',\n",
       " 'i51',\n",
       " 'i52',\n",
       " 'i53',\n",
       " 'i54',\n",
       " 'i55',\n",
       " 'i56',\n",
       " 'i57',\n",
       " 'i58',\n",
       " 'i59',\n",
       " 'i60',\n",
       " 'i61',\n",
       " 'i62',\n",
       " 'i63',\n",
       " 'i64',\n",
       " 'i65',\n",
       " 'i66',\n",
       " 'i67',\n",
       " 'i68',\n",
       " 'i69',\n",
       " 'i70',\n",
       " 'i71',\n",
       " 'i72',\n",
       " 'i73',\n",
       " 'i74',\n",
       " 'i75',\n",
       " 'i76',\n",
       " 'i77',\n",
       " 'i78',\n",
       " 'i79',\n",
       " 'i80',\n",
       " 'i81',\n",
       " 'i82',\n",
       " 'i83',\n",
       " 'i84',\n",
       " 'i85',\n",
       " 'i86',\n",
       " 'i87',\n",
       " 'i88',\n",
       " 'i89',\n",
       " 'i90',\n",
       " 'i91',\n",
       " 'i92',\n",
       " 'i93',\n",
       " 'i94',\n",
       " 'i95',\n",
       " 'i96',\n",
       " 'i97',\n",
       " 'i98',\n",
       " 'i99',\n",
       " 'i100',\n",
       " 'i101',\n",
       " 'i102',\n",
       " 'i103',\n",
       " 'i104',\n",
       " 'i105',\n",
       " 'i106',\n",
       " 'i107',\n",
       " 'i108',\n",
       " 'i109',\n",
       " 'i110',\n",
       " 'i111',\n",
       " 'i112',\n",
       " 'i113',\n",
       " 'i114',\n",
       " 'i115',\n",
       " 'i116',\n",
       " 'i117',\n",
       " 'i118',\n",
       " 'i119',\n",
       " 'i120',\n",
       " 'i121',\n",
       " 'i122',\n",
       " 'i123',\n",
       " 'i124',\n",
       " 'i125',\n",
       " 'i126',\n",
       " 'i127',\n",
       " 'i128',\n",
       " 'i129',\n",
       " 'i130',\n",
       " 'i131',\n",
       " 'i132',\n",
       " 'i133',\n",
       " 'i134',\n",
       " 'i135',\n",
       " 'i136',\n",
       " 'i137',\n",
       " 'i138',\n",
       " 'i139',\n",
       " 'i140',\n",
       " 'i141',\n",
       " 'i142',\n",
       " 'i143',\n",
       " 'i144',\n",
       " 'i145',\n",
       " 'i146',\n",
       " 'i147',\n",
       " 'i148',\n",
       " 'i149',\n",
       " 'i150',\n",
       " 'i151',\n",
       " 'i152',\n",
       " 'i153',\n",
       " 'i154',\n",
       " 'i155',\n",
       " 'i156',\n",
       " 'i157',\n",
       " 'i158',\n",
       " 'i159']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_get_input(CONTEXT_REPS.iloc[0], CONTEXT_REPS.iloc[0].name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.00342255 s\n",
       "File: <ipython-input-48-354800ee8d82>\n",
       "Function: new_get_input at line 11\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    11                                           def new_get_input(input_state, current_stream):\n",
       "    12                                             # Get item feats\n",
       "    13                                             # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
       "    14         1       2660.0   2660.0      0.1    item_list = STREAM_ITEM_DICT[current_stream]\n",
       "    15         1     552753.0 552753.0     16.2    item_feat = BERT_BY_IDX_DF.loc[item_list]\n",
       "    16                                             \n",
       "    17         1    1456739.0 1456739.0     42.6    input_state['item_feat'] = list(item_feat)\n",
       "    18         1    1410208.0 1410208.0     41.2    input_state = input_state.explode('item_feat')\n",
       "    19                                             \n",
       "    20         1        190.0    190.0      0.0    return input_state"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f new_get_input new_get_input(CONTEXT_REPS.iloc[0], CONTEXT_REPS.iloc[0].name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_input_v2(input_state, current_stream):\n",
    "  # Get item feats\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list].reset_index().rename(columns={'index': 'item_id'})\n",
    "\n",
    "  # Fill in other context\n",
    "  stream_item_feat = pd.DataFrame([input_state]*len(item_list)).reset_index(drop=True)\n",
    "  \n",
    "  # Merge with items\n",
    "  stream_item_feat = stream_item_feat.merge(item_feat, left_index=True, right_index=True).astype('float32')\n",
    "  return stream_item_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0176343 s\n",
       "File: <ipython-input-84-4d017c41242b>\n",
       "Function: get_input_v2 at line 9\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     9                                           def get_input_v2(input_state, current_stream):\n",
       "    10                                             # Get item feats\n",
       "    11                                             # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
       "    12         1       8785.0   8785.0      0.0    item_list = STREAM_ITEM_DICT[current_stream]\n",
       "    13         1    5560119.0 5560119.0     31.5    item_feat = BERT_BY_IDX_DF.loc[item_list].reset_index().rename(columns={'index': 'item_id'})\n",
       "    14                                           \n",
       "    15                                             # Fill in other context\n",
       "    16         1   10882756.0 10882756.0     61.7    stream_item_feat = pd.DataFrame([input_state]*len(item_list)).reset_index(drop=True)\n",
       "    17                                             \n",
       "    18                                             # Merge with items\n",
       "    19         1    1182536.0 1182536.0      6.7    stream_item_feat = stream_item_feat.merge(item_feat, left_index=True, right_index=True).astype('float32')\n",
       "    20         1        130.0    130.0      0.0    return stream_item_feat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f get_input_v2 get_input_v2(CONTEXT_REPS.iloc[0], CONTEXT_REPS.iloc[0].name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Chasing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 µs, sys: 2.91 ms, total: 3.02 ms\n",
      "Wall time: 2.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "baseline_model3 = Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "exp_replay3 = ReplayBuffer(max_memory=MAX_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.32 s, sys: 177 ms, total: 8.5 s\n",
      "Wall time: 8.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dqn3 = DQN(baseline_model3, exp_replay3, 5, EPOCH, BATCH_SIZE, LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start Chasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.   Time: 15:23:38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dac98cf24c4a009486a688ebb7ff89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 3.32292 s\n",
       "File: <ipython-input-87-1e430f3ba6d5>\n",
       "Function: train at line 93\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    93                                             def train(self):\n",
       "    94         1   16194974.0 16194974.0      0.5      self.model.to(DEVICE)\n",
       "    95         1        950.0    950.0      0.0      self.c_win_cnt = 0\n",
       "    96         1      40919.0  40919.0      0.0      self.model.train(True)\n",
       "    97                                           \n",
       "    98         1        738.0    738.0      0.0      for e in self.epochs:\n",
       "    99         1        361.0    361.0      0.0        self.rec_cnt = 0\n",
       "   100         1        335.0    335.0      0.0        self.win_cnt = 0\n",
       "   101         1        395.0    395.0      0.0        self.loss = 0.\n",
       "   102         1       1624.0   1624.0      0.0        self.epsilon = 4 / ((e + 1) ** (1 / 2))\n",
       "   103                                           \n",
       "   104         1      99669.0  99669.0      0.0        print(f'Epoch {e} started.   Time: {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
       "   105                                                 # ------------------- Episode (User) -------------------------------\n",
       "   106         5   29169483.0 5833896.6      0.9        for asid in tqdm(self.__episodes()):\n",
       "   107         5       3671.0    734.2      0.0          self.asid = asid\n",
       "   108         5   13840796.0 2768159.2      0.4          self.__user_episode_context()\n",
       "   109                                                   \n",
       "   110                                                   # ----------------- Runs (User x All_Stream) ---------------------\n",
       "   111        40      74011.0   1850.3      0.0          for i, stream in enumerate(self.stream_list):\n",
       "   112        40      42038.0   1051.0      0.0            game_over = stream == self.final_stream\n",
       "   113        40      17114.0    427.9      0.0            self.current_stream = stream\n",
       "   114        40   14281161.0 357029.0      0.4            self.current_state = self.__full_state(i)\n",
       "   115        40      54286.0   1357.2      0.0            self.stream_items = STREAM_ITEM_DICT[self.current_stream]\n",
       "   116                                                     \n",
       "   117                                                     # --------------- Explore/Exploit Section ----------------------\n",
       "   118        40   10822590.0 270564.8      0.3            self.action_ids = self.__choose_actions_eps()\n",
       "   119                                                     \n",
       "   120                                                     # --------------- Get next state & info to store ---------------\n",
       "   121        40   11733166.0 293329.2      0.4            reward = self.__reward()\n",
       "   122        40   13252099.0 331302.5      0.4            next_state = self.__full_state(i+1) if not game_over else []\n",
       "   123        40     155896.0   3897.4      0.0            next_stream = 0 if (i + 1) == len(self.stream_list) else self.stream_list[i + 1]\n",
       "   124        40     110756.0   2768.9      0.0            self.exp_replay.remember([[stream, next_stream], self.current_state, self.action_ids, reward, next_state], game_over)\n",
       "   125                                                     \n",
       "   126                                                     # --------------- Load batch of experiences --------------------\n",
       "   127        40 3137809074.0 78445226.8     94.4            inputs, targets = self.exp_replay.get_batch(self.model, batch_size=self.batch_size)\n",
       "   128        40    5304262.0 132606.5      0.2            inputs, targets = df_to_tensor(inputs).to(DEVICE), df_to_tensor(targets).to(DEVICE)\n",
       "   129        40   69784301.0 1744607.5      2.1            batch_loss = self.__train_agent_batch(inputs, targets)\n",
       "   130        40      38686.0    967.1      0.0            self.loss += batch_loss      \n",
       "   131                                                     \n",
       "   132                                                 \n",
       "   133                                                 # Track win history to later check if our model is improving at the game over time.\n",
       "   134         1       1001.0   1001.0      0.0        self.hist.append(self.win_cnt)\n",
       "   135         1        693.0    693.0      0.0        self.c_hist.append(self.c_win_cnt)\n",
       "   136         1        586.0    586.0      0.0        self.rec_list.append(self.rec_cnt)\n",
       "   137                                           \n",
       "   138         1        295.0    295.0      0.0        print(f'Epoch: {e}/{len(self.epochs)} | Loss {self.loss} | Epoch Hit Rate {self.win_cnt/self.rec_cnt} | Cumulative Hit Rate {self.c_win_cnt/sum(self.rec_list)} |\\\n",
       "   139         1      83647.0  83647.0      0.0                Time {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
       "   140         1        357.0    357.0      0.0        break"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100 | Loss 2.4590116441249847 | Epoch Hit Rate 0.775 | Cumulative Hit Rate 0.775 |              Time 15:23:41\n"
     ]
    }
   ],
   "source": [
    "%lprun -f dqn3.train dqn3.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0848023 s\n",
       "File: <ipython-input-86-f9f91d8b7747>\n",
       "Function: get_batch at line 26\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    26                                             def get_batch(self, model, batch_size=10):\n",
       "    27                                               # How many experiences do we have?\n",
       "    28         1       1013.0   1013.0      0.0      len_memory = len(self.memory)\n",
       "    29                                           \n",
       "    30                                               # Calculate the number of actions that can possibly be taken in the game.\n",
       "    31                                               # Actions: 0 = not recommend, 1 = recommend\n",
       "    32         1        741.0    741.0      0.0      num_actions = self.model_output_shape\n",
       "    33                                           \n",
       "    34                                               # Dimensions of our observed states, ie, the input to our model.\n",
       "    35                                               # Memory:  [\n",
       "    36                                               #   [ [ [stream, next_stream], [...state], action, reward, next_state_idx], game_over],\n",
       "    37                                               #   [ [ [stream, next_stream], [...state], action, reward, nexr_state_idx], game_over],\n",
       "    38                                               #   ...\n",
       "    39                                               # ]\n",
       "    40         1        512.0    512.0      0.0      env_dim = len(INPUT_DF_COL)\n",
       "    41                                           \n",
       "    42         1   23397393.0 23397393.0     27.6      inputs = pd.DataFrame(columns=INPUT_DF_COL)\n",
       "    43         1    1719888.0 1719888.0      2.0      targets = pd.DataFrame(columns=[0])\n",
       "    44                                               \n",
       "    45                                               \n",
       "    46                                               # We draw states to learn from randomly\n",
       "    47         2      40406.0  20203.0      0.0      for i, idx in enumerate(np.random.randint(0, len_memory, size=min(len_memory, batch_size))):  \n",
       "    48                                                 # Here we load one transition <s, a, r, s'> from memory\n",
       "    49         2      12107.0   6053.5      0.0        streams, state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
       "    50         2        582.0    291.0      0.0        current_stream, next_stream = streams\n",
       "    51         2        705.0    352.5      0.0        game_over = self.memory[idx][1]\n",
       "    52                                           \n",
       "    53                                                 '''\n",
       "    54                                                 修改倒入 state 的方式 input = (state - item) + item_feat\n",
       "    55                                                 拆掉 model_predict 成 function\n",
       "    56                                                 \n",
       "    57                                                 here should be state_t * all_items\n",
       "    58                                                 '''\n",
       "    59         2   24825667.0 12412833.5     29.3        state_t = get_input_v2(state_t, current_stream).astype('float32')\n",
       "    60                                                 # puts state into input\n",
       "    61         2    1505652.0 752826.0      1.8        inputs = pd.concat([inputs, state_t], axis=0)\n",
       "    62                                           \n",
       "    63                                                 '''\n",
       "    64                                                 每個 actions 都會被 predict 一個成績/reward\n",
       "    65                                                 '''\n",
       "    66                                                 # if the game ended, the reward is the final reward\n",
       "    67         2        491.0    245.5      0.0        if game_over:  # if game_over is True\n",
       "    68                                                   state_t['reward'] = reward_t\n",
       "    69                                                   targets = pd.concat([targets, reward_t], axis=0).astype('float32')\n",
       "    70                                                 else:\n",
       "    71         2    1833815.0 916907.5      2.2          state_t['reward'] = model(df_to_tensor(state_t).to(DEVICE)).detach().cpu().numpy()\n",
       "    72                                                   # 找到 action_t 們，指到 state_t 上去算 discount values\n",
       "    73         2     686727.0 343363.5      0.8          action_t = list(set(action_t[action_t == 1].index))\n",
       "    74                                                   \n",
       "    75         2   23827017.0 11913508.5     28.1          state_tp1 = get_input_v2(state_tp1, next_stream)\n",
       "    76         2    1203817.0 601908.5      1.4          Q_sa = np.max(model(df_to_tensor(state_tp1).to(DEVICE)).detach().cpu().numpy())\n",
       "    77                                                   # r + gamma * max Q(s',a')\n",
       "    78                                                   # DataFrame apply\n",
       "    79         2     195845.0  97922.5      0.2          state_t.loc[state_t['item_id'].isin(action_t)]['reward'] = state_t.loc[state_t['item_id'] \\\n",
       "    80         2    1266091.0 633045.5      1.5                                                                            .isin(action_t)]['reward'] \\\n",
       "    81         2     562086.0 281043.0      0.7                                                                            .apply(lambda x: x + self.discount * Q_sa) \\\n",
       "    82         2    1512456.0 756228.0      1.8                                                                            .astype('float32')\n",
       "    83         2    2209093.0 1104546.5      2.6          targets = pd.concat([targets, state_t['reward']], axis=0).astype('float32')\n",
       "    84         1        236.0    236.0      0.0      return inputs, targets"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f exp_replay3.get_batch exp_replay3.get_batch(baseline_model3, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per hit\n",
    "* exp/get_input:\n",
    "  * v1: `49609136.0`\n",
    "  * v2: `12412833.5`\n",
    "* train/get_batch:\n",
    "  * v1: `216278453.8`\n",
    "  * v2: `78445226.8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(85)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
    "if len(predicts) > 10:\n",
    "  ind = np.argpartition(predicts, -10)[-10:]\n",
    "  q_val = predicts[ind].sum()\n",
    "else:\n",
    "  q_val = predicts.sum()\n",
    "q_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
