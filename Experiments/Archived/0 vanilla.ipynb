{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Torch] Main Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import line_profiler\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "  np.random.seed(seed)  \n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "CONTEXT_REPS = pd.read_pickle('../../data/w_final_context.pkl')\n",
    "STREAM_ITEM_DICT = pd.read_pickle('../../data/stream_item_dict.pkl')\n",
    "BERT_BY_IDX_DF = pd.read_pickle('../../data/bert_by_idx_pca.pkl')\n",
    "BOUGHT_DICT = pd.read_pickle('../../data/bought_dict.pkl')\n",
    "USER_ALL_STREAM_INIT = CONTEXT_REPS.describe().loc['50%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1397141, 219), 7701, (162189, 160), 79207)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_REPS.shape, len(STREAM_ITEM_DICT), BERT_BY_IDX_DF.shape, len(BOUGHT_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "USER_LIST = CONTEXT_REPS.index.get_level_values('asid').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "LB_ITEMS = ['item_id'] + [f'i{x}' for x in range(160)]\n",
    "INPUT_DF_COL__USR = CONTEXT_REPS.columns.to_list()\n",
    "INPUT_DF_COL = INPUT_DF_COL__USR + LB_ITEMS\n",
    "\n",
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "Convert state format to model input format\n",
    "'''\n",
    "def get_input_v2(input_state, current_stream):\n",
    "  # Get item feats\n",
    "  # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list].reset_index().rename(columns={'index': 'item_id'})\n",
    "\n",
    "  # Fill in other context\n",
    "  stream_item_feat = pd.DataFrame([input_state]*len(item_list)).reset_index(drop=True)\n",
    "  \n",
    "  # Merge with items\n",
    "  stream_item_feat = stream_item_feat.merge(item_feat, left_index=True, right_index=True).astype('float32')\n",
    "  return stream_item_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "\n",
    "Generate series: whether elements in A existed in list B\n",
    "A, B: List\n",
    "return: pd.Series\n",
    "example:\n",
    "  A: [1, 2, 4, 5]\n",
    "  B: [1, 2, 3, 4, 5, 6, 7]\n",
    "  return: Series([1, 1, 0, 1, 1, 0, 0], index=[1, 2, 3, 4, 5, 6, 7])\n",
    "'''\n",
    "def gen_exist_series(A, B):\n",
    "  return [int(item in A) for item in B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_tensor(input_df):\n",
    "  return torch.tensor(input_df.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "  def __init__(self, max_memory=100000, discount=.9, model_output_shape=1):\n",
    "    \"\"\"\n",
    "    Setup\n",
    "    max_memory: the maximum number of experiences we want to store\n",
    "    memory: a list of experiences\n",
    "    discount: the discount factor for future experience\n",
    "    In the memory the information whether the game ended at the state is stored seperately in a nested array\n",
    "    [...\n",
    "    [experience, game_over]\n",
    "    [experience, game_over]\n",
    "    ...]\n",
    "    \"\"\"\n",
    "    self.max_memory = max_memory\n",
    "    self.memory = list()\n",
    "    self.discount = discount\n",
    "    self.model_output_shape = model_output_shape\n",
    "\n",
    "  def remember(self, states, game_over):\n",
    "    # Save a state to memory\n",
    "    self.memory.append([states, game_over])\n",
    "    # We don't want to store infinite memories, so if we have too many, we just delete the oldest one\n",
    "    if len(self.memory) > self.max_memory:\n",
    "      del self.memory[0]\n",
    "\n",
    "  def get_batch(self, model, batch_size=10):\n",
    "    # How many experiences do we have?\n",
    "    len_memory = len(self.memory)\n",
    "\n",
    "    # Calculate the number of actions that can possibly be taken in the game.\n",
    "    # Actions: 0 = not recommend, 1 = recommend\n",
    "    num_actions = self.model_output_shape\n",
    "\n",
    "    # Dimensions of our observed states, ie, the input to our model.\n",
    "    # Memory:  [\n",
    "    #   [ [ [stream, next_stream], [...state], action, reward, next_state_idx], game_over],\n",
    "    #   [ [ [stream, next_stream], [...state], action, reward, nexr_state_idx], game_over],\n",
    "    #   ...\n",
    "    # ]\n",
    "    env_dim = len(INPUT_DF_COL)\n",
    "\n",
    "    inputs = pd.DataFrame(columns=INPUT_DF_COL)\n",
    "    targets = pd.DataFrame(columns=[0])\n",
    "    \n",
    "    \n",
    "    # We draw states to learn from randomly\n",
    "    for i, idx in enumerate(np.random.randint(0, len_memory, size=min(len_memory, batch_size))):  \n",
    "      # Here we load one transition <s, a, r, s'> from memory\n",
    "      streams, state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
    "      current_stream, next_stream = streams\n",
    "      game_over = self.memory[idx][1]\n",
    "\n",
    "      '''\n",
    "      修改倒入 state 的方式 input = (state - item) + item_feat\n",
    "      拆掉 model_predict 成 function\n",
    "      \n",
    "      here should be state_t * all_items\n",
    "      '''\n",
    "      state_t = get_input_v2(state_t, current_stream).astype('float32')\n",
    "      # puts state into input\n",
    "      inputs = pd.concat([inputs, state_t], axis=0)\n",
    "\n",
    "      '''\n",
    "      每個 actions 都會被 predict 一個成績/reward\n",
    "      '''\n",
    "      # if the game ended, the reward is the final reward\n",
    "      if game_over:  # if game_over is True\n",
    "        state_t['reward'] = reward_t\n",
    "      else:\n",
    "        state_tp1 = get_input_v2(state_tp1, current_stream)\n",
    "        Q_sa = model(df_to_tensor(state_tp1).to(DEVICE)).detach().cpu().numpy()\n",
    "        # Double DQN\n",
    "        # Q_sa_ = \n",
    "        # r + gamma * max Q(s',a')\n",
    "        state_t['reward'] = reward_t + self.discount * Q_sa\n",
    "      targets = pd.concat([targets, state_t['reward']], axis=0).astype('float32')\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "\n",
    "class Epsilon(ABC):\n",
    "  @abstractmethod\n",
    "  def clear(self):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def get_epsilon(self, key):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def update_at_step(self, key, data):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def update_at_epoch(self, data):\n",
    "    pass\n",
    "  \n",
    "  # @abstractmethod\n",
    "  # def update_at_epsisode():\n",
    "  #   pass\n",
    "\n",
    "\n",
    "class Decay(Epsilon):\n",
    "  # Ref: Decay(0.5, 0.85)\n",
    "  '''\n",
    "  Epsilon Decay EE method with update/decay at epoch\n",
    "  '''\n",
    "  def __init__(self, initial, epoch_decay, step_decay=1.0):\n",
    "    self.initial = initial\n",
    "    self.epoch_decay, self.step_decay = epoch_decay, step_decay\n",
    "    self.epsilon = self.initial\n",
    "    \n",
    "  def clear(self):\n",
    "    self.epsilon = self.initial # should be 4 for origin setting\n",
    "    \n",
    "  def get_epsilon(self, key):\n",
    "    return self.epsilon\n",
    "  \n",
    "  def update_at_step(self, key, data, _):\n",
    "    # origin setting\n",
    "    pass\n",
    "    # exponentially\n",
    "    # self.epsilon *= self.step_decay\n",
    "    \n",
    "  def update_at_epoch(self, data):\n",
    "    # origin settings\n",
    "    epoch = data\n",
    "    self.epsilon = 4 / ((epoch + 1) ** (1 / 2))\n",
    "    # exponentially\n",
    "    # self.epsilon *= self.epoch_decay\n",
    "\n",
    "\n",
    "class VDBE(Epsilon):\n",
    "  # VDBE(0.5, 0.01)\n",
    "  def __init__(self, initial, sigma):\n",
    "    self.initial = initial\n",
    "    self.sigma = sigma\n",
    "\n",
    "  def clear(self):\n",
    "    self.epsilon = defaultdict(lambda: self.initial)\n",
    "\n",
    "  def get_epsilon(self, key):\n",
    "    return self.epsilon[key]\n",
    "  \n",
    "  def update_at_step(self, key, data, delta):\n",
    "    td_error = data\n",
    "    coeff = math.exp(-abs(td_error) / self.sigma)\n",
    "    f = (1.0 - coeff) / (1.0 + coeff)\n",
    "    self.epsilon[key] = delta * f + (1.0 - delta) * self.epsilon[key]\n",
    "  \n",
    "  def update_at_epoch(self, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(object):\n",
    "  def __init__(self, model, exp_replay, epsilon, num_episode, epochs, batch_size, lr):\n",
    "    self.model = model\n",
    "    self.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    self.loss_fn = nn.MSELoss()\n",
    "    self.exp_replay = exp_replay\n",
    "    self.epsilon = epsilon\n",
    "    self.num_episode = num_episode\n",
    "    self.epochs = epochs\n",
    "    self.batch_size = batch_size\n",
    "    self.user_all_stream_init = USER_ALL_STREAM_INIT\n",
    "    self.hist = []\n",
    "    self.c_hist = []\n",
    "    self.rec_list = []\n",
    "    self.ep_score_list = []\n",
    "\n",
    "  # Environment Methods\n",
    "  def __episodes(self):\n",
    "    # return USER_LIST[:self.num_episode]\n",
    "    return np.random.choice(USER_LIST, self.num_episode, replace=False)\n",
    "  \n",
    "  def __user_episode_context(self):\n",
    "    self.user_all_streams = CONTEXT_REPS.xs(self.asid, level=\"asid\")\n",
    "    self.stream_list = self.user_all_streams.index\n",
    "    self.final_stream = max(self.stream_list)\n",
    "  \n",
    "  def __full_state(self, i):\n",
    "    '''\n",
    "    retrieve full state -> should be exported to pickle\n",
    "    '''\n",
    "    if (i - 1) == -1:\n",
    "      user_part = self.user_all_stream_init.copy()\n",
    "      user_part.name = self.stream_list[i]\n",
    "    else:\n",
    "      user_part = self.user_all_streams.loc[self.stream_list[(i - 1)]]\n",
    "    return user_part\n",
    "\n",
    "  def reward(self):\n",
    "    '''\n",
    "    Comparison function for reward, 考慮「所有」歷史購買紀錄\n",
    "    '''\n",
    "    real_bought_ids = BOUGHT_DICT[self.asid]\n",
    "    real_bought_ids_series = gen_exist_series(real_bought_ids, self.stream_items)\n",
    "    \n",
    "    reward_list = [a & b for a, b in zip(real_bought_ids_series, self.action_ids)]\n",
    "    # Reward Count \n",
    "    self.rec_cnt += 1\n",
    "    if sum(reward_list) > 0:\n",
    "      self.c_win_cnt += 1\n",
    "      self.win_cnt += 1\n",
    "      self.ep_score += sum(reward_list)\n",
    "    return list(map(lambda x: x * sum(reward_list), reward_list))\n",
    "\n",
    "  # Agent Methods\n",
    "  def __choose_actions(self):\n",
    "    if np.random.rand() <= self.epsilon.get_epsilon(f'{self.asid}-{self.current_stream}'):\n",
    "    # if len(self.exp_replay.memory) < 1:\n",
    "      # Explore by randomly select 10/n items from candidate_items\n",
    "      # Get all items from the stream\n",
    "      self.explore += 1\n",
    "      selected_actions = random.sample(self.stream_items, 10) if len(self.stream_items) > 10 else self.stream_items\n",
    "    else:\n",
    "      # Exploit by choosing action from the model's prediction\n",
    "      self.exploit += 1\n",
    "      selected_actions = self.__agent_predict()\n",
    "    x = pd.Series(0, index=self.stream_items)\n",
    "    x.loc[selected_actions] = 1\n",
    "    return x\n",
    "    \n",
    "  def q_value(self): \n",
    "    if type(self.epsilon) == Decay: return 0\n",
    "\n",
    "    predicts = self.model(df_to_tensor(self.full_input).to(DEVICE)).detach().cpu().numpy().flatten()\n",
    "    if len(predicts) > 10:\n",
    "      ind = np.argpartition(predicts, -10)[-10:]\n",
    "      q_val = predicts[ind].sum()\n",
    "    else:\n",
    "      q_val = predicts.sum()\n",
    "    return q_val\n",
    "\n",
    "  def __agent_predict(self):\n",
    "    predicts = self.model(df_to_tensor(self.full_input).to(DEVICE)).detach().cpu().numpy()\n",
    "    full_input = self.full_input.copy()\n",
    "    full_input['predict'] = predicts\n",
    "    actions = full_input['predict'].nlargest(10).index\n",
    "    actions = full_input.loc[actions, 'item_id'].values\n",
    "    return actions\n",
    "\n",
    "  def __train_agent_batch(self, inputs, targets):\n",
    "    self.optimizer.zero_grad()\n",
    "    outputs = self.model(inputs)\n",
    "    loss = self.loss_fn(outputs, targets)\n",
    "    # Add CL Regularization Term\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "  # MAIN TRAIN\n",
    "  def train(self):\n",
    "    self.model.to(DEVICE)\n",
    "    self.c_win_cnt = 0\n",
    "    self.model.train(True)\n",
    "    self.epsilon.clear()\n",
    "    self.explore = 0\n",
    "    self.exploit = 0\n",
    "\n",
    "    for e in self.epochs:\n",
    "      self.rec_cnt = 0\n",
    "      self.win_cnt = 0\n",
    "      self.loss = 0.\n",
    "      self.ep_score = 0\n",
    "\n",
    "      print(f'Epoch {e} started.   Time: {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
    "      # ------------------- Episode (User) -------------------------------\n",
    "      for asid in tqdm(self.__episodes()):\n",
    "        self.asid = asid\n",
    "        self.__user_episode_context()\n",
    "\n",
    "        # ----------------- Runs (User x All_Stream) ---------------------\n",
    "        for i, stream in enumerate(self.stream_list):\n",
    "          game_over = stream == self.final_stream\n",
    "          self.current_stream = stream\n",
    "          self.current_state = self.__full_state(i)\n",
    "          self.stream_items = STREAM_ITEM_DICT[self.current_stream]\n",
    "          self.full_input = get_input_v2(self.current_state, self.current_stream).astype('float32')\n",
    "\n",
    "          # --------------- Explore/Exploit Section ----------------------\n",
    "          self.action_ids = self.__choose_actions()\n",
    "\n",
    "          # --------------- Get next state & info to store ---------------\n",
    "          reward = self.reward()\n",
    "          next_state = self.__full_state(i+1) if not game_over else []\n",
    "          next_stream = 0 if (i + 1) == len(self.stream_list) else self.stream_list[i + 1]\n",
    "          self.exp_replay.remember([[stream, next_stream], self.current_state, self.action_ids, reward, next_state], game_over)\n",
    "\n",
    "          # --------------- Load batch of experiences --------------------\n",
    "          inputs, targets = self.exp_replay.get_batch(self.model, batch_size=self.batch_size)\n",
    "          inputs, targets = df_to_tensor(inputs).to(DEVICE), df_to_tensor(targets).to(DEVICE)\n",
    "          # store pre-training value for td_error\n",
    "          old_Q = self.q_value()\n",
    "          batch_loss = self.__train_agent_batch(inputs, targets)\n",
    "          # store post-training value for td_error\n",
    "          new_Q = self.q_value()\n",
    "          self.loss += batch_loss\n",
    "\n",
    "          # --------------- Update with TD error -------------------------\n",
    "          self.epsilon.update_at_step(f'{self.asid}-{self.current_stream}', (new_Q - old_Q), len(self.stream_items))\n",
    "\n",
    "      # Track win history to later check if our model is improving at the game over time.\n",
    "      self.hist.append(self.win_cnt)\n",
    "      self.c_hist.append(self.c_win_cnt)\n",
    "      self.rec_list.append(self.rec_cnt)\n",
    "      self.ep_score_list.append(self.ep_score)\n",
    "\n",
    "      print(f'Epoch: {e}/{len(self.epochs)} | Loss {self.loss} | Epoch Hit Rate {self.win_cnt/self.rec_cnt} | Cumulative Hit Rate {self.c_win_cnt/sum(self.rec_list)} | Explore {self.explore} | Exploit {self.exploit} | Score {self.ep_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# parameters\n",
    "MAX_MEMORY = 1000  # Maximum number of experiences we are storing\n",
    "BATCH_SIZE = 2  # Number of experiences we use for training per batch\n",
    "EPOCH = range(100)\n",
    "TOTAL_ACTIONS = 1 # probability of ordering\n",
    "NUM_EPISODE = 100\n",
    "HIDDEN_SIZE = 512\n",
    "LR = 1.0e-4\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline(\n",
      "  (fc1): Linear(in_features=380, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (tanh): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Baseline(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Baseline, self).__init__()\n",
    "    self.fc1 = nn.Linear(380, 512)\n",
    "    self.fc2 = nn.Linear(512, 256)\n",
    "    self.fc3 = nn.Linear(256, 128)\n",
    "    self.fc4 = nn.Linear(128, 64)\n",
    "    self.fc5 = nn.Linear(64, 1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.tanh = nn.Tanh()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc4(x)\n",
    "    x = self.tanh(x)\n",
    "    x = self.fc5(x)\n",
    "    return x\n",
    "\n",
    "baseline_model = Baseline()\n",
    "print(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.   Time: 16:35:51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36652ea4067f4da2bb04c451dae2fdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 58, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'reward'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3575\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3576\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3577\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'reward'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-c8b69aa35f9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m           \u001b[0;31m# --------------- Load batch of experiences --------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_replay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m           \u001b[0;31m# store pre-training value for td_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-bbbee0032a00>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, model, batch_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Q_sa_ =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# r + gamma * max Q(s',a')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mstate_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mQ_sa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3121\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3577\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3578\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3579\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3580\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2742\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 58, placement implies 1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "exp_replay = ReplayBuffer(max_memory=MAX_MEMORY)\n",
    "epsilon = Decay(0.5, 0.85)\n",
    "dqn = DQN(baseline_model, exp_replay, epsilon, NUM_EPISODE, EPOCH, BATCH_SIZE, LR)\n",
    "dqn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "res = [a/b for a, b in zip(dqn.hist, dqn.rec_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1b48afe2e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAABjBElEQVR4nO2dd3hb1fn4P68lS97bcRzbWSRkbzMLZZQRKAQoLaPQQimlpaXQSeFLSym0pdAW6KADaAstFGihQPixV9gJGSRk72UnsR3vPeT398e9V5Zl2ZZsy3bi83kePZbOvffoXMk673nnEVXFYDAYDIZwiRnqARgMBoPh0MIIDoPBYDBEhBEcBoPBYIgIIzgMBoPBEBFGcBgMBoMhIozgMBgMBkNEGMFhMBgMhogwgsMwJIjIehE5eajHEQoRyRGRd0SkVkR+O9TjGShE5GER+fkgv+cSEbnafn6ZiLw6mO9viA5GcBgGHBHZJSKnBbVdKSLvOa9VdYaqLrGP3SYij3bT11Ei8qSIFIlIuYisEJHviYgn6LyLROQDEWkQkSUh+pkrIivt4ytFZG4Pt3ANcBBIUdXvh3vf3WHfu09E6uzHDhG5NuD4eBHRgOPO42L7+MMi0mK3VYjIayIy1Z6InXMbRaQ98Pr+jnugUdXHVPWMoR6Hof8YwWEYtojIt4F/Ac8D84Fs4DJgHPCeiKQFnF4B3Af8KkQ/HuA54FEgHXgEeC5Y+AQwDtigfSirICLubg59qKpJqpoEXAjcLSLzgs5Jc86xH08GHLvbvjYPKAb+Zk/ETp9nAfsCr4907AZDuBjBYRgSHK1ERBYC/wdcbK+U19jHTwauAo5V1UdVtVRV21V1s6regDX53+P0p6qvq+p/gH0h3u5kwA3cp6rNqvp7QIBTQ4zrYeAK4EZ7PKeJiFdE7hORffbjPhHxOuO0taEficgB4B+93buqfgxsBKaF+XEFXtsI/AeYG+m1Nlm2xlIrIm+LyDjngIj8TkT2ikiNrZWdGHDsaFvbqxGREhG5J+DYsba2VyUia7ozQQZrnbaW9Q0R2Wpfe7+ISMDxq0Rko4hUisgrgWM1DC1GcBiGFFV9Gfgl8KS9Up5jH/op8E1VrRKRG+zJebOI3CEiPwb+BBwrIqlhvM0M4JMgDeITuz14PFcCj2Gv8FX1deAW4FisyXoOcDTw44DLRgMZWJrKNb0NRkSOAo4EVoQx9uBrE4FLgW2RXmtzGXAHkAWsxrpXh+VY95gB/Bv4r4jE2cd+B/xOVVOAI7CEFyKSB7wA/Ny+7gfA0yKSHeZ4zgGOAmYDFwFn2v2eh7Wg+ByWpvku8HikN2uIDkZwGKLFs/YqskpEqrAm+rCwJ6uxqvqhiEwHbgQ+jTXBHAO4bSGwHpgcRpdJQHVQWzWQHOaQLgNut7WeMuBnwJcCjrcDP7W1mcZu+jjW/ixqgY+wTHBbg845GPiZiUigRvID+3OsBU4Iev9IeEFV31HVZiyBeJyIFADYml25qrap6m8BLzDFvq4VmCQiWapap6pL7fbLgRdV9UVbI3wNSyCeHeZ4fqWqVaq6B3iLDk3qG8CdqrpRVduwFhdzjdYxPDCCwxAtzlfVNOcBfDOCazOAEvv5TOB9Vd2hqjXAswHnFWDZ+3ujDkgJakvBmoTDYQywO+D1brvNoUxVm3rpY6n9WSRjaSgzsCbDQLICPzNV3Rhw7Df25zgeaKRjQg+JiPxfgKP8LwGH9jpPVLUOyzc0xr7mB7ZpqNoWUqlYmgnAV7G0pE0islxEzrHbxwFfCFoknADk9vJ5OBwIeN6AJeSdfn8X0GcFlnkxL8x+DVHECA7DcCDYCV0BjLKfrwOOF5GJIpIMnA94ROR6oFRV94fR/3pgdqD9HMs0sj7M8e3DmsgcxtLZlxKRE11VS4CngXMjuc6+dg9wA9akGt/Deb8McJR/I+BQgfNERJKwhPQ+259xI5a5KN0WUtVYkzWqulVVL8X6Xu4CnrLNZnuBfwUJvERV7RKkECF7ga8H9Ruvqh/0s1/DAGAEh2E4UAKMF5EYAHv1fkBEFqjqBuDXWDbu94A1WFFJ47HMJACIiMs2cbmBGBGJE5FY+/ASwAdcbzu6r7Pb3wxzfI8DPxaRbBHJAm7FitDqEyKSCVxA+IKrE7Y5aB9h+FNCcLaInGBHlN2BpQntxTLbtQFlgFtEbiVASxORy0UkW1XbgSq7uR3rczhXRM50vgM7YCC/L/cWwF+Am0Vkhv3+qSLyhX72aRggjOAwDAf+a/8tF5FV9vM7gL+KSJKq/k5V81R1jqr+EJihqt+zTVcOX8Iy4fwZONF+/iCAqrZgaSpfxpr0rsIypbWEOb6fY9ntPwHWAqvstkg4TjryKzZiTdDfDjqnSjrncXyvh/5+jRX55Y1wHP/GCjyoABbQIXxfAV4GtmCZ4poIMGsBC4H19vh/B1yiqo220HEc2WX2NT+kn3OLqj6Dpdk8ISI1WJrnWf3p0zBwiNkB0DBcEZEfYgmEW7Acpy1YQuGXwPdU9f0hHJ7BMGKJqsYhIgvtEMptInJTN+dcJCIbxCpB8e+A9ivs+O6tInJFQPsCEVlr9/n7ILu14TBCVX+NtSr/Glb46QHgZqwIJyM0DIYhImoah4i4sNTe04EirBjxS22btXPOZKx48FNVtVJERqlqqYhkYJkGCrEcjyuBBfY5HwHXA8uAF4Hfq+pLUbkJg8FgMHQhmhrH0cA2O4yyBXgCyxYayNeA+1W1EkBVS+32M4HXVLXCPvYasFBEcrHqBy214/j/iWW7NhgMBsMg0V1dnYEgj87OtSKs5K1AjgQQkfcBF3CbnUkc6to8+1EUor0LInINdtRJYmLigqlTp/b5RgwGg2EksnLlyoOq2qUKQDQFRzi4sTJ/TwbygXdEZNZAdKyqDwAPABQWFuqKFRFXdzAYDIYRjYjsDtUeTVNVMQHJRliCITjLtwhYrKqtqroTyycyuYdri+3nPfVpMBgMhigSTcGxHJgsIhPsZKNLgMVB5zyLpW1gJ1YdCezAiik/Q0TSRSQdOAN4xc4SrhGrGqdgxeU/F8V7MBgMBkMQUTNVqWqbnaH7Cpb/4u+qul5EbgdWqOpiOgTEBqzM3h+qajmAiNyBJXzACr+ssJ9/E3gYiAdesh8Gg8FgGCRGRAKg8XEYDAZD5IjISlUtDG43JUcMBoPBEBFGcBgMBoMhIozgMBgMBkNEGMFhMBgMhogwgsNgMBgMEWEEh8FgMBgiwggOg8FgMESEERwGg8FgiAgjOAwGg8EQEUZwGAwGgyEijOAwGPpJc5uPt7eUDfUwDIZBwwgOg6GfvLzuAFf8/SP2lDcM9VAMhkHBCA6DoZ9U1LcAUFbXPMQjMRgGByM4DIZ+UtvUBkB1Y8sQj8RgGByM4DAY+kltUysAVQ2tQzwSg2FwMILDYOgndc2WxlFpBIdhhGAEh8HQT2ocU1WDMVUZRgZGcBgM/aTOFhxVjUbjMIwMoio4RGShiGwWkW0iclOI41eKSJmIrLYfV9vtpwS0rRaRJhE53z72sIjsDDg2N5r3YDD0hvFxGEYa7mh1LCIu4H7gdKAIWC4ii1V1Q9CpT6rqdYENqvoWMNfuJwPYBrwacMoPVfWpaI3dYIgEJ6qq0piqDCOEaGocRwPbVHWHqrYATwDn9aGfzwMvqarJrjIMSxzneLUxVRlGCNEUHHnA3oDXRXZbMBeKyCci8pSIFIQ4fgnweFDbL+xr7hUR7wCN12DoE47GYUxVhpHCUDvHnwfGq+ps4DXgkcCDIpILzAJeCWi+GZgKHAVkAD8K1bGIXCMiK0RkRVmZqSNkiA6+dvVrHFXGVDUoqCrPrS72f+6GwSeagqMYCNQg8u02P6parqpOnYaHgAVBfVwEPKOqrQHX7FeLZuAfWCaxLqjqA6paqKqF2dnZ/bwVgyE09S3W5JXkdVPT1Eabr32IR3T4s2F/DTc8sZoXPtk31EMZsURTcCwHJovIBBHxYJmcFgeeYGsUDouAjUF9XEqQmcq5RkQEOB9YN7DDNhjCxzFT5afHAx05HYbosbaoGoCDdUbDGyqiFlWlqm0ich2WmckF/F1V14vI7cAKVV0MXC8ii4A2oAK40rleRMZjaSxvB3X9mIhkAwKsBr4RrXswGHrDyeEoyEhg04FaqhpayEj0DPGoDm/W7bMER2W9ERxDRdQEB4Cqvgi8GNR2a8Dzm7F8FqGu3UUIZ7qqnjqwozQY+o6Tw1GQngCYJMDBYG1xDdBRlXioaPO189bmMk6bNgrLADJyGGrnuMFwSFPr1zgsU5VxkEeXVl87G/fbgmOIP+vXN5bytX+uYP2+miEdx1BgBMchxv9WFfH6hpKhHobBptaO7PFrHP0Myd1RVke1Cevtlm2ldbS0tSMy9KaqfVWNAJTUNA3pOIYCIzgOMX7zymZ+8tw6fO061EMZEbyxsYRfvhgcs9GBY6rK92sc/Zv0L35gKXe+1P37jXTWFVv+jdl5qZQPseAoqbUExsERuIGXERyHEE2tPvbXNLG/uokPth8c6uGMCF74ZD8PvLOj29Wt4xzPS4tHpH8+jtqmVspqm1m6o7zPfRzurCuuJtHjYt7Y9CHXOEprLIExEqO7jOA4hCiqbEBtReO/K4qGdjDd8Je3t/PS2v1DPYwBw7Gjr9hdGfJ4bVMbMWLlcaTExfbLx1Fsmz52lTdQVjvyVrHhsG5fDTPGpJKV5KG+xUdTq2/IxuKYqEbid2UExyHE7nKrXNesvFReWX9gWNZGeuSDXTy7urj3EyNga0ktn/vT+0OywnTec/muipDHa5taSfK6ERHSE2L7Zaoqqmj0P1/ZjaAayfjalQ37apiRl0JGolVpaCjLvJTWOhqHERyGYYwjOL5/xpE0t7Xz/Jrhlzlb3dg64KUgXt1Qwqo9VXw4BCYcx47+0c5uBEdzG8lxsQCkJnj6ZaoqqrS+3xiBlbtDv99IZkdZHY2tPmblpZKRaH3m5fVDN2k7GocRHIZhzZ6KBhI9Lk46Mpupo5P578rhZa5q9bXT0OLz2/0HCidT+OM9g78Kr6xvQcSyrTe0dL2v2qY2kuOsdKi0+Nh+7QJYVNlIXGwM88amd2saixalNU3M+ukrw1rTWWs7xmfmpZKeYCVZVtYPjcbR0NLmD8U2Pg7DsGZ3eT3jMhMRET6/IJ81e6vYWlI71MPyU2Ovtgda43AmjNV7qwa0395oavVR3+Jjwdh02tqV1Xu6vn9doOBIiO3XvuNFlY3kpydQOD6ddcXVg2q/33SgltrmtiERzuGyrriGuNgYjshOIjPJEhxDlcvhOMaTvG6jcRiGN7vLGxiXaeULnD8vD3eM8OTyvb1cNXg4dZoGUnCU1zVTXNVIgsfFJ0XVtA5iEUHHfn7a9BxEYPmurpNqbXOr31SVFt9/53heWjyF4zJo9Smf2JrWYLC/2vKv7K0YvtverCuuZnpuCq4Y8WscFVGatH3t2qPgdsxU03KTqWpoHdT/y+GAERyHCL52ZW9lA2NtwZGV5OWzs3P5xwe7eGtz6RCPzsJx1g+kqcrRNi6Yl0dzWzubDwyehuXYz8dnJjB1dEpIB3ltUxtJXkfj8FDT1NbnHJuiygby0+NZMC4d6N4hHw2Kq6yJcG9lYy9nDg3t7cr6fdXMyksFrM9aBCqi5Bz/23s7+Mxv30Y19HdZYjvGZ4yxxjPU5U8GGyM4DhH2VzfS6lPGZST6235xwSymjk7mW4+t4pOiqqEbnI1jqqpv8dE+QAmKjn/jS8eNAwbXz+HYz9MTPBw1Pp1Veyq7lE0PNlVBx+cQCXXNbVQ2tJKfnkBGoocjshMH1d/gZEHvGaYax67yeupbfMywBYcrRkiLj41apN3yXZUUVzVS3xJa6yi1NY7pY1KAkReSawTHIcIeO6JqvK1xgGVf/ceVR5Ge4OGqh5f7z+kvjtkiUgLDg+tDOJL7wifF1UzMSmRKTjJZSV4+HkQ/h2M/z0j0cNT4DBpafF3qElnOcdtUZQuOvuw9Xmyv9J3y7IXjMli5u3LABHBvOIJjb0VDl1X24jX7OFA9tGU1nPd3SrsApCd6orbS315aB8DBbgRCaW0zXncME7OshdxI83MYwXGIsMsWCmMDBAfAqJQ4HrnqaNralR88tabLdTVNrf6icOGwYlcFx935Jv9dEbnvpKapQ3AMlJ9jXXE1s/JTERHmjU0L6aCOFs5qNiPRw9ETMoDO5qPmNh8tvvaAqCrL7t6XkNziKuv7zbMFx4Lx6VQ3trK9rK7vNxABjuBobmvvtHour2vm+sc/5sF3dwzKOLojUIg7ZCRER3A0t/nYVV4PdC8QSmqayEmJIyvJa58XehxtvnbufHEjuw7WD/g4hxIjOMJk04Ea3tkydFvQ7q6oJ9Yl5KbGdzk2aVQSZ8/K9a+SAvnbuzv53J8+CNvu/vQqK3nvzpc2Rezo7aRxDIDgKK21yqs4du25BWnsOFg/aBVoy+1Q3NT4WHJS4hibkdApn8MJx3QER6qtcfSlSGFRF43D8nP0NSx3b0VDt7knwbS3K/uqm5iSk2xdW9mhuW62o/aG2hTqRKul2/kbYAmRvmh3vbHrYAPOz6VnweElK9nb43nvbj3IX9/ZwQuHUTUFMIIjLNrblW//+2N+9PQnYV+jqpTWDpx6v6e8gYKMBFwxoev+Zyd5Ka9v6RLdsbeygcZWH+VhqNItbe28tG4/cwvSqG5s5e5XNkc0xprGDmFROwAOcqegnSM45o1NAwYvLLeyvoXU+FjcLutnctT4DFbsrvSbcpx7dJzjTqRPVWPkk1lRZSNedwzZ9gp2QlYimYkeloc5+TvsPFjPD/67hpN/s4RLH1waluZXXt9CS1s7x0y0tKpAP8cWOxhhbXH1kG6L62h/jlYHluCIRqHDbQELsO40idKaZkalxJHocREXG9OtScuporC73GgcI47XNpawtbSOg3XN3UZZBPP2ljKOu/PNAVNRd5c3MC4jodvjo1KsCac86B/dMTuUhuG8e29bGVUNrXz71Elccdx4Hv9oD2simKQDNY6BMFWtLapBBL9DdHZ+GiLw8SCZqyqCdvObMSaFivoWv3mkzq9xdITjQt+S0ooqG+xCidbCQEQ4cXIWS7aUha0tvrR2P5/57RKeX7OP+WPT8LVrWL4Jx0zlmOP2BpQ+2WJPok2t7WwpGRyzWSgqG1pI9rrxuDumrPRED5X1LWH/JsNlW2kdzr5MPWocyXGICFn2oi2Y+uY2Xl1vbYGwe4D8j8MFIzh6QVX501vbAGj1adj1oTbsr8HXrgOyOlZV9lQ0MC4zsdtznJVqsJbjJCqFs2fA4tX7SI2P5cTJ2Xz39MlkJ3n58bPhl3AP9HEMhKlqbXEVR2Qn+Vf0SV43U3KSO32mA51sGEhFXQsZCR2Cw8mh2W2vyJ2S6o6pKsUWHH3ycVQ2+v0bDqdPH01FfUvY0VXvbC0jJT6W9350Kt87fQoQ3vfuCI4JWYmMSvZ2yuXYcqCW0SlxAKwZQnNVZX0LaQFmKoDMRA9t7erfE2Wg2FZWR356PGkJsSEFR11zG/UtPnLsxVpWkjfkea9tKKGx1ce4zIRhG63WV4zg6IX3t5WzpqiaY201PtzoCefHF4ljujvK61uoa25jbI8ah/XjDg4LdARJSU3P425s8fHqhhLOnjUajzuG5LhYfnzOdNYWV3O/LTh7o6axlSw7o3cgTFWfFHXE7TvMG5vG6r1VvLu1jMsfWsbMn77CiijlO1Q2tJCeGCg4LMHtmB2cCcsRbK4YISXO3aeyI07WeCAnTcnG44rh1fUHwurjYF0Lo1PiyE72MjrV+n8IR+NwqvLmpcUzNqNjklNVNpfU8plpo0iNj41I+xxoKhpaOwlxICAJcGDNVVtLapmUnWQJhNqufTuhuKMCBEeocNxnVxczJjWO8+fmcaCmaUgr+Q40URUcIrJQRDaLyDYRuSnE8StFpExEVtuPqwOO+QLaFwe0TxCRZXafT4qIJ7jfgeT+t7YxKtnL1z99BBB+XRpH3d8wAILDUXPHZ3UvOLKTHY2j4x+4pa3d71Tszd/yxqYSGlp8nDtnjL/t3Nm5nD93DPe8tiWsyaumsZUxadaqub8aR0lNE6W1zV0Eh+N/+dLfPvI7bKO1mquobyEzQHAUZFh7bjjfhyMcU+I6VsLpiZEXOmxoaaO8vsXvGHdI8ro57ohMXttYEpY5pryu2R/l42gJJWH42fZVNZHgcZEaH0tBRoLfUX+gponapjamjk5mTkEaawYxkz2YqiAhDh0RVgNZdsTXruw4WM+kUUlkJXlCLhSdRVhOsvUZZyd7uswLB+uaeXfrQRbNzWN8VgKqHQEQhwNRExwi4gLuB84CpgOXisj0EKc+qapz7cdDAe2NAe2LAtrvAu5V1UlAJfDVaN3Dqj2VfLijnGs+PdE/IYarcTiT2YZ9Nf22we6psFa4YzO6N1U5K/3AlU9ZwFh70zgWr97HqGQvx0zI9LeJCL+6cDaz81P57pOre83arm5sJdde6fbXhOSYo2bndxYcn5mWw5kzcrjrwlm8eMOJADR0k6TVH1S1i8bhdbvITYnz58s4pqok21QFlp8j0npVwTkcgZw+PYfd5Q1sDRExF0x5fYu/hlO8x0VKnJuSMDSO/dWNjLH9KwUZCeyrbqSlrcOnMTknmbn5qWwpqQ1Z6LEvfFJUxV0vbwr7t1FR3+LXMByc72YgkwCLKhtoaWu3BUdoE5SzCHO0/KwkLxX1zZ1Mui98sh9fu3L+vDH+363zOz4ciKbGcTSwTVV3qGoL8ARwXn86FMtzeCrwlN30CHB+f/rsiT+9tZ20hFguPXqsf2LuLnoikDZfO/uqGkmJc1Ne39LvrNLd5Q2IWCve7vC6XaQlxHbSLEprQj8HWLO3ilN/s4Qv//0jfvniRpZsLuOzs3O7RG3Fxbp44EuFJHjdXP3P5T3+SGua2shK8uJxx/TL7tzc5uOeV7eQnexlZpDGkZXk5a9fKuTio8b6J5JIJjNfu4aVVFfb3EarT7uYR8ZlJvpj/OuCwnHBKq0eqakqOBQ3kNOn5wCWvbw3yus6O/NzUuI4EKaPw1kYFaTHo2q1ORFVR+ZYGoevXbskQPaV59fs489LtoetLVaGEByONjiQuRxORFWH4Ojat+M3cnwcmYke2rVz4uezq4uZOjqZqaNT/CbmgUrQHQ5EU3DkAYFZZEV2WzAXisgnIvKUiBQEtMeJyAoRWSoi59ttmUCVqjozRXd9IiLX2NevKCvrW/7Fl44bx63nTCfR6yY9wUOMhGeq2l/dRFu7cto060ffX3PV7vIGclPi8LpdPZ6XHWRrdcxWWUneLlFVH2wvZ8fBeg7WNvPw+7tobW/nwvn5IfsdnRrHA19awP6qJv7wZmh/h6pS09hKanwsSV53v0xV972+lc0ltdx94WziYru/53j7WCQax/n3v88Pn+o9rNoRkMHmkUBHZ21zG3GxMcS6On5GafGxEZuqiqocwdHVFJmTEsec/FRe7UVwNLX6qGtu85uqwPreDvSiaYJVpyovzVo9+ye5igY2l9SSnewlI9HD7Pw0gAHzczi/o3C2yW1us6oUZwQ5x9OjKTiyk8lO9lLX3NbFN1FS00yCx+X3bQXnchRVNvDxnirOm2tNTVlJHhI8Ln9QxeHAUDvHnwfGq+ps4DUsDcJhnKoWAl8E7hORIyLpWFUfUNVCVS3Mzs7u0+BOOjKbz9mTaUyMkJEYWnUNxnGMnzGj/4KjqdXH1tLaHiOqHEalhBYcs/JSukTX7KloICPRw4s3nMj6289kxS2ndVndBzJvbDrnzM7lyeV7OkVPOTS0+GhrV1JswdHXQocrd1fw17e3c8lRBZwydVSP58bECPGxrrAFR0V9C2uLq3l6VRFvbOx5InYmo8wgwTE2M4GDdVawgrX7X+fJLK0PuwAWVTbgcXXkcARz+vQc1uyt6jFCqjzEeHNS4no1VTW1+jhY18wYO7G0wBYceysb2FJS608KzE72kpcWP2A5NM7vaNmO3gMbnM8zLUjjSPS48LhiBtTHsa20juxkL6kJsSHNv2D9rkYle/2h0/7scduR/v62gwCcNs36/xURK+jAaBxhUQwEahD5dpsfVS1XVedbeQhYEHCs2P67A1gCzAPKgTQRcWwDXfqMJpazrPd/UifzdsaYVPLS4tm4P7KKrnsrGnjwnR1c/tAyZv/sVdYV1zA1N7nX67KDNIuymiZiBKblpnCwrrMNdm9Fg3+SiHXFkNnNpBXI1SdOpL7FxxMf7elyzBEmjsbRFx9HQ0sb3//PGsakxfPjc0K5w7qS4HGFrd044aTJcW5+/Oy6HsfomB2CNY7xAZFVtU1tpASYqcCpkNsaUYXcospGxqTFEdNNcufp00cD8HoPws6JLAr8HkenxFEW9L0H40RdOaaqnJQ4PK4Yy69SUsfknCT/uXMKUgcsJNeZjJfuKO/Vz1EZotwIWBNyhp3LMVBsLa1jUrZ1zx3lRDoLjpKaJr9/I/A8p5ryB9vLyUryMmlUx2d3uIXkRlNwLAcm21FQHuASYHHgCSKSG/ByEbDRbk8XEa/9PAv4FLBBrf+wt4DP29dcATwXxXvoRHZyeBrHnooGXDFCbmoc08eksGFf52iU7n4ojy3bzXl/fI8T736LX7y4kbLaZr587Dge/spR3HzWtF7fd1RKHGW1HUmKpbXNZCZ5yU2Lp13plD2+p6Khx/DeUMzMS+XYiRmWaSsoi9jJb0mJ67vgePyjvewqb+DXn5/jNwP0RqrLR2OYGseavVXECPzl8gUcqGni7pc3dXuuk0gZ7OMItFcH7v7nkBYfi2pkFXJDheIGcmROEmMzEliyuXuT60F70nKc4wA5qXH42rXHqgFODkeubapyxQh56fF8uL2cxlafX+MAmJOfxt6KxgExDR2sa8HjjmFfdVOnhMNQOO/nFJEMZCALHaoq20vr/BN+d3WoSu06VQ6Opuj89j7YXs7xR2T6NRLAH+Y8UEUrVTXs//toEDXBYfshrgNewRII/1HV9SJyu4g4UVLXi8h6EVkDXA9cabdPA1bY7W8Bv1LVDfaxHwHfE5FtWD6Pv0XrHoLpLsoimL0V1grS7YphWm4KOw/W+7/kzQdqmfOzV7vYiqsaWrjlGWsVfNNZU3n3xlN45buf5sfnTOfkKaM6Zcx2R3aSl+a2dv+GSo5KPcq2wTqRVW2+doqrGhnbg7O9O64+YSL7qpt4aV3n8Fyn3EhqfCxJcT0LjlV7KnludVdFcVtpHZmJHo47IrPrRbt3w9Kl8Pzz8Kc/wZe+BBMm8OYtZ7HogZ9DU+9O4DV7q5g8KplPTcriyuPH86+lu7vNAfGvcpO6+jjAKjpZ19zWKaIKOia3SPwcxZWNIR3jDiLCkTlJPYZzOoIuK7FD48ixv/eeHOSBORwOBRkJ/n1QjhwdIDgK0oD+JwL62pWK+mZOmWKZkJfu7NnP4WTiB2scVlusX3A0t/n4zG+X8J8+bm5WWttMbXNbh+AIUYdKVSmpafZ/tgAp8W48rhgO1rWwvayestrmLv/DYzMTaW5rD6uCQ2+0+dq5+pEVnH7v20NWBia8ZV0fUdUXgReD2m4NeH4zcHOI6z4AZnXT5w6siK1BJzPR4y874qwmVu2p5H+rirjjvJn+tsDV/PTcFNrVKhY3tyCNP761jZqmNtYUVfl/iNARWfPDM6ewcGYufcFJSCqrbSY13oqwGpXs9a+OrIirVPZXN+Fr104lqsPl1KmjmJiVyEPv7uDc2bn+e/ZrHPFukrxudpR1Lzj+9NZ2PtpZbjkPVXHqOzgbGflRhZdfhl/+Et57r3Mno0fDCSfwxujpfObNp+FTO+E//4EjQrvCVJXtW4v5RsNm+N3H3KQQt2EnH9yzgcIfXAwFBf5xAFTUt+JxxZDo6eycT46LJTPRw56KemqbWslOSoK2NvjkE8jNJdsWNOuLq5igDbBvH6SlQU4OxMURjN/HkNazEM9O9vaYR+FoFYEaR2AS4OzAuIeGBoiPBxH2VTWBKqOba2DVZpg6lYKA72BygLllVl4qMQKr91RxSvUu+M1vYO9e8HqtR2wsxMRYj4kT4dJLobCw0+cKllBuVzhuYibLd1WydEc5FxUW0B1+IZ4QSnB4WVdlfS5vbixle1k96/dV09lKHh6BEVXQ4S8KjKSsbW6jsdXXSeMQETLtnI8Pt1v+jeODBIdTLmh3eb3/e+kLqsrPnt/AG5uszds+2lnB8ZOy+txfX4mq4DjcyEr20tTaTkOLj0TblLJ49T4eXbqHLx07nin26qyossEfUTU919roZeP+GlLjY3nhk31AR+y+g7Py620C6YnAsiOTRiVRWtPMjNxUf9igo3E4zvtITVVgOaSvOmECP352HR/trOCYidYPxDHNpMbHkuh1U9fcvRq9o6yOmqY2qhtaSf3p/8Ef/gCJifzW58KXmAT/Hm1NtsXF1oRcUAB33w0zZsCoUZbQyMsDEf7x0DI+mnsSNz/5K5g3D6ZNA58P2tshM9O6NjeXpg+X8cbbS4htt8blxVJdAfjDjda58+bB3Lkwdy7JO1s5sbwGWZEFHo81nrQ0SE5mbGYCu21T1RFlu+D4a2H5cgBOSEzkvfh0Mu89CC1BK/3MTFi40NKWPvMZcLv9JWG6TCY+H1RWQm0tNDYyc98W1m7bh2/HEbgyMyAlpdOEXF7fgtcdQ0LZAfjvf+Hxx5m1di2L0/KJ37AA5k+FNWuscRYXWxP9qFFchJevlu7De7dtf/d6uXZmISlJk0hMiCP5Z+9Z40hOJnHMGL65u4zTv3M7bPgIMjJgwQJobobqakuAtrdbf196Ce69FyZNgosugvPOs4RITAwVZdUcs2ctRz3/Mb/YuIO2xQfglVy44go48cSugsZvqgohOBJi/ULz6VVFAGGXBQomWHDExbpI9ro71aEKzhp3cKwRH2wv92fgB+JoqnsqGvy/mb7w9/d38a+lu7niuHE8uWIvL68/YATHcCfQWeYIDqf8xIfbDzJldDL1zW0crGvxO57z0+NJ9rrZsK+G1XuqiHXFkBzn9odgOuwLYTKIlECNw9euHKxrZlSKl6wkLyId8eeOk66gD4ID4ML5+dz+/6xVj/MjCPRxJMe5qWsO/eNt9bX7339PRQOzTjkFXC60ro533t3CjGQhN0GhrMxaFf/jH/DFL1qTdwgSPC7ennIsN69aBTffbE1yLpc1+ZSVWRrLgQP4Csbz8FEXcMYt3+CIT80Dn4//fLiTJ/77Dv+Y6yZ103pYvdoSYs3NfMt5g78GvWFSEj+fPJfXx8zmuPo6rn3vcUhLtcxn7e3I1q24N+3giYMw+8R5LDh+pjWpHjhAy+ateF54Hh57zBJ+xxyDe1QBX9yjHN34Lty9A9atg/37oaqq09teZj94+AarYeJE+OlP4bLLwOXC+8lqHnzmj8gvP7Q0tfnz0a9+lZoX3mfS26/A80/C5Mlw0kmWcK2pgZIS9q/ZwcfjZ3H2hSdBbi4sW0bq4hf50cr3rfd5zQ3p6db5zc38AChPTKP9rruIufZaSO4maKOqCv73P/j3v+FXv7K0xtGjYdw4Jq1axZOt1v/HNJeLsvhU2rf4iPn732HOHPj2t+GSSyDRCkSoaGghyevGE8Jam55obddbUtPk9wH1pVYYwNbSWpK9br9pF6zFYqhE2lHJnQV9ZpKH0ppm9lU38pmpOZ38G2AtCF0x0i8H+VubSvn5Cxs4c0YOPz13BiU1zbyy/gC3nTuj28CKaGEERwT4kwDrmgPqFln/CB9sL+fKT03wR1Q5K46YGGFqbjLvbi2juKqRLx49lm1ldV01jspG4mJjQtpxwyU7qaNeVXl9M+0Ko5K9VtRUosdvX91T0YDbdt73hXiPi4L0+E7F8GoCCv4led00tbbT5mv3lyR32FPRQJvtINxT0cCss8+Gs8+mtKaJH/zyDe44fybTjh0X9lgSPC4aW30wfjw8/njok3w+7n1xE48u28PVZ58C9piOmONm1QdlLFu4gDO+b0Uu0doKmzZxxwOv442BG8840vKfVFdbk+G2beQ+/xI3fGyZzraceCZHPvVPSxOyyVHl//3lQ/5c0cCS804mPtbF/W9t4zd1W/jHkjs4ZftKePJJWLeOnJde5pctzZYncOJEmDULTjvNWs2np0NqKiQksLKkkQfe2sJPTxjDmPZGa0K+4gprUp44ke+/8AJ18Unwf/9naTRTphAD/DDvDT51RCa/OXcKxMdzoLqJu1/ZxHdPO5KCjAR+8NslTB2dzNmX2QGNF13Eru/eyuW/fokvf/oIvv8529SkClVVvPT6x3xnaRUvXHkGk5I7zFhdSEuDq66yHuXllgayeDHs38/2y67mztpsfnLbFTRnZLDw9+9zzzmT+dymd+B3v4Orr4bvfc8ydZ13HoWPvcDnli6BX2yy+p0wwXqMHs3JTW4O7mpi/Q/e5YZ1uxitTewpnQtfmg/uyKa3LSV1HDk6udOkn5Xk6WSqcqLQckJoHO9sKaNdu5qpwIpcHJMW168quQ+9t4OxGQncd/E8YmKEM2fm8PL6A6wuqmL+2PQ+99sXjOCIgCx/9ISlurb52v2CYtnOCnzt6o8QCVzNT89N4ZFdu3HHCNecdAS/e30LbwVFyOwLKPvQV1LirbLTZbXNfhNItr0yGpUc51ez91Q0kJce32VSj4SCjM7hhdWNrSR53bhdMX5trL7ZR2pC5/fYUdZRdmF3QAmGIvtz7MlJHIoEr5v6ILOYqvLdJ1fzhcICPjUpC1wu1tgFEwOT9abnphAj1r4fZ8ywBUdsLMyaxVvjyq39pD87v8t7Lrm6iN889BoZDTWcd9W5HBkgNMCyed981lQ+/5cP+cvbOyiubPSbUdaVNXPKBRfABRcA8Lc3t/DwU+/z8s/OIyU7o9v71F0VvFL8IV8852jGHJltTazPPAO33goffMCjZ3+VD87+In/61qmdrhuVEkdJbbOlvQHPrS7mf6uKWbq9nH9/7Vj2VTVy6pTO4z9iVCL5R+TxqXkTO8xGIpCezuSTjqJ55Tt8vKeyU7hpj2RmwuWXWw/g7Xd38OYLG7l3YgHJcW7SE2J5f18jn7v6avjqVy1/1kMPwT//CX/9K58FthZMge9+19J8du60tMPSUuZWVzPXfpuTJIZWbxxxS5+DNx+G73wH8vNhwwbYuBHGjoVvfMMSOsGfryqbD9Ry9qzO/sWsJC9bSjrC6dfvqyEuNqaLKSoryevf/MnvGPf5YOtW6/19Ps7fu5vqvW5YON5aFERAm6+dj/dU8fkF+cTbfrdTp+bgjhFeWXfACI7hTHC89v7qJlp9ynETM/lwRzkb99f4J9PAf6xptp/jgnl55KXFk5eWQFltM02tPn9mdHFlY7/MVGBNWE72uBMn75ivRqV4/QXv9vYhFDeYsRkJrAoo913T2EaqXVY82RYctc2t/l3xHHbYW6HGx7o6aSxOcEBBpIIj1tWl5EhNUxvPrt7H8l2VvP69k3C7hHX7qrnsmM6aTLzHxaRRSawLUUajvL6lW+1vXGYC+1JGsS9lFJfHhf4JFY7P4PTpOfz+ja0A3PCZyTy2bLffl+Wwv76V6qxckrN6/uE7RSz9q9+YGLjwQusB3H/nG3xqVNeV7ugUbydhvWpPJVlJXhpbfXz+Lx/Q1Nrexa+W4HHzwvUnhhzHxKwkUuLcrNpTxRd6cGj3xMG6FjyuGFLi3YgIR0/IYJkTWSVi+TlOPNHSPj78kC9/3IqMHs0jV3WNiflwwz6u/9ObNMV6+P7nFrC1tI6GZ57j3r1vWILG6XPsWMv38+tfwznnWMdOPtkvGEtrm6lubGXq6M6mt6wkLx9s74j6+mRXGYvaS3A/+i/L/7ZnD8yYwdyEAgqq4KTGYsbc/ga8/z6sXQuNHd/3950nD94E554LX/6y5etK6P23uOlALQ0tPhaM6/g/SY2P5fhJWby8/gA3nTW1X4vOSDGCIwIy/fWqLI3DqVl0ydEFfLijnA+3l1Nc1Uiix0V6wIT56SOzOWp8Ot8+dTLQsa/0/uomJtib3RdXNfkFTH/ITraSAP2F2OwJJyc5jg32BLm3spGFPWSJh0NBekKHgzshlurGVn9OgxOiGiokd0dZPZmJni4aiyM48tIiE2gJXjeNrT7a29Vv53WKDxZXNfLXd7Zz+vQcmlrbO0WxOcwck8q7dqavQ5uvnerG1h4ER0cWf3A4biA3nTWVvRUNfP2kiVwwL58lm0u7CI6SmiZyUuN6/dH7td0Q4eCq2qnAYSCjU+L8E5+qsnJ3FSdOzuLrJ03ksgeXAZEFZMTECHPHpvPxns57hGwrrcPrjgnLb3awrpnMJI//no8/IotX1pewvayOI7IDtJi0NDjrLHaufZMFIXI4ANIzkihLSifWJSyaX8CD7+7gP+MKuedfP0HWrrUc9VOnWpNzURH89a/wwANw6qlw/PHw4x/DwoVsCqjL5aelhckVRRz9yfu03fYhMe+9yyPvvE9iqx30EBcHY8bA00+zUJWFznVeLxx9tKXdzJkDM2eC18tTH2znf2+u4+HMA3j++yQ89ZS1AJg82TrvuOMsM+WMGV0CBJyw8UDBAbBwxmj+75m1bDpQ2zF/NDZaQm3FCuvxhz9AUpjaYZgYwREBsa6YTpu77LLtlcdMyGRidiIfbD9IjF1hNHAiGJMWz3+/cbz/taNZFFc2MiEr0R+S2V+NAyxBsbu8IcBUZQuOFCvqo7qhlYr6ln5rHAUBNY1mJaRS09Tq1zg6TFUhBMfBOiZmJzImLb7TBkVFlQ1kJXn8ani4JHpcqEJTm48ET2eBlZno4c9LtvuTFefa9ZYCmZmXyv8+LqY0IBvYca52JzgyEz0kelzUt/j8u/+F4ojsJF7+zqf9r/PS49kUVEVgf3VTWL6mRK+bBI8rZMHMuuY2WtraO+VwOOSkxlHb1GaVbq9r4WBdM/PHpTN1dApPXHMs972+lcLxkZk55hWk8Yc3t1p5LF43LW3tXPrgUtp87Tz3rRMYm9nz/9bBgPLvYJXm+eni9by0dj/X2YurQCrrW7tk8Ds4IbqnTh1FRqKH1PhYWn1qRT7Ont355Px8uOMOuOUWK+jiV7+Cs8+GsWOZOHo8t/rSmNv2NmzbYpm2tm/nyz4fXwb0GaFp6nT+O+s05l58NnMXnWJFjLndUFvL+v/3Fo8+8hqfvfQ0TrhkoSU8gkjUTD7Y4Wbr9Scw47574PXXrdykNWtg2TIrnBysIIJPfcoSODNmQEICCU+9y8+37SDvm49aQR+lpVBdzcXNLSysaSDhjwqiVlRbU5P1Fyzf2w9+YPUzgBjBESGBSYC7D9YTFxvDqGQvxx+RyTOrislJieOIXmy/jh2/uMoSPPsGIBTXITvZy/JdFZTWNpOWEOsvjJidEke7wqq91mTdlxyOQMYG1DSalZ9KTWOrX5g4Wd+hNnPaUVbPadNyGJXi5fk1+2j1tRPriqGospG8PowpwdNR6NARHM77/mjhVG5dvI4/LdlOekJsyOrCs+yy7WuLq/mMLTj8BQ5DhH+CXXsoM5GN+2u6ZI73RF5aPG9sLO2UB1RS3cSxoRIeQ5CdHHrDoHJ/uZHQGgdY0UDO/iXz7b3bJ+ckc/9lXX04vTFvbBrtCp/sreL4SVm8uuEAZbXNeFwxfPWR5fzvm8f3KFAP1jV3qsuVmxrPgnHp/L9PugqOlrZ26prbQuZwgPV7/OIxY/ni0WMB/IuX6sZW/wKmC3FxcO21lj/l0UfhtdeQZau5tOgj4te8CEceCbNnw0UX8UliDj/Z0MIvb/4CyyvauO35DXz49VMhNeB/KTmZaRefy3HTCzl25mh/8EUwjkDdU97AjDGpcNZZ1sNh92544w147TVYudKKSrOrQFwEtMZ6kP0FljCYOBHS0nB5PCzfXE6jCucXjrU0mMREmDePtnnzicnPJ6YfvszuMIIjQpwkQLBMVeMyEomJEY6bmMWjS/ew42B9r8X5RqfGESMduRz7qizVN3jr0L4wKjmOyoZW9lU1dgordDJdV+6yBEf/NQ5rrI65yamMCx2CI9hUVd3QSnl9CxOzE0m3S1Hvq2pkXGYieysa/HuLR4IjLBqafWDLa6fA4pGjk7n2pEnc+/oW5hSkhTQHTc9NQcQWHHbuTaiCgcGMz0ywBEeYpVHAEhzNbe0crGshO9mLr10pqW0OO7otuPqxg+NzC6UhOYlqB6qbWLm7kkSPq1MZkb4wr8DSUD62Bce/PtxNQUY8d14wmyv/8RHXP/4xD11xVJcS/Q4Ha1uYOrqzWfbsWbnc8f82sKOsjokB5qoqO/kvrZvvIiZG+OUFHbnCgYKj14WYx+OP/Lr2D++RGufm0a8UdorGat1dyZo/f0CpePl470FGp8SRm9q135gYYVHAJmihcH5zq4uqOCvICQ/AuHEdkWhgmZw2bqTsYA1nLy7imxcfx1dO7Jrgun3JNu5+eTMn33p6p1yXtzaUcP1tr/LMt47v8nn3l6GujnvIkZXs9a/wdpU3+Hflc7aWhd4dvLGuGEanxPnt+o7mMRCmKsc0tWF/TadYc2cCWW7bSvsrOJLjYklPiPULjurGVv9OeI7dP9hUtf2g5RifmJ3kz6R16vcUV/VcdqM7HI2jPsBB7oQGJ3ndfP2kicwbm8ZZM0eHvD7R62ZiViLrijsc5N2VVA/EWT32tLIOxqlH5fg5yu0ChKNTwhQc3dRKc2opZYUoVJnj1ziaWLWnkjkFaf2KpgNITYjliOxEVu2uZGtJLct2VvDFo8dxwuQsbls0g7c2l3Hva1tCXmv5Y5q7jPXsWdb38+La/Z3aK3rIGg9FWoDgCBdfu7K1tJYpuSldQnizA3xLq/dWMTeEnyxckuNi+ezsXP7x3i62lXZf+PSe17bw5yXbrUi4+fP5MOdIypLSKZwQOtHP8W04G285bNpfQ2Orr8c6aH3FCI4IyU7y+iuO7ilv8FdLzUzy+iMyerPxgqVdOEmAxVVWFdv+lCJwcLSM/dVNnTQOJ7pqTVEVKXHuLtFOfWFsRgJ7Kxpo87VT3+LronEEm6qc6J6J2Yn+z2h3eQOltc20+vpWAiXBfq/A0uqOppMc5yYu1sUz3/wUFx81tts+Zualsq64o5xHRTfVWAM5Zcoojp2YEdI81B2ORulomvvtnIDRIVawochK8oZ0jvdoqrL/p3YcrGfj/toBC9ucNzadj/dW8ejS3XhcMVxUaNU0ufzYcXxm6iieDVGLDKzou1af+nOiHALNVYE4darSE8P7f03pg+DYU9FAU2t7SE3M+Uy3ltSyu7yBebaZr6/cdu4MEr0ufvjUJyGrFje2+Pjr29v5zaub/RGIq3ZXEh/r6rZCtjPuzSWdhdGmklrGZiSEXTA0EozgiJCsJA+1TW3sLq+nxdfeKcLGid8OZwLMS4v3TyDFlY3kpMR1yjHoK9kBwiI7IEnJyR5vam0PS7CFQ74tOJyiiinx1j+oU98p2FS1o6wOd4y1N0FOslW+e29FQ59zOALfKzAktzbEznw9MSsvlQM1TX4zUGUP1Vgdjp2YyRPXHBfRd5YX5Ntyig9GonFUNbTS3NY5b8UpuRFK0CV5rYTMV9cfwNeuXaJy+sr8selU1Lfw+Ed7+ezs3E7l3OePS6eosjHkvi2O4Av8P3X47KxcNh2o9U+YEFDePkyNw2+qCtoTpbyu2R9tF4yzJfKU0V0n5kSvm/hYF69vtGpD9UfjAOu+b1s0g4/3VPGP93d2Of7+toM0t7XTrspvXt0MwIrdFcwtSOv2fy03NY5kr9u/Y6PDpv01Ie9pIDCCI0IcFduJCBofMAl/8eixXHr0WH+IbU/kpcdzoKbJrlTbMCCOcehcQyfQVGVlj1vH+mumchibkUBxVaP/x+38aN2uGOJju+6TsaOsnrEZCcS6YoiJEfIz4tlT0RCwdWrk44oPcI471DW14bI3eQqHGWMs38o6u/x9eX0LyV53rzsuRopTjsVZMPizkFN73wsFOibb8qAy3+X1LSTHdT/enBSvP9y0vytmB6efFl87lwdl+k+zV8bBExl0VJoNZVY7K4S5yql8G25FBUeTDtY4rnp4OT9dvD7kNU6CX+DeI4FkJXvYebAeV4z4gyn6w6I5Y/jM1FH85tXN7DrYeR/yNzaVkOR1882Tj+DFtQd4f9tBNu6v7THyTUQ4cnRyJ42jqdXHzoP1TDOCY3jgrKxW2XHs4wKExOScZO783KywbMh5aQl+5+i+qqYB8W8AfuEAdDJVBb7ua42qYMZmJNDqU/8EkRJg7w9VWt0JxXUYl2EVC+yfxuGYqgI1DiuLPdyEqBl5lo142Y4KHl26m1fXl3Qppz5Q5KXF+30cB2qacMdIyDDaUATu+xBIcHhrMI6f44jsxJCFAvvCkTnJJHpcTMtN8UdpOTiO2I0hdr7sSXDkpsZTGGSu8jvHwzStJnvduGKki+DYebDeX8QwmM0HLJOOE2gRjDPWKTnJ3Z4TCSLCLy6YRWxMDHe/0rEnTHu78sbGUj59ZBbfPHkSWUlebnji47A0xSNzktlSUuvfi2dbaR3tClMG2CnuYARHhDi22RW7KvG4Y8gN08wQjGO22FvRwH673MhA4HF31LsKFhxOfZ2B0jgck5yzUg/0myR53Z18HL52ZVd5Q6eIGcdHsreikawkb4/7i3dHgtd2jgeUHam18wvCJSUulglZifzl7e38+Nl1pMbHcsvZvW+c1Rfy0+P9GtaBamtDoHAL1GWH2B8CrFV5TxFgjilsIMtSuGKEey6ey90Xzu4ioHNT40iJc7MxlMZR6wiO0OM92zZXbbfNVRX1rSR6XGFrfyJCSpy7k+BoavVR09TWpT6cw+aS2h5NOo7gGChtDSzf0+XHjePldQf8Wse6fdWU1jbzmak5JHrd3HDaZA7WtSBi+ZR6YkpOElUNrf5FxaYezG8DgREcEeL8E20trWNsRkKfq1I6GsbqvVW0+nRAQnEdnJXpqCCh5qw8B9JUBfgjkjppHF53J1NVcWUjLW3tTAzQ0AoyEqhtbmNtcXWftA3oCMcN3A0t1M58vfG1EydycWEB//vm8bxw/QkdtasGmEDf1oHqpogCIpyNhYI1jvK67sujgJUECJbvYSA5c8bokKYbEWFabgqbQmocLcRI6BLp0GGuesk2V1U2tPQY3RaK1PjYToLD+bzK61u67JrX3GaZdHoKUXZ+8/31bwTzlePH446J4aH3dgDw+sZSYgR/OP8lRxUwMSuRaaNT/Gbg7nA23HLMVZsP1OB1x3QypQ8kRnBESKBTrz9fiiM4lu+0wmPzB0jjgID6VN2ZqgYoPC83LQ5XjPgjkgL/uYO3jw0MxXVwAgs27K/ps+Bw/BiB4bh1fRAcXzxmLHd9fjbzx6ZHteZPXno8tc1tVDe2UlLTFLZjHDpW6V0ER31zj3vGO/9rhQMsOHpiWm4Kmw7Udtkq9WBdMxmJ3m5zPJzoqhfXWjtMVja0hO0YdwgWHIG77u2r7qx1bC+tx9euPa7Mnc25elv1R8qolDgumJfHf1cUUV7XzBsbS5g/Nt2/CIh1xfDY147hr19a0Gtf/sgqW9PYdKCWyTlJ/Q697g4jOCIkLtblN4MERlRFSrzHRVaSx59XMVCmKrA0jgSPq0vm7ClTR/HZ2bl9nqSDiXXFkJsa50+Yc6KqgC6bOe0MCMV1CNR8+up3ccUIcbExnZzjtc2tEeVXDCZOLa7iykb2R6hxeN0uUuNjO4XkWtuwtnRr+gGruObfrihkcj8T/yJh6uhkGlp8/urRDpY/pmdBcNbM0WzYX8Oug/VU1keucaTEx3bak6OstmNDrWBzleMY70lwfHb2GL5+0sRO2vJA8bVPT6C5rZ27Xt7E+n01nDY9p9Px3NT4sH4bmUlespI8bLVzOTYdqB3wpL9Aoio4RGShiGwWkW0iclOI41eKSJmIrLYfV9vtc0XkQ3s/8k9E5OKAax4WkZ0B18yN5j2Ewont7q8amJcW7w9lHZPW/xwOhy8fP57bzu1am2be2HTu/+L8AV2FOJN/rKtzFFPwZk47DtaREufuZIsPLAHSH2GW6HF3co7XNUXm4xhMHJPkRjs5KxKNA7qWHamyt2HtyceR6HX7s+IHi2n+nS87+zmcrPmecLKqX1y3n8qGVjIizDlKS/D4d6SEzhpacJHJTQdqiXVJj5GQU0Ync/NZ06KyWdKkUcmcNi2H/6ywyu6fNq3nqhM9cWSOFVlVXmdVxw6u9DuQRE1wiIgLuB84C5gOXCoi00Oc+qSqzrUfD9ltDcCXVXUGsBC4T0TSAq75YcA1q6N1D93h2Dz7o3FAxySSEuce0BXy3II0LjqqbyWvI8URHClxsZ1MPElet7/0B8CWA3VMGpXU6ZwEj9s/ifQnuzXB67JKjtj0xccxWDhmo5V2VF6kSZ9ZSZ5OE6G/PEoPpqqh4MicZERg04HOfo7eIsDA+ozmFqTx4tr9VNa3RBwJlhrv7mKqihGIkY66cA5bSmqZmJU0IDlUfeXrJ00ErHL9naoDR8iROclsLan1C+tDVeM4GtimqjtUtQV4AjgvnAtVdYuqbrWf7wNKgeyojTRCHFU7nHyNnnAmkb4U9xsuOGp0sPMuMWCDpfZ2Zf0+ayOlYBzB0x+NIyHWHWSqauux3PlQkpXkweuO8dcMi1RwZCfHdYqqcp5HksE+GMR7XEywC0E6qGpYpiqwSpCsK66htrkt4l0xHR+HE5paWmP5gEanxHUxVW0tre02f2OwKByXzoXz87nqUxP65V+bMjqZ+hYfb2wq8b+OFtEUHHnA3oDXRXZbMBfa5qinRKTLMllEjgY8wPaA5l/Y19wrIiGXLyJyjYisEJEVZWVloU7pM9nJXmJdfd961cEvOAbQvzHYOIIjOUhwJMe5afG109zmY8fBeupbfMzsQXD05zNI8Lr8zvHmNh8tbe2dIryGEyJCXlo8W+xaRRGbqoIKHZb3UKdqqJmam+wPCwWob/HR1Noe1ljPmtlRBDA9QlNVanwsvnal3l5MlNU1MyrZ26nMD1i5P0WVjUweNXi+n1CICL+9aA5XHD++X/04e4n8v0/2k5no6dUk2B+G2jn+PDBeVWcDrwGPBB4UkVzgX8BXVNUuMM/NwFTgKCAD+FGojlX1AVUtVNXC7OyBVVa+8qkJ/O6Sef32FTiaRt4A+jcGG6egY7DG4a+Q29TG2uIqAGaH2A9j0ZwxXH7s2D7lcDhYPg6f//0C3384kpce71TL9odIh0t2spf6Fp8/1LmnciNDzbTRKewub/CP1cnhCMesVpCRwGw71Lcv4bjQkTxYWmvVbctLi+9kqtpRVo9q9xnjhxpH2vdRVtvcbV2rgSKagqMYCNQg8u02P6parqrO8ukhwB93JiIpwAvALaq6NOCa/WrRDPwDyyQ2qByRndRlb+K+0GGqOnQ1jg4fR+eJOnDf8bVF1j7NR2R3Ne2dMnUUPz9/Vpf2SIj3uPyCI9I6VUOB871nJXnwuCP7CQYnAVbUWwlikYasDgZTbQe5o3V0ZI2HN1bnNxZ5OK51vuPnKKttJtvWOA5UN/mLC24tdXb9OzwER3JcrP9/a0pO9PwbEF3BsRyYLCITRMQDXAIsDjzB1igcFgEb7XYP8AzwT1V9KtQ1YhkDzwfWResGos2kUUl8fkE+pw1yxMtAkpHoISXO3cX84K+Q29zKuuJqpuemRC2mPNHTse+4kzsyrDUO+8cdqbYBXXM5iqoayUjwdJsXMZQ4UT2Og7ynciOhuLiwgCuPHx9xxnvgnhy+duVgXQujkuMYkxZPW7tSYheX3FpiFd3sb5DLcMIRgtHWOKL261LVNhG5DngFcAF/V9X1InI7sEJVFwPXi8gioA2oAK60L78I+DSQKSJO25V2BNVjIpINCLAa+Ea07iHaeNwx/OYLc4Z6GP1CRHjs6mO7FOpzJu6axjbW7avmosLoRXnFB5iqnIqswzWPAzo0zL74yAI1jgPVTbzwyX7O7WUDoaEiPz2eZK/bv11ume2PCdf2np7o4bZFkW956giOmkZrm2Rfu1oah7Nlc5VV4mdLSR0TshKHNKJqoDlydDJvbS6LaiguRHkHQFV9EXgxqO3WgOc3Y/ksgq97FHi0mz5PHeBhGvpJqLITTlTT2uIqGrpxjA8UiR4XDbamUXcImar6onFkB5Qduf+tbfjalRs+03Wf7uGAiDA1N5nXN5aQFOf2ZzVH2x8TWCHX0cxGJXv9kXuOn2NbaS3Tx0TXpDPYnDljNBv391x7ayA4fEStYVjhaBwfbC8H8Ds6o0GC101Dqw9V9fs4hrWpyp7AIo2oAqv6cYxY27Y+sXwPFx1VMGDVjqPBRYUFeN0xPPTuDt7cVEp+enzUV/gdzvFWSu2s8VEpXn91hqLKRppafeypaGDSEEdUDTTzx6bzz6uOHvAtAYIJ69clIjlYUUwAH6lqafSGZDgccCbu5TsriI919SuxqTcSPC5UrU2qAnf/G67kpcVz48IpnDs7chOTK0bISPTwv1XFeNwxfPvUSVEY4cDxhcICvlBYgK9dOVDTRFyEwQB9IdHjwm2XVnfqVGUnxZHgcZOeEEtxVSM7yuppV5g86vBwjA82vX6LInIR8BHwBSzfwzIR+Xy0B2Y4tPHvO97iY8aYlKg6bxMD9h13dnkbrgmAYJlwvnnypD5rCo5z+bJjxpIb5razQ40rxspfGYwMdxHxJwH6TVV24c+8dCsk14moOlxCcQebcH5dtwBHOVqG7Zh+HXiqx6sMI5qEWBcioEpU/RtgOccBGpp91Da34XHHRF1VH0pGpcSxu7yBa08+YqiHMmxxBEesK8a/9zxY2t6OMmtTJ1dMzzWqDN0TjuCICTJNlWN8I4ZeiIkREj1WafVo+jcgYN/x1jarTtUw9m8MBN87/UiqGlo6bQ1s6EyKv+xI5yiuvLQE3t16kC0ltYzLTDisFxjRJJxf2Msi8grwuP36YoIipQyGUDh7coSqUTWQJAQkG/ZlL45DjYHeUOhwJDU+lsqGFppafZ32pRmTFkdDi4+Vuyt73Y7V0D29/sJU9YciciHwKbvpAVV9JrrDMhwOJMW5SWhyddq8KRok2BpHY4uPumFc4NAweKQlxLKr3NoDJrDUjROSe7CuZchrVB3KhPULU9WngaejPBbDYUZmooespOhnNScEOceTvcM3+c8wODg+jpa29k4ah7ORFhjHeH/oVnCIyHuqeoKI1AKB+z8KoKp6eGXOGAac33xhTlQ2vwkm0XGOt1g+juGc12AYHFLjY6lqsCLsgk1VDpNMKG6f6VZwqOoJ9l+jzxn6xGBN4I7G0dDiG9abOBkGj8BqzYHO8YxED3GxMbS0tUc1t+hwJ5w8jn+F02YwDBWOc7yh2fJxHO5RVYbeSQkQHIHRZ85+KGMzEvpVyn+kE84vrFOVMRFxE1D+3GAYapy9zutb2izBMYwLHBoGh7RAwZHSOelw0Zw8hmEx4UOKnnwcNwP/B8SLiLP/owAtwAODMDaDISxcMUJcbAzldVYlVBNVZehkqgrKVr/htOFZFPJQoltTlareafs3fq2qKfYjWVUz7aq2BsOwIdHj9u+zYHwcBqdCbqxLSItw61lD74STx3GziKQDk4G4gPZ3ojkwgyES4j0uSuy6RMO5Mq5hcHA0juwkL9aeb4aBpNdfmIhcDdyAtfXrauBY4EPA7IthGDYketyUVFsaR4rxcYx4/IKjD6XrDb0TTs2pG7BKqu9W1VOAeUBVNAdlMERKgtdFmb01qfFxGOJjXXhcMZ1yOAwDRziCo0lVmwBExKuqm4Ap0R2WwRAZCR4XvnYrT9WYqgwiQkFGvMnViBLhCI4iEUkDngVeE5HngN3hdC4iC0Vks4hsE5GbQhy/UkTKRGS1/bg64NgVIrLVflwR0L5ARNbaff5ejAHTACR4OoSFcY4bAJ6+9ni+YyKookI4zvEL7Ke3ichbQCrwUm/XiYgLuB84HSgClovIYlXdEHTqk6p6XdC1GcBPgUKscicr7WsrgT8DXwOWYVXpXRjOeAyHN072OGBqVRkASEuI7t7mI5mI9tVQ1beBJsIrq340sE1Vd6hqC/AEcF6Yb3Um8JqqVtjC4jVgoYjkAimqulRVFfgncH4k92A4PAnUOIyPw2CILt0KDhE5VUS2iEidiDwqIrNEZAVwJ9aqvzfygL0Br4vstmAuFJFPROQpESno5do8+3lvfSIi14jIChFZUVZWFsZwDYcyzmZOCR5X1KvxGgwjnZ40jt8C1wCZWNvEfgg8rKoLVPV/A/T+zwPjVXU2llbxyAD1i6o+oKqFqlqYnZ09UN0ahimOqcr4NwyG6NOT4FBVXaKqzar6LFCsqn+MoO9ioCDgdb7dFvgG5arabL98iI4aWN1dW2w/77ZPw8jEKXRoIqoMhujT068sTUQ+F3hu4OswtI7lwGQRmYA1uV8CfDHwBBHJVdX99stFwEb7+SvAL+2MdYAzgJtVtUJEakTkWCzn+JeBP/QyDsMIoEPjMI5xgyHa9CQ43gbODXj9TsBrBXoUHKraJiLXYQkBF/B3VV0vIrcDK1R1MXC9iCwC2oAK4Er72goRuQNL+ADcrqoV9vNvAg8D8VjRVCaiyuB3jhtTlcEQfXrayOkr/e1cVV8kKAJLVW8NeH4zELJgoqr+Hfh7iPYVwMz+js1weJFofBwGw6ARUTiuwTBcibcFh/FxGAzRxwgOw2FBotcxVRkfh8EQbcLZOrZLlbBQbQbDUJJgNA6DYdAIR+P4MMw2g2HIMM5xg2Hw6Gnr2NFYWdnxIjIPa9tYgBQgYRDGZjCETXayl9T4WCbnJA/1UAyGw56elmdnYoXH5gP3BLTXYu1FbjAMG5K8btb89IyhHobBMCLoKRz3EeAREblQVZ8exDEZDAaDYRjTk6nqclV9FBgvIt8LPq6q94S4zGAwGAyHOT2ZqhLtv2YLLYPBYDD46clU9Vf7788GbzgGg8FgGO70ZKr6fU8Xqur1Az8cg8FgMAx3ejJVrQx4/jOsrVwNBoPBMMLpLaoKABH5TuBrg8FgMIxcwq1VpVEdhcFgMBgOGUyRQ4PBYDBERE/O8Vo6NI0EEalxDmFtK5sS7cEZDAaDYfjRk4/DFP0xGAwGQxeMqcpgMBgMERFVwSEiC0Vks4hsE5GbejjvQhFRESm0X18mIqsDHu0iMtc+tsTu0zk2Kpr3YDAYDIbORG3zAhFxAfcDpwNFwHIRWayqG4LOSwZuAJY5bar6GPCYfXwW8Kyqrg647DJ773GDwWAwDDLR1DiOBrap6g5VbQGeAM4Lcd4dwF1AUzf9XGpfazAYDIZhQDQFRx6wN+B1kd3mR0TmAwWq+kIP/VwMPB7U9g/bTPUTEZFQF4nINSKyQkRWlJWV9WH4BoPBYAjFkDnHRSQGa4Oo7/dwzjFAg6quC2i+TFVnASfajy+FulZVH1DVQlUtzM7OHsCRGwwGw8gmmoKjGCgIeJ1vtzkkAzOBJSKyCzgWWOw4yG0uIUjbUNVi+28t8G8sk5jBYDAYBoloCo7lwGQRmSAiHiwhsNg5qKrVqpqlquNVdTywFFjkOL1tjeQiAvwbIuIWkSz7eSxwDhCojRgMBoMhykQtqkpV20TkOuAVwAX8XVXXi8jtwApVXdxzD3wa2KuqOwLavMArttBwAa8DD0Zh+AaDwWDoBlE9/OsXFhYW6ooVJnrXYDAYIkFEVqpqYXC7yRw3GAwGQ0QYwWEwGAyGiDCCw2AwGAwRYQSHwWAwGCLCCA6DwWAwRIQRHAaDwWCICCM4DAaDwRARRnAYDAaDISKM4DAYDAZDRBjBYTAYDIaIMILDYDAYDBFhBIfBYDAYIsIIDoPBYDBEhBEcBoPBYIgIIzgMBoPBEBFGcBgMBoMhIozgMBgMBkNEGMFhMBgMhoiIquAQkYUisllEtonITT2cd6GIqIgU2q/Hi0ijiKy2H38JOHeBiKy1+/y9iEg078FgMBgMnXFHq2MRcQH3A6cDRcByEVmsqhuCzksGbgCWBXWxXVXnhuj6z8DX7PNfBBYCLw3s6A0Gg8HQHdHUOI4GtqnqDlVtAZ4Azgtx3h3AXUBTbx2KSC6QoqpLVVWBfwLnD9yQDQaDwdAb0RQcecDegNdFdpsfEZkPFKjqCyGunyAiH4vI2yJyYkCfRT31GdD3NSKyQkRWlJWV9fkmDAaDwdCZqJmqekNEYoB7gCtDHN4PjFXVchFZADwrIjMi6V9VHwAeACgsLNR+DtdgMBgMNtEUHMVAQcDrfLvNIRmYCSyx/dujgcUiskhVVwDNAKq6UkS2A0fa1+f30KfBYDAYokw0TVXLgckiMkFEPMAlwGLnoKpWq2qWqo5X1fHAUmCRqq4QkWzbuY6ITAQmAztUdT9QIyLH2tFUXwaei+I9GAwGgyGIqGkcqtomItcBrwAu4O+qul5EbgdWqOriHi7/NHC7iLQC7cA3VLXCPvZN4GEgHiuaykRUGQwGwyAiVnDS4U1hYaGuWLFiqIdhMBgMhxQislJVC4PbTea4wWAwGCLCCA6DwWAwRIQRHAaDwWCICCM4DAaDwRARRnAYDAaDISKM4DAYDAZDRBjBYTAYDIaIMILDYDAYDBFhBIfBYDAYIsIIDoPBYDBEhBEcBoPBYIiIIduPY6hpbW2lqKiIpqZeNx40DBFxcXHk5+cTGxs71EMxGAwBjFjBUVRURHJyMuPHj8feD8QwjFBVysvLKSoqYsKECUM9HIPBEMCINVU1NTWRmZlphMYwRUTIzMw0GqHBMAwZsYIDMEJjmGO+H4NheDKiBYfBYDAYIscIDoPBYDBEhBEcQ8iuXbuYOXNml/Zbb72V119/HYD77ruPhoaGTsdramr4yU9+wrx585g3bx6XXHIJ69ev73TOLbfcQkFBAUlJSZ3am5ubufjii5k0aRLHHHMMu3btGtibMhgMhz1RjaoSkYXA77D2HH9IVX/VzXkXAk8BR6nqChE5HfgV4AFagB+q6pv2uUuAXKDRvvwMVS3tzzh/9vx6Nuyr6U8XXZg+JoWfnjujT9fefvvt/uf33Xcfl19+OQkJCQBUVFSwcOFCrrrqKj744APi4+NZuXIlV199Nffeey/HHnssAOeeey7XXXcdkydP7tT33/72N9LT09m2bRtPPPEEP/rRj3jyySf7eJcGg2EkEjXBISIu4H7gdKAIWC4ii1V1Q9B5ycANwLKA5oPAuaq6T0RmAq8AeQHHL1PVw2ITcZ/Px9e+9jU++OAD8vLyeO6557j22ms555xz2LdvH/v27eOUU04hKyuLt956i+9///v87Gc/46yzzvL3sWDBAhYvXsyFF17IO++8A+AXIME899xz3HbbbQB8/vOf57rrrkNVjSPaYDCETTQ1jqOBbaq6A0BEngDOAzYEnXcHcBfwQ6dBVT8OOL4eiBcRr6o2R2OgfdUMBoKtW7fy+OOP8+CDD3LRRRfx9NNP+49df/313HPPPbz11ltkZWVRV1fHzp07Oeuss1i2bBnXXXcdWVlZ5Obm8rOf/Yz58+ezatUq5s+f3+37FRcXU1BQAIDb7SY1NZXy8nKysrKifq8Gg+HwIJo+jjxgb8DrIjprDYjIfKBAVV/ooZ8LgVVBQuMfIrJaRH4ih/hSecKECcydOxewNIeefA4bN25kwYIFANx44408/fTTPPbYY7z55pv4fD6mTJnC9u3bB2HUBoNhJDNkznERiQHuAb7fwzkzsLSRrwc0X6aqs4AT7ceXurn2GhFZISIrysrKBm7gA4zX6/U/d7lctLW19Xi+y+UCICYmhrFjx5KRkcExxxwDQGlpKaNGjerx+ry8PPbuteR5W1sb1dXVZGZm9ucWDAbDCCOagqMYKAh4nW+3OSQDM4ElIrILOBZYLCKFACKSDzwDfFlV/ctoVS22/9YC/8YyiXVBVR9Q1UJVLczOzh6wmxpskpOTqa2tBWDq1KmsWrUKsHwjRUVFVFVVsWzZMoqKiliyZAnHHXdcj/0tWrSIRx55BICnnnqKU0891fg3DAZDRERTcCwHJovIBBHxAJcAi52DqlqtqlmqOl5VxwNLgUV2VFUa8AJwk6q+71wjIm4RybKfxwLnAOuieA9DzjXXXMPChQs55ZRTSE5OZtSoUbzxxhvcddddXHDBBVx66aWcddZZ3HvvvTz44IN4PB7AMmXl5+fT0NBAfn6+3yH+1a9+lfLyciZNmsQ999zDr34VMtDNYDAYukVUNXqdi5wN3IcVjvt3Vf2FiNwOrFDVxUHnLgF+YAuOHwM3A1sDTjkDqAfeAWLtPl8Hvqeqvp7GUVhYqCtWdA7C2rhxI9OmTevH3Q0NJSUlfPazn+XGG2/kc5/7HG63m02bNvHxxx9z6aWXDvXwBpxD9XsyGA4HRGSlqhYGt0c1j0NVXwReDGq7tZtzTw54/nPg5910u2CgxncokpOTw6uvvsqdd97JXXfdRUtLCzNmzOCWW24Z6qEZDIYRwogtq34ok5GRwa9//euhHobBYBihmJIjBoPBYIgIIzgMBoPBEBFGcBgMBoMhIozgMBgMBkNEGMExRHRXUh0Or7LqH330EXPnzmXu3LnMmTOHZ555xn/s5ZdfZsqUKUyaNMnkkxgMhxAmqgrgO9+B1asHts+5c+G++/p06eFUVn3mzJmsWLECt9vN/v37mTNnDueeey4iwre+9S1ee+018vPzOeqoo1i0aBHTp0+P2lgMBsPAYDSOIcQpqT5jxgzOOOMMGhutLUauvPJKnnrqKX7/+9/7y6qfcsopAP6y6t/4xjeIj48HOsqq33jjjf6+jz32WHJzc7u853PPPccVV1wBWGXV33jjDYKTQJcsWcJJJ53Eeeedx8SJE7npppt47LHHOProo5k1a5a/kOLzzz/PMcccw7x58zjttNMoKSnp8n4JCQm43db6pKmpyV/e5KOPPmLSpElMnDgRj8fDJZdcwnPPPdevz9NgMAwORuOAPmsG/SVUSfXLL7/cf3woy6qvWbOGjRs3kpGRwcSJE7n66qv56KOP+N3vfscf/vAH7rvvPk444QSWLl2KiPDQQw9x991389vf/rbLey5btoyrrrqK3bt3869//Qu3291pHAD5+fksW7asy7UGg2H4YTSOISSSkuowuGXVjzrqKHJzc/F6vRxxxBGcccYZAMyaNcs/zqKiIs4880xmzZrFr3/96y5+FodjjjmG9evXs3z5cu68806ampoGZIwGg2FoMIJjCIm0pLpzHkS/rHrg2GJiYvyvY2Ji/OP89re/zXXXXcfatWv561//2qtAmDZtGklJSaxbt67TOMASQnl5eT1cbTAYhgtGcAxzhnNZ9erqav9k7/QZzM6dO/2CZvfu3WzatInx48dz1FFHsXXrVnbu3ElLSwtPPPEEixYt6tM4DAbD4GIExzBnOJdVv+222/jCF77AggULut169r333mPOnDnMnTuXCy64gD/96U9kZWXhdrv54x//yJlnnsm0adO46KKLmDFj6LbwNRgM4RPVsurDBVNW/dDlUP2eDIbDge7KqhuN4xDDKau+fPlyjjnmGGbNmsVtt93WbTKhwWAwDDQjOhxXVQ/JbVNHSln1kaANGwyHIiNW44iLi6O8vNxMTsMUVaW8vJy4uLihHorBYAhixGoc+fn5FBUVUVZWNtRDMXRDXFwc+fn5Qz0Mg8EQxIgVHLGxsUyYMGGoh2EwGAyHHFE1VYnIQhHZLCLbROSmHs67UERURAoD2m62r9ssImdG2qfBYDAYokPUNA4RcQH3A6cDRcByEVmsqhuCzksGbgCWBbRNBy4BZgBjgNdF5Ej7cK99GgwGgyF6RFPjOBrYpqo7VLUFeAI4L8R5dwB3AYH1Ks4DnlDVZlXdCWyz+wu3T4PBYDBEiWj6OPKAvQGvi4BjAk8QkflAgaq+ICI/DLp2adC1TiGjHvsM6Psa4Br7ZZ2IbI74DiyygIN9vPZQZiTe90i8ZxiZ923uOTzGhWocMue4iMQA9wBXRqN/VX0AeKC//YjIilCZk4c7I/G+R+I9w8i8b3PP/SOagqMYKAh4nW+3OSQDM4EldhLeaGCxiCzq5dqe+jQYDAZDlImmj2M5MFlEJoiIB8vZvdg5qKrVqpqlquNVdTyWaWqRqq6wz7tERLwiMgGYDHzUW58Gg8FgiD5R0zhUtU1ErgNeAVzA31V1vYjcDqxQ1W4nfPu8/wAbgDbgW6rqAwjVZ7Tuwabf5q5DlJF43yPxnmFk3re5534wIqrjGgwGg2HgGLG1qgwGg8HQN4zgMBgMBkNEGMHRAyOhvImIFIjIWyKyQUTWi8gNdnuGiLwmIlvtv+lDPdaBRkRcIvKxiPw/+/UEEVlmf99P2gEYhxUikiYiT4nIJhHZKCLHHe7ftYh81/7fXicij4tI3OH4XYvI30WkVETWBbSF/G7F4vf2/X9i59SFjREc3RBQMuUsYDpwqV0K5XCjDfi+qk4HjgW+Zd/nTcAbqjoZeMN+fbhxA7Ax4PVdwL2qOgmoBL46JKOKLr8DXlbVqcAcrPs/bL9rEckDrgcKVXUmVlDNJRye3/XDwMKgtu6+27OwolUnYyVK/zmSNzKCo3tGRHkTVd2vqqvs57VYE0ke1r0+Yp/2CHD+kAwwSohIPvBZ4CH7tQCnAk/ZpxyO95wKfBr4G4CqtqhqFYf5d40VPRovIm4gAdjPYfhdq+o7QEVQc3ff7XnAP9ViKZAmIrnhvpcRHN0TqmRKXjfnHhaIyHhgHlbByRxV3W8fOgDkDNW4osR9wI1Au/06E6hS1Tb79eH4fU8AyoB/2Ca6h0QkkcP4u1bVYuA3wB4sgVENrOTw/64duvtu+zW/GcFhAEBEkoCnge+oak3gMbVitg+buG0ROQcoVdWVQz2WQcYNzAf+rKrzgHqCzFKH4XedjrW6noBVaTuRruacEcFAfrdGcHRPbyVTDhtEJBZLaDymqv+zm0sc1dX+WzpU44sCnwIWicguLBPkqVi2/zTbnAGH5/ddBBSpqrOFwVNYguRw/q5PA3aqapmqtgL/w/r+D/fv2qG777Zf85sRHN0zIsqb2Lb9vwEbVfWegEOLgSvs51cAzw322KKFqt6sqvl2qZtLgDdV9TLgLeDz9mmH1T0DqOoBYK+ITLGbPoNVneGw/a6xTFTHikiC/b/u3PNh/V0H0N13uxj4sh1ddSxQHWDS6hWTOd4DInI2li3cKW/yi6Ed0cAjIicA7wJr6bD3/x+Wn+M/wFhgN3CRqgY73g55RORk4Aeqeo6ITMTSQDKAj4HLVbV5CIc34IjIXKyAAA+wA/gK1gLysP2uReRnwMVYEYQfA1dj2fMPq+9aRB4HTsYqn14C/BR4lhDfrS1E/4hltmsAvmLXCQzvvYzgMBgMBkMkGFOVwWAwGCLCCA6DwWAwRIQRHAaDwWCICCM4DAaDwRARRnAYDAaDISKM4DAYBgAR8YnI6oDHgBUKFJHxgRVPDYahJmpbxxoMI4xGVZ071IMwGAYDo3EYDFFERHaJyN0islZEPhKRSXb7eBF5094L4Q0RGWu354jIMyKyxn4cb3flEpEH7X0lXhWR+CG7KcOIxwgOg2FgiA8yVV0ccKxaVWdhZereZ7f9AXhEVWcDjwG/t9t/D7ytqnOw6kitt9snA/er6gygCrgwqndjMPSAyRw3GAYAEalT1aQQ7buAU1V1h11M8oCqZorIQSBXVVvt9v2qmiUiZUB+YPkLu9z9a/ZmPIjIj4BYVf35INyawdAFo3EYDNFHu3keCYF1lHwY/6RhCDGCw2CIPhcH/P3Qfv4BVmVegMuwCk2Ctb3nteDfEz11sAZpMISLWbUYDANDvIisDnj9sqo6IbnpIvIJltZwqd32bayd+H6ItSvfV+z2G4AHROSrWJrFtVg71xkMwwbj4zAYoojt4yhU1YNDPRaDYaAwpiqDwWAwRITROAwGg8EQEUbjMBgMBkNEGMFhMBgMhogwgsNgMBgMEWEEh8FgMBgiwggOg8FgMETE/we/2Dm8xF1iXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res, label='hit@10')\n",
    "plt.plot(pd.Series(res).rolling(30).mean(), c='r', label='hit@10 ma 30')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Hit Ratio')\n",
    "plt.title('Hit@10 for BERT-baseline')\n",
    "plt.ylim([0.4, 0.6])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.c_hist[-1]/sum(dqn.rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n請不要關掉這ㄍ分頁 乾蝦哈咪搭\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "請不要關掉這ㄍ分頁 乾蝦哈咪搭\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Baseline. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(dqn.model, './torch-ep100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open('dqn_ep100.pkl', 'wb') as file_pi:\n",
    "  pickle.dump(dqn, file_pi, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Decay(4, 0.5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(e) == Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9599999999999997"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*0.7*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865475"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.82842712474619/4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "2.82842712474619\n",
      "2.3094010767585034\n",
      "2.0\n",
      "1.7888543819998317\n",
      "1.6329931618554523\n",
      "1.5118578920369088\n",
      "1.414213562373095\n",
      "1.3333333333333333\n",
      "1.2649110640673518\n"
     ]
    }
   ],
   "source": [
    "for e in range(10): print(4 / ((e + 1) ** (1 / 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 / ((1) ** (1 / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "# %reload_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.82 ms, sys: 0 ns, total: 2.82 ms\n",
      "Wall time: 2.13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "baseline_model2 = Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 9.54 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "exp_replay2 = ReplayBuffer(max_memory=MAX_MEMORY)\n",
    "epsilon2 = VDBE(0.5, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.26 s, sys: 144 ms, total: 8.41 s\n",
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dqn2 = DQN(baseline_model2, exp_replay2, epsilon2, 5, EPOCH, BATCH_SIZE, LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Chasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.   Time: 20:15:21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c1972d818a42de86fb01f83fff7fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 38.1236 s\n",
       "File: <ipython-input-80-6659d9ecefc0>\n",
       "Function: train at line 106\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   106                                             def train(self):\n",
       "   107         1     938371.0 938371.0      0.0      self.model.to(DEVICE)\n",
       "   108         1        664.0    664.0      0.0      self.c_win_cnt = 0\n",
       "   109         1      40553.0  40553.0      0.0      self.model.train(True)\n",
       "   110         1       8414.0   8414.0      0.0      self.epsilon.clear()\n",
       "   111         1        482.0    482.0      0.0      self.explore = 0\n",
       "   112         1        361.0    361.0      0.0      self.exploit = 0\n",
       "   113                                           \n",
       "   114         1        492.0    492.0      0.0      for e in self.epochs:\n",
       "   115         1        309.0    309.0      0.0        self.rec_cnt = 0\n",
       "   116         1        224.0    224.0      0.0        self.win_cnt = 0\n",
       "   117         1        270.0    270.0      0.0        self.loss = 0.\n",
       "   118         1        285.0    285.0      0.0        self.ep_score = 0\n",
       "   119                                           \n",
       "   120         1      78419.0  78419.0      0.0        print(f'Epoch {e} started.   Time: {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
       "   121                                                 # ------------------- Episode (User) -------------------------------\n",
       "   122         5  193017321.0 38603464.2      0.5        for asid in tqdm(self.__episodes()):\n",
       "   123         5       4664.0    932.8      0.0          self.asid = asid\n",
       "   124         5   12324255.0 2464851.0      0.0          self.__user_episode_context()\n",
       "   125                                           \n",
       "   126                                                   # ----------------- Runs (User x All_Stream) ---------------------\n",
       "   127       227     383208.0   1688.1      0.0          for i, stream in enumerate(self.stream_list):\n",
       "   128       227     133821.0    589.5      0.0            game_over = stream == self.final_stream\n",
       "   129       227      66119.0    291.3      0.0            self.current_stream = stream\n",
       "   130       227   90445602.0 398438.8      0.2            self.current_state = self.__full_state(i)\n",
       "   131       227     321714.0   1417.2      0.0            self.stream_items = STREAM_ITEM_DICT[self.current_stream]\n",
       "   132       227 5003847606.0 22043381.5     13.1            self.full_input = get_input_v2(self.current_state, self.current_stream).astype('float32')\n",
       "   133                                           \n",
       "   134                                                     # --------------- Explore/Exploit Section ----------------------\n",
       "   135       227  375473144.0 1654066.7      1.0            self.action_ids = self.__choose_actions()\n",
       "   136                                           \n",
       "   137                                                     # --------------- Get next state & info to store ---------------\n",
       "   138       227 1470921251.0 6479829.3      3.9            reward = self.reward()\n",
       "   139       227   79161266.0 348728.0      0.2            next_state = self.__full_state(i+1) if not game_over else []\n",
       "   140       227     882732.0   3888.7      0.0            next_stream = 0 if (i + 1) == len(self.stream_list) else self.stream_list[i + 1]\n",
       "   141       227     702771.0   3095.9      0.0            self.exp_replay.remember([[stream, next_stream], self.current_state, self.action_ids, reward, next_state], game_over)\n",
       "   142                                           \n",
       "   143                                                     # --------------- Load batch of experiences --------------------\n",
       "   144       227 30090961405.0 132559301.3     78.9            inputs, targets = self.exp_replay.get_batch(self.model, batch_size=self.batch_size)\n",
       "   145       227   84272858.0 371246.1      0.2            inputs, targets = df_to_tensor(inputs).to(DEVICE), df_to_tensor(targets).to(DEVICE)\n",
       "   146                                                     # store pre-training value for td_error\n",
       "   147       227  154928210.0 682503.1      0.4            old_Q = self.q_value()\n",
       "   148       227  440476664.0 1940425.8      1.2            batch_loss = self.__train_agent_batch(inputs, targets)\n",
       "   149                                                     # store post-training value for td_error\n",
       "   150       227  119707554.0 527346.1      0.3            new_Q = self.q_value()\n",
       "   151       227     302443.0   1332.3      0.0            self.loss += batch_loss\n",
       "   152                                           \n",
       "   153                                                     # --------------- Update with TD error -------------------------\n",
       "   154       227    4101799.0  18069.6      0.0            self.epsilon.update_at_step(f'{self.asid}-{self.current_stream}', (new_Q - old_Q), len(self.stream_items))\n",
       "   155                                           \n",
       "   156                                                 # Track win history to later check if our model is improving at the game over time.\n",
       "   157         1       1060.0   1060.0      0.0        self.hist.append(self.win_cnt)\n",
       "   158         1        671.0    671.0      0.0        self.c_hist.append(self.c_win_cnt)\n",
       "   159         1        660.0    660.0      0.0        self.rec_list.append(self.rec_cnt)\n",
       "   160         1        560.0    560.0      0.0        self.ep_score_list.append(self.ep_score)\n",
       "   161                                           \n",
       "   162         1      52726.0  52726.0      0.0        print(f'Epoch: {e}/{len(self.epochs)} | Loss {self.loss} | Epoch Hit Rate {self.win_cnt/self.rec_cnt} | Cumulative Hit Rate {self.c_win_cnt/sum(self.rec_list)} | Explore {self.explore} | Exploit {self.exploit} | Score {self.ep_score}')\n",
       "   163         1        531.0    531.0      0.0        break"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100 | Loss 1.0081119492335264 | Epoch Hit Rate 0.43171806167400884 | Cumulative Hit Rate 0.43171806167400884 | Explore 122 | Exploit 105 | Score 148\n"
     ]
    }
   ],
   "source": [
    "%lprun -f dqn2.train dqn2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.000899958 s\n",
       "File: <ipython-input-80-6659d9ecefc0>\n",
       "Function: q_value at line 70\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    70                                             def q_value(self): \n",
       "    71         1        953.0    953.0      0.1      if type(self.epsilon) == Decay: return 0\n",
       "    72                                             \n",
       "    73                                               # Get all items\n",
       "    74                                               # full_input = get_input_v2(self.current_state, self.current_stream).astype('float32')\n",
       "    75                                               # 紀錄所有預測結果\n",
       "    76         1     866317.0 866317.0     96.3      predicts = self.model(df_to_tensor(self.full_input).to(DEVICE)).detach().cpu().numpy().flatten()\n",
       "    77         1        637.0    637.0      0.1      if len(predicts) > 10:\n",
       "    78         1      18065.0  18065.0      2.0        ind = np.argpartition(predicts, -10)[-10:]\n",
       "    79         1      13862.0  13862.0      1.5        q_val = predicts[ind].sum()\n",
       "    80                                               else:\n",
       "    81                                                 q_val = predicts.sum()\n",
       "    82         1        124.0    124.0      0.0      return q_val"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f dqn2.q_value dqn2.q_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 3.727e-06 s\n",
       "File: <ipython-input-52-6ef98bedccbe>\n",
       "Function: gen_exist_series at line 12\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    12                                           def gen_exist_series(A, B):\n",
       "    13         1       3727.0   3727.0    100.0    return [int(item in A) for item in B]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  # A: [1, 2, 4, 5]\n",
    "  # B: [1, 2, 3, 4, 5, 6, 7]\n",
    "  # return: Series([1, 1, 0, 1, 1, 0, 0], index=[1, 2, 3, 4, 5, 6, 7])\n",
    "%lprun -f gen_exist_series gen_exist_series([1, 2, 4, 5], [1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### old profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.230175 s\n",
       "File: <ipython-input-9-4ff322623ba3>\n",
       "Function: get_batch at line 26\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    26                                             def get_batch(self, model, batch_size=10):\n",
       "    27                                               # How many experiences do we have?\n",
       "    28         1        816.0    816.0      0.0      len_memory = len(self.memory)\n",
       "    29                                           \n",
       "    30                                               # Calculate the number of actions that can possibly be taken in the game.\n",
       "    31                                               # Actions: 0 = not recommend, 1 = recommend\n",
       "    32         1        372.0    372.0      0.0      num_actions = self.model_output_shape\n",
       "    33                                           \n",
       "    34                                               # Dimensions of our observed states, ie, the input to our model.\n",
       "    35                                               # Memory:  [\n",
       "    36                                               #   [ [ [stream, next_stream], [...state], action, reward, next_state_idx], game_over],\n",
       "    37                                               #   [ [ [stream, next_stream], [...state], action, reward, nexr_state_idx], game_over],\n",
       "    38                                               #   ...\n",
       "    39                                               # ]\n",
       "    40         1        334.0    334.0      0.0      env_dim = len(INPUT_DF_COL)\n",
       "    41                                           \n",
       "    42         1   22289849.0 22289849.0      9.7      inputs = pd.DataFrame(columns=INPUT_DF_COL)\n",
       "    43         1    1331259.0 1331259.0      0.6      targets = pd.DataFrame(columns=[0])\n",
       "    44                                               \n",
       "    45                                               \n",
       "    46                                               # We draw states to learn from randomly\n",
       "    47         2      37840.0  18920.0      0.0      for i, idx in enumerate(np.random.randint(0, len_memory, size=min(len_memory, batch_size))):  \n",
       "    48                                                 # Here we load one transition <s, a, r, s'> from memory\n",
       "    49         2      12975.0   6487.5      0.0        streams, state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
       "    50         2        712.0    356.0      0.0        current_stream, next_stream = streams\n",
       "    51         2        757.0    378.5      0.0        game_over = self.memory[idx][1]\n",
       "    52                                           \n",
       "    53                                                 '''\n",
       "    54                                                 修改倒入 state 的方式 input = (state - item) + item_feat\n",
       "    55                                                 拆掉 model_predict 成 function\n",
       "    56                                                 \n",
       "    57                                                 here should be state_t * all_items\n",
       "    58                                                 '''\n",
       "    59         2   99218272.0 49609136.0     43.1        state_t = get_input(state_t, current_stream).astype('float32')\n",
       "    60                                                 # puts state into input\n",
       "    61         2    1495298.0 747649.0      0.6        inputs = pd.concat([inputs, state_t], axis=0)\n",
       "    62                                           \n",
       "    63                                                 '''\n",
       "    64                                                 每個 actions 都會被 predict 一個成績/reward\n",
       "    65                                                 '''\n",
       "    66                                                 # if the game ended, the reward is the final reward\n",
       "    67         2        577.0    288.5      0.0        if game_over:  # if game_over is True\n",
       "    68                                                   state_t['reward'] = reward_t\n",
       "    69                                                   targets = pd.concat([targets, reward_t], axis=0).astype('float32')\n",
       "    70                                                 else:\n",
       "    71         2    1860638.0 930319.0      0.8          state_t['reward'] = model(df_to_tensor(state_t).to(DEVICE)).detach().cpu().numpy()\n",
       "    72                                                   # 找到 action_t 們，指到 state_t 上去算 discount values\n",
       "    73         2     612459.0 306229.5      0.3          action_t = list(set(action_t[action_t == 1].index))\n",
       "    74                                                   \n",
       "    75         2   96197577.0 48098788.5     41.8          state_tp1 = get_input(state_tp1, next_stream)\n",
       "    76         2    1317627.0 658813.5      0.6          Q_sa = np.max(model(df_to_tensor(state_tp1).to(DEVICE)).detach().cpu().numpy())\n",
       "    77                                                   # r + gamma * max Q(s',a')\n",
       "    78                                                   # DataFrame apply\n",
       "    79         2     182761.0  91380.5      0.1          state_t.loc[state_t['item_id'].isin(action_t)]['reward'] = state_t.loc[state_t['item_id'] \\\n",
       "    80         2    1296049.0 648024.5      0.6                                                                            .isin(action_t)]['reward'] \\\n",
       "    81         2     568897.0 284448.5      0.2                                                                            .apply(lambda x: x + self.discount * Q_sa) \\\n",
       "    82         2    1504948.0 752474.0      0.7                                                                            .astype('float32')\n",
       "    83         2    2244776.0 1122388.0      1.0          targets = pd.concat([targets, state_t['reward']], axis=0).astype('float32')\n",
       "    84         1        255.0    255.0      0.0      return inputs, targets"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f exp_replay2.get_batch exp_replay2.get_batch(baseline_model2, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0504328 s\n",
       "File: <ipython-input-6-c8baae5034eb>\n",
       "Function: get_input at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                           def get_input(input_state, current_stream):\n",
       "    11                                             # Get item feats\n",
       "    12                                             # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
       "    13         1       2178.0   2178.0      0.0    item_list = STREAM_ITEM_DICT[current_stream]\n",
       "    14         1     402689.0 402689.0      0.8    item_feat = BERT_BY_IDX_DF.loc[item_list]\n",
       "    15                                           \n",
       "    16                                             # Create new df\n",
       "    17         1   23229756.0 23229756.0     46.1    stream_item_feat = pd.DataFrame(columns=INPUT_DF_COL)\n",
       "    18                                           \n",
       "    19                                             # Fill in other context\n",
       "    20         1   11686664.0 11686664.0     23.2    stream_item_feat = stream_item_feat.append([input_state]*len(item_list),ignore_index=True)\n",
       "    21                                             \n",
       "    22                                             # stream_item_feat\n",
       "    23         1   14848264.0 14848264.0     29.4    stream_item_feat[LB_ITEMS] = item_feat.reset_index()\n",
       "    24                                             \n",
       "    25         1     263220.0 263220.0      0.5    return stream_item_feat.astype('float32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f get_input get_input(CONTEXT_REPS.iloc[0], CONTEXT_REPS.iloc[0].name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleansing\n",
    "Original Version:\n",
    "```python\n",
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "\n",
    "Convert state format to model input format\n",
    "'''\n",
    "def get_input(input_state, current_stream):\n",
    "  # Get item feats\n",
    "  # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list]\n",
    "\n",
    "  # Create new df\n",
    "  stream_item_feat = pd.DataFrame(columns=INPUT_DF_COL)\n",
    "\n",
    "  # Fill in other context\n",
    "  stream_item_feat = stream_item_feat.append([input_state]*len(item_list),ignore_index=True)\n",
    "  \n",
    "  # stream_item_feat\n",
    "  stream_item_feat[LB_ITEMS] = item_feat.reset_index()\n",
    "  \n",
    "  return stream_item_feat.astype('float32')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "Convert state format to model input format\n",
    "\n",
    "LB_ITEMS = ['item_id'] + [f'i{x}' for x in range(160)]\n",
    "INPUT_DF_COL__USR = CONTEXT_REPS.columns.to_list()\n",
    "INPUT_DF_COL = INPUT_DF_COL__USR + LB_ITEMS\n",
    "'''\n",
    "input_state = CONTEXT_REPS.iloc[0]\n",
    "current_stream = CONTEXT_REPS.iloc[0].name[1]\n",
    "def new_get_input(input_state, current_stream):\n",
    "  # Get item feats\n",
    "  # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list]\n",
    "\n",
    "  for idx in input_state.index: item_feat[idx] = input_state[idx]\n",
    "  item_feat_ri = item_feat.reset_index().rename(columns={'index':'item_id'})\n",
    "  \n",
    "  return item_feat_ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.107122 s\n",
       "File: <ipython-input-22-07c49d6a115a>\n",
       "Function: new_get_input at line 11\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    11                                           def new_get_input(input_state, current_stream):\n",
       "    12                                             # Get item feats\n",
       "    13                                             # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
       "    14         1       2309.0   2309.0      0.0    item_list = STREAM_ITEM_DICT[current_stream]\n",
       "    15         1     396509.0 396509.0      0.4    item_feat = BERT_BY_IDX_DF.loc[item_list]\n",
       "    16                                           \n",
       "    17       219  105267435.0 480673.2     98.3    for idx in input_state.index: item_feat[idx] = input_state[idx]\n",
       "    18         1    1455838.0 1455838.0      1.4    item_feat_ri = item_feat.reset_index().rename(columns={'index':'item_id'})\n",
       "    19                                             \n",
       "    20         1        133.0    133.0      0.0    return item_feat_ri"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f new_get_input new_get_input(CONTEXT_REPS.iloc[0], CONTEXT_REPS.iloc[0].name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_input_v2(input_state, current_stream):\n",
    "  # Get item feats\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list].reset_index().rename(columns={'index': 'item_id'})\n",
    "\n",
    "  # Fill in other context\n",
    "  stream_item_feat = pd.DataFrame([input_state]*len(item_list)).reset_index(drop=True)\n",
    "  \n",
    "  # Merge with items\n",
    "  stream_item_feat = stream_item_feat.merge(item_feat, left_index=True, right_index=True).astype('float32')\n",
    "  return stream_item_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0176343 s\n",
       "File: <ipython-input-84-4d017c41242b>\n",
       "Function: get_input_v2 at line 9\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     9                                           def get_input_v2(input_state, current_stream):\n",
       "    10                                             # Get item feats\n",
       "    11                                             # STREAM_ITEM_DICT: 要拿到對的 STREAM!!!\n",
       "    12         1       8785.0   8785.0      0.0    item_list = STREAM_ITEM_DICT[current_stream]\n",
       "    13         1    5560119.0 5560119.0     31.5    item_feat = BERT_BY_IDX_DF.loc[item_list].reset_index().rename(columns={'index': 'item_id'})\n",
       "    14                                           \n",
       "    15                                             # Fill in other context\n",
       "    16         1   10882756.0 10882756.0     61.7    stream_item_feat = pd.DataFrame([input_state]*len(item_list)).reset_index(drop=True)\n",
       "    17                                             \n",
       "    18                                             # Merge with items\n",
       "    19         1    1182536.0 1182536.0      6.7    stream_item_feat = stream_item_feat.merge(item_feat, left_index=True, right_index=True).astype('float32')\n",
       "    20         1        130.0    130.0      0.0    return stream_item_feat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f get_input_v2 get_input_v2(CONTEXT_REPS.iloc[0], CONTEXT_REPS.iloc[0].name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Chasing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 µs, sys: 2.91 ms, total: 3.02 ms\n",
      "Wall time: 2.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "baseline_model3 = Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "exp_replay3 = ReplayBuffer(max_memory=MAX_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.32 s, sys: 177 ms, total: 8.5 s\n",
      "Wall time: 8.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dqn3 = DQN(baseline_model3, exp_replay3, 5, EPOCH, BATCH_SIZE, LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Start Chasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.   Time: 15:23:38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dac98cf24c4a009486a688ebb7ff89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 3.32292 s\n",
       "File: <ipython-input-87-1e430f3ba6d5>\n",
       "Function: train at line 93\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    93                                             def train(self):\n",
       "    94         1   16194974.0 16194974.0      0.5      self.model.to(DEVICE)\n",
       "    95         1        950.0    950.0      0.0      self.c_win_cnt = 0\n",
       "    96         1      40919.0  40919.0      0.0      self.model.train(True)\n",
       "    97                                           \n",
       "    98         1        738.0    738.0      0.0      for e in self.epochs:\n",
       "    99         1        361.0    361.0      0.0        self.rec_cnt = 0\n",
       "   100         1        335.0    335.0      0.0        self.win_cnt = 0\n",
       "   101         1        395.0    395.0      0.0        self.loss = 0.\n",
       "   102         1       1624.0   1624.0      0.0        self.epsilon = 4 / ((e + 1) ** (1 / 2))\n",
       "   103                                           \n",
       "   104         1      99669.0  99669.0      0.0        print(f'Epoch {e} started.   Time: {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
       "   105                                                 # ------------------- Episode (User) -------------------------------\n",
       "   106         5   29169483.0 5833896.6      0.9        for asid in tqdm(self.__episodes()):\n",
       "   107         5       3671.0    734.2      0.0          self.asid = asid\n",
       "   108         5   13840796.0 2768159.2      0.4          self.__user_episode_context()\n",
       "   109                                                   \n",
       "   110                                                   # ----------------- Runs (User x All_Stream) ---------------------\n",
       "   111        40      74011.0   1850.3      0.0          for i, stream in enumerate(self.stream_list):\n",
       "   112        40      42038.0   1051.0      0.0            game_over = stream == self.final_stream\n",
       "   113        40      17114.0    427.9      0.0            self.current_stream = stream\n",
       "   114        40   14281161.0 357029.0      0.4            self.current_state = self.__full_state(i)\n",
       "   115        40      54286.0   1357.2      0.0            self.stream_items = STREAM_ITEM_DICT[self.current_stream]\n",
       "   116                                                     \n",
       "   117                                                     # --------------- Explore/Exploit Section ----------------------\n",
       "   118        40   10822590.0 270564.8      0.3            self.action_ids = self.__choose_actions_eps()\n",
       "   119                                                     \n",
       "   120                                                     # --------------- Get next state & info to store ---------------\n",
       "   121        40   11733166.0 293329.2      0.4            reward = self.__reward()\n",
       "   122        40   13252099.0 331302.5      0.4            next_state = self.__full_state(i+1) if not game_over else []\n",
       "   123        40     155896.0   3897.4      0.0            next_stream = 0 if (i + 1) == len(self.stream_list) else self.stream_list[i + 1]\n",
       "   124        40     110756.0   2768.9      0.0            self.exp_replay.remember([[stream, next_stream], self.current_state, self.action_ids, reward, next_state], game_over)\n",
       "   125                                                     \n",
       "   126                                                     # --------------- Load batch of experiences --------------------\n",
       "   127        40 3137809074.0 78445226.8     94.4            inputs, targets = self.exp_replay.get_batch(self.model, batch_size=self.batch_size)\n",
       "   128        40    5304262.0 132606.5      0.2            inputs, targets = df_to_tensor(inputs).to(DEVICE), df_to_tensor(targets).to(DEVICE)\n",
       "   129        40   69784301.0 1744607.5      2.1            batch_loss = self.__train_agent_batch(inputs, targets)\n",
       "   130        40      38686.0    967.1      0.0            self.loss += batch_loss      \n",
       "   131                                                     \n",
       "   132                                                 \n",
       "   133                                                 # Track win history to later check if our model is improving at the game over time.\n",
       "   134         1       1001.0   1001.0      0.0        self.hist.append(self.win_cnt)\n",
       "   135         1        693.0    693.0      0.0        self.c_hist.append(self.c_win_cnt)\n",
       "   136         1        586.0    586.0      0.0        self.rec_list.append(self.rec_cnt)\n",
       "   137                                           \n",
       "   138         1        295.0    295.0      0.0        print(f'Epoch: {e}/{len(self.epochs)} | Loss {self.loss} | Epoch Hit Rate {self.win_cnt/self.rec_cnt} | Cumulative Hit Rate {self.c_win_cnt/sum(self.rec_list)} |\\\n",
       "   139         1      83647.0  83647.0      0.0                Time {datetime.now(pytz.timezone(\"Asia/Taipei\")).strftime(\"%H:%M:%S\")}')\n",
       "   140         1        357.0    357.0      0.0        break"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100 | Loss 2.4590116441249847 | Epoch Hit Rate 0.775 | Cumulative Hit Rate 0.775 |              Time 15:23:41\n"
     ]
    }
   ],
   "source": [
    "%lprun -f dqn3.train dqn3.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.0848023 s\n",
       "File: <ipython-input-86-f9f91d8b7747>\n",
       "Function: get_batch at line 26\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    26                                             def get_batch(self, model, batch_size=10):\n",
       "    27                                               # How many experiences do we have?\n",
       "    28         1       1013.0   1013.0      0.0      len_memory = len(self.memory)\n",
       "    29                                           \n",
       "    30                                               # Calculate the number of actions that can possibly be taken in the game.\n",
       "    31                                               # Actions: 0 = not recommend, 1 = recommend\n",
       "    32         1        741.0    741.0      0.0      num_actions = self.model_output_shape\n",
       "    33                                           \n",
       "    34                                               # Dimensions of our observed states, ie, the input to our model.\n",
       "    35                                               # Memory:  [\n",
       "    36                                               #   [ [ [stream, next_stream], [...state], action, reward, next_state_idx], game_over],\n",
       "    37                                               #   [ [ [stream, next_stream], [...state], action, reward, nexr_state_idx], game_over],\n",
       "    38                                               #   ...\n",
       "    39                                               # ]\n",
       "    40         1        512.0    512.0      0.0      env_dim = len(INPUT_DF_COL)\n",
       "    41                                           \n",
       "    42         1   23397393.0 23397393.0     27.6      inputs = pd.DataFrame(columns=INPUT_DF_COL)\n",
       "    43         1    1719888.0 1719888.0      2.0      targets = pd.DataFrame(columns=[0])\n",
       "    44                                               \n",
       "    45                                               \n",
       "    46                                               # We draw states to learn from randomly\n",
       "    47         2      40406.0  20203.0      0.0      for i, idx in enumerate(np.random.randint(0, len_memory, size=min(len_memory, batch_size))):  \n",
       "    48                                                 # Here we load one transition <s, a, r, s'> from memory\n",
       "    49         2      12107.0   6053.5      0.0        streams, state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
       "    50         2        582.0    291.0      0.0        current_stream, next_stream = streams\n",
       "    51         2        705.0    352.5      0.0        game_over = self.memory[idx][1]\n",
       "    52                                           \n",
       "    53                                                 '''\n",
       "    54                                                 修改倒入 state 的方式 input = (state - item) + item_feat\n",
       "    55                                                 拆掉 model_predict 成 function\n",
       "    56                                                 \n",
       "    57                                                 here should be state_t * all_items\n",
       "    58                                                 '''\n",
       "    59         2   24825667.0 12412833.5     29.3        state_t = get_input_v2(state_t, current_stream).astype('float32')\n",
       "    60                                                 # puts state into input\n",
       "    61         2    1505652.0 752826.0      1.8        inputs = pd.concat([inputs, state_t], axis=0)\n",
       "    62                                           \n",
       "    63                                                 '''\n",
       "    64                                                 每個 actions 都會被 predict 一個成績/reward\n",
       "    65                                                 '''\n",
       "    66                                                 # if the game ended, the reward is the final reward\n",
       "    67         2        491.0    245.5      0.0        if game_over:  # if game_over is True\n",
       "    68                                                   state_t['reward'] = reward_t\n",
       "    69                                                   targets = pd.concat([targets, reward_t], axis=0).astype('float32')\n",
       "    70                                                 else:\n",
       "    71         2    1833815.0 916907.5      2.2          state_t['reward'] = model(df_to_tensor(state_t).to(DEVICE)).detach().cpu().numpy()\n",
       "    72                                                   # 找到 action_t 們，指到 state_t 上去算 discount values\n",
       "    73         2     686727.0 343363.5      0.8          action_t = list(set(action_t[action_t == 1].index))\n",
       "    74                                                   \n",
       "    75         2   23827017.0 11913508.5     28.1          state_tp1 = get_input_v2(state_tp1, next_stream)\n",
       "    76         2    1203817.0 601908.5      1.4          Q_sa = np.max(model(df_to_tensor(state_tp1).to(DEVICE)).detach().cpu().numpy())\n",
       "    77                                                   # r + gamma * max Q(s',a')\n",
       "    78                                                   # DataFrame apply\n",
       "    79         2     195845.0  97922.5      0.2          state_t.loc[state_t['item_id'].isin(action_t)]['reward'] = state_t.loc[state_t['item_id'] \\\n",
       "    80         2    1266091.0 633045.5      1.5                                                                            .isin(action_t)]['reward'] \\\n",
       "    81         2     562086.0 281043.0      0.7                                                                            .apply(lambda x: x + self.discount * Q_sa) \\\n",
       "    82         2    1512456.0 756228.0      1.8                                                                            .astype('float32')\n",
       "    83         2    2209093.0 1104546.5      2.6          targets = pd.concat([targets, state_t['reward']], axis=0).astype('float32')\n",
       "    84         1        236.0    236.0      0.0      return inputs, targets"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f exp_replay3.get_batch exp_replay3.get_batch(baseline_model3, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per hit\n",
    "* exp/get_input:\n",
    "  * v1: `49609136.0`\n",
    "  * v2: `12412833.5`\n",
    "* train/get_batch:\n",
    "  * v1: `216278453.8`\n",
    "  * v2: `78445226.8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
