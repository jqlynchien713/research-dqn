{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember with Expanded Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import line_profiler\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "  np.random.seed(seed)  \n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "CONTEXT_REPS = pd.read_pickle('../../data/CONTEXT_REPS_CLEAN_ASID.pkl')\n",
    "STREAM_ITEM_DICT = pd.read_pickle('../../data/stream_item_dict.pkl')\n",
    "BERT_BY_IDX_DF = pd.read_pickle('../../data/bert_by_idx_pca.pkl')\n",
    "BOUGHT_DICT = pd.read_pickle('../../data/bought_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((871416, 219), 7701, (162189, 160), 79207)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_REPS.shape, len(STREAM_ITEM_DICT), BERT_BY_IDX_DF.shape, len(BOUGHT_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "USER_LIST = CONTEXT_REPS.index.get_level_values('asid').unique().tolist()\n",
    "USER_LIST = USER_LIST[:744]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "LB_ITEMS = ['item_id'] + [f'i{x}' for x in range(160)]\n",
    "INPUT_DF_COL__USR = CONTEXT_REPS.columns.to_list()\n",
    "INPUT_DF_COL = INPUT_DF_COL__USR + LB_ITEMS\n",
    "\n",
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "Convert state format to model input format\n",
    "'''\n",
    "def get_input_tensor(input_state, current_stream, with_tensor=False):\n",
    "  # Get item feats\n",
    "  # STREAM_ITEM_DICT: 要拿到對的 STREAM\n",
    "  item_list = STREAM_ITEM_DICT[current_stream]\n",
    "  item_feat = BERT_BY_IDX_DF.loc[item_list].reset_index().rename(columns={'index': 'item_id'})\n",
    "\n",
    "  # Fill in other context\n",
    "  stream_item_feat = pd.DataFrame([input_state]*len(item_list)).reset_index(drop=True)\n",
    "  \n",
    "  # Merge with items\n",
    "  stream_item_feat = stream_item_feat.merge(item_feat, left_index=True, right_index=True).astype('float32')\n",
    "  \n",
    "  # Convert to tensor\n",
    "  if with_tensor: \n",
    "    stream_item_feat_tensor = df_to_tensor(stream_item_feat)\n",
    "    return stream_item_feat_tensor, stream_item_feat\n",
    "  else:\n",
    "    return stream_item_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "METHOD FOR BOTH EXP_REPLAY & DQN\n",
    "\n",
    "Generate series: whether elements in A existed in list B\n",
    "A, B: List\n",
    "return: pd.Series\n",
    "example:\n",
    "  A: [1, 2, 4, 5]\n",
    "  B: [1, 2, 3, 4, 5, 6, 7]\n",
    "  return: Series([1, 1, 0, 1, 1, 0, 0], index=[1, 2, 3, 4, 5, 6, 7])\n",
    "'''\n",
    "def gen_exist_series(A, B):\n",
    "  return [int(item in A) for item in B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_tensor(input_df):\n",
    "  return torch.tensor(input_df.values).to(DEVICE).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "  def __init__(self, max_memory=100000, discount=.9, model_output_shape=1):\n",
    "    \"\"\"\n",
    "    Setup\n",
    "    max_memory: the maximum number of experiences we want to store\n",
    "    memory: a list of experiences\n",
    "    discount: the discount factor for future experience\n",
    "    In the memory the information whether the game ended at the state is stored seperately in a nested array\n",
    "    [...\n",
    "    [experience, game_over]\n",
    "    [experience, game_over]\n",
    "    ...]\n",
    "    \"\"\"\n",
    "    self.max_memory = max_memory\n",
    "    self.memory = list()\n",
    "    self.discount = discount\n",
    "    self.model_output_shape = model_output_shape\n",
    "    self.input_dim = 380\n",
    "    self.next_state_list = {}\n",
    "\n",
    "  def remember(self, states, game_over):\n",
    "    # Save a state to memory\n",
    "    current_state, actions, reward, next_state, next_stream = states\n",
    "    selected_actions = np.where(actions == 1)[0]\n",
    "    reward_h = np.where(reward == 0.5)[0]\n",
    "    selected_memory = np.sort(np.append(reward_h, selected_actions))\n",
    "    \n",
    "    current_state = current_state[selected_memory]\n",
    "    reward = reward.iloc[selected_memory]\n",
    "        \n",
    "    for i in range(len(reward)):\n",
    "      self.memory.append([[current_state[i].view(1, self.input_dim), reward.iloc[i], next_state, next_stream], game_over])\n",
    "      \n",
    "    # We don't want to store infinite memories, so if we have too many, we just delete the oldest one\n",
    "    if len(self.memory) > self.max_memory:\n",
    "      del self.memory[0]\n",
    "\n",
    "  def get_batch(self, eval_net, target_net, structure, batch_size=10):\n",
    "    # How many experiences do we have?\n",
    "    len_memory = len(self.memory)\n",
    "    # Dimensions of our observed states, ie, the input to our model.\n",
    "    # Memory:  [\n",
    "    #   [ [ [stream, next_stream], [...state], action, reward, next_state_idx], game_over],\n",
    "    #   [ [ [stream, next_stream], [...state], action, reward, nexr_state_idx], game_over],\n",
    "    #   ...\n",
    "    # ]\n",
    "    env_dim = len(INPUT_DF_COL)\n",
    "\n",
    "    inputs = torch.tensor([], dtype=torch.float32).to(DEVICE)\n",
    "    targets = torch.tensor([], dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    \n",
    "    # We draw states to learn from randomly\n",
    "    for i, idx in enumerate(np.random.randint(0, len_memory, size=min(len_memory, batch_size))):  \n",
    "      # Here we load one transition <s, a, r, s'> from memory\n",
    "      state_t, reward, next_state, next_stream = self.memory[idx][0]\n",
    "      game_over = self.memory[idx][1]\n",
    "      \n",
    "      # puts state into input\n",
    "      inputs = torch.cat((inputs, state_t), dim=0)\n",
    "\n",
    "      # if the game ended, the reward is the final reward\n",
    "      if game_over:  # if game_over is True\n",
    "        current_target = torch.tensor([reward]).to(DEVICE).float()\n",
    "      else:\n",
    "        state_tp1, _ = get_input_tensor(next_state, next_stream, with_tensor=True)\n",
    "        \n",
    "        if target_net == None:\n",
    "          with torch.no_grad():\n",
    "            Q_sa = torch.max(eval_net(state_tp1))\n",
    "        elif structure == 'target':\n",
    "          with torch.no_grad():\n",
    "            Q_sa = torch.max(target_net(state_tp1))\n",
    "        elif structure == 'double':\n",
    "          with torch.no_grad():\n",
    "            _, selected_actions = eval_net(state_tp1).max(dim=0, keepdim=True)\n",
    "            Q_sa = target_net(state_tp1).gather(dim=0, index=selected_actions)          \n",
    "        # r + gamma * max Q(s',a')\n",
    "        current_target = torch.tensor([reward + self.discount * Q_sa]).to(DEVICE)\n",
    "      # concat targets\n",
    "      targets = torch.cat((targets, current_target), 0)\n",
    "    targets = targets.view(len(targets), 1)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "\n",
    "class Epsilon(ABC):\n",
    "  @abstractmethod\n",
    "  def clear(self):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def get_epsilon(self, key):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def update_at_step(self, key, data, delta):\n",
    "    pass\n",
    "  \n",
    "  @abstractmethod\n",
    "  def update_at_epoch(self, data):\n",
    "    pass\n",
    "\n",
    "class Decay(Epsilon):\n",
    "  # Ref: Decay(0.5, 0.85)\n",
    "  '''\n",
    "  Epsilon Decay EE method with update/decay at epoch\n",
    "  '''\n",
    "  def __init__(self, initial, epoch_decay=1.0, step_decay=1.0):\n",
    "    self.initial = initial\n",
    "    self.epoch_decay, self.step_decay = epoch_decay, step_decay\n",
    "    self.epsilon = self.initial\n",
    "    \n",
    "  def clear(self):\n",
    "    self.epsilon = self.initial # should be 4 for origin setting\n",
    "    \n",
    "  def get_epsilon(self, key):\n",
    "    return self.epsilon\n",
    "  \n",
    "  def update_at_step(self, key, data, delta):\n",
    "    # origin setting\n",
    "    # pass\n",
    "    # exponentially\n",
    "    i = data[1]\n",
    "    self.epsilon = 4 / ((i + 1) ** (1 / 4))\n",
    "    \n",
    "  def update_at_epoch(self, data):\n",
    "    # origin settings\n",
    "    # epoch = data\n",
    "    # self.epsilon = 4 / ((epoch + 1) ** (1 / 2))\n",
    "    # exponentially\n",
    "    self.epsilon *= self.epoch_decay\n",
    "\n",
    "\n",
    "class VDBE(Epsilon):\n",
    "  # VDBE(0.5, 0.01)\n",
    "  def __init__(self, initial, sigma):\n",
    "    self.initial = initial\n",
    "    self.sigma = sigma\n",
    "\n",
    "  def clear(self):\n",
    "    self.epsilon = defaultdict(lambda: self.initial)\n",
    "\n",
    "  def get_epsilon(self, key):\n",
    "    return self.epsilon[key]\n",
    "  \n",
    "  def update_at_step(self, key, data, delta):\n",
    "    td_error = data[0]\n",
    "    coeff = math.exp(-abs(td_error) / self.sigma)\n",
    "    f = (1.0 - coeff) / (1.0 + coeff)\n",
    "    self.epsilon[key] = delta * f + (1.0 - delta) * self.epsilon[key]\n",
    "  \n",
    "  def update_at_epoch(self, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(a, b):\n",
    "  if a == b == 1: return 1\n",
    "  elif a == 1 and b == 0: return 0.5\n",
    "  else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(object):\n",
    "  def __init__(self, structure, exp_replay, epsilon, num_episode, batch_size, lr, switch_param_threshold, single_reward):\n",
    "    self.eval_net = Net()\n",
    "    self.target_net = Net() if not structure == 'vanilla' else None\n",
    "    self.structure = structure\n",
    "    self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=lr)\n",
    "    self.loss_fn = nn.MSELoss()\n",
    "    self.exp_replay = exp_replay\n",
    "    self.epsilon = epsilon\n",
    "    self.num_episode = num_episode\n",
    "    self.batch_size = batch_size\n",
    "    self.switch_param_threshold = switch_param_threshold\n",
    "    self.single_reward = single_reward\n",
    "    self.win_list = []\n",
    "    self.score_list = []\n",
    "    self.fake_list = []\n",
    "    self.loss_list = []\n",
    "    self.learn_step_counter = 0\n",
    "\n",
    "  def __user_episode_context(self):\n",
    "    self.user_all_streams = CONTEXT_REPS.xs(self.asid, level=\"asid\")\n",
    "    self.stream_list = self.user_all_streams.index\n",
    "    self.final_stream = max(self.stream_list)\n",
    "\n",
    "  def _print_status(self):\n",
    "    if self.learn_step_counter > 0 and self.learn_step_counter % 100 == 0:\n",
    "      self.win_list.append(self.win_cnt)\n",
    "      self.score_list.append(self.score)\n",
    "      self.fake_list.append(self.fake_score)\n",
    "      self.loss_list.append(self.loss)\n",
    "      print(f'[{len(self.win_list)}] win_cnt: {self.win_cnt} | score: {self.score} | fake score: {self.fake_score} | asid: {USER_LIST.index(self.asid)} | loss: {self.loss:.2f} | explore: {self.explore} | exploit: {self.exploit}')\n",
    "      self.win_cnt = 0\n",
    "      self.score = 0\n",
    "      self.fake_score = 0\n",
    "      self.loss = 0\n",
    "      self.explore = 0\n",
    "      self.exploit = 0\n",
    "      \n",
    "  def reward(self):\n",
    "    '''\n",
    "    Comparison function for reward, 考慮「所有」歷史購買紀錄\n",
    "    '''\n",
    "    real_bought_ids = BOUGHT_DICT[self.asid]\n",
    "    real_bought_ids_series = gen_exist_series(real_bought_ids, self.stream_items)\n",
    "\n",
    "    reward_list = [r(a, b) for a, b in zip(real_bought_ids_series, self.action_ids)]\n",
    "    # Reward Count \n",
    "    self.fake_score += sum(reward_list)\n",
    "    if reward_list.count(1) > 0:\n",
    "      self.score += reward_list.count(1)\n",
    "      self.win_cnt += 1\n",
    "\n",
    "    self._print_status()\n",
    "    \n",
    "    if self.single_reward:\n",
    "      return pd.Series(reward_list, index=self.stream_items)\n",
    "    else:\n",
    "      return pd.Series(list(map(lambda x: 0.5 if x == 0.5 else x * reward_list.count(1), reward_list)), index=self.stream_items)\n",
    "\n",
    "  # Agent Methods\n",
    "  def __choose_actions(self):\n",
    "    if np.random.rand() <= self.epsilon.get_epsilon(self.asid):\n",
    "    # if len(self.exp_replay.memory) < 1:\n",
    "      # Explore by randomly select 10/n items from candidate_items\n",
    "      # Get all items from the stream\n",
    "      self.explore += 1\n",
    "      selected_actions = random.sample(self.stream_items, 10) if len(self.stream_items) > 10 else self.stream_items\n",
    "    else:\n",
    "      # Exploit by choosing action from the model's prediction\n",
    "      self.exploit += 1\n",
    "      selected_actions = self.__agent_predict()\n",
    "    x = pd.Series(0, index=self.stream_items)\n",
    "    x.loc[selected_actions] = 1\n",
    "    return x\n",
    "    \n",
    "  def q_value(self): \n",
    "    if type(self.epsilon) == Decay: return 0\n",
    "    with torch.no_grad():\n",
    "      predicts = self.eval_net(self.full_input).flatten()    \n",
    "    actions_idx = np.where(self.action_ids.values == 1)[0]\n",
    "    q_val = predicts[actions_idx].mean()\n",
    "    return q_val\n",
    "\n",
    "  def __agent_predict(self):\n",
    "    with torch.no_grad():\n",
    "      predicts = self.eval_net(self.full_input).flatten()\n",
    "    if len(predicts) > 10:\n",
    "      top10_idx = torch.topk(predicts, 10).indices.cpu()\n",
    "      actions = self.candidate_actions.iloc[top10_idx]['item_id'].values\n",
    "    else:\n",
    "      actions = self.candidate_actions['item_id'].values\n",
    "    return actions\n",
    "\n",
    "  def __train_agent_batch(self, inputs, targets):\n",
    "    self.optimizer.zero_grad()\n",
    "    outputs = self.eval_net(inputs)\n",
    "    loss = self.loss_fn(outputs, targets)\n",
    "    # Add CL Regularization Term\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "  # MAIN TRAIN\n",
    "  def train(self):\n",
    "    self.eval_net.to(DEVICE)\n",
    "    if self.target_net:\n",
    "      self.target_net.to(DEVICE)\n",
    "    self.eval_net.train(True)\n",
    "    self.epsilon.clear()\n",
    "    self.loss = 0.\n",
    "    self.win_cnt = 0\n",
    "    self.explore = 0\n",
    "    self.exploit = 0\n",
    "    self.score = 0\n",
    "    self.fake_score = 0\n",
    "\n",
    "    # ------------------- Episode (User) -------------------------------\n",
    "    for asid in tqdm(USER_LIST):\n",
    "      self.asid = asid\n",
    "      self.__user_episode_context()\n",
    "\n",
    "      # ----------------- Runs (User x All_Stream) ---------------------\n",
    "      for i, stream in enumerate(self.stream_list):\n",
    "        game_over = stream == self.final_stream\n",
    "        self.current_stream = stream\n",
    "        self.current_state = self.user_all_streams.loc[stream]\n",
    "        self.stream_items = STREAM_ITEM_DICT[self.current_stream]\n",
    "        self.full_input, self.candidate_actions = get_input_tensor(self.current_state, self.current_stream, with_tensor=True)\n",
    "\n",
    "        # --------------- Explore/Exploit Section ----------------------\n",
    "        self.action_ids = self.__choose_actions()\n",
    "\n",
    "        # --------------- Get next state & info to store ---------------\n",
    "        reward = self.reward()\n",
    "        next_state = self.user_all_streams.loc[self.stream_list[i + 1]] if not game_over else []\n",
    "        next_stream = None if (i + 1) == len(self.stream_list) else self.stream_list[i + 1]\n",
    "        \n",
    "        if sum(reward) > 0 or len(self.exp_replay.memory) < 10:\n",
    "          self.exp_replay.remember([self.full_input, self.action_ids, reward, next_state, next_stream], game_over)\n",
    "        # for updating target network\n",
    "        self.learn_step_counter += 1\n",
    "        if self.target_net and (self.learn_step_counter % self.switch_param_threshold == 0):\n",
    "          self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "\n",
    "\n",
    "        # --------------- Load batch of experiences --------------------\n",
    "        inputs, targets = self.exp_replay.get_batch(self.eval_net, self.target_net, self.structure, batch_size=self.batch_size)\n",
    "\n",
    "        # store pre-training value for td_error\n",
    "        old_Q = self.q_value()\n",
    "        batch_loss = self.__train_agent_batch(inputs, targets)\n",
    "        # store post-training value for td_error\n",
    "        new_Q = self.q_value()\n",
    "        self.loss += batch_loss\n",
    "\n",
    "        # --------------- Update with TD error -------------------------\n",
    "        self.epsilon.update_at_step(self.asid, [(new_Q - old_Q), self.learn_step_counter], 1/len(self.stream_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# parameters\n",
    "MAX_MEMORY = 1000  # Maximum number of experiences we are storing\n",
    "BATCH_SIZE = 100  # Number of experiences we use for training per batch\n",
    "TOTAL_ACTIONS = 1 # probability of ordering\n",
    "NUM_EPISODE = 100\n",
    "LR = 1.0e-3\n",
    "SWITCH_PARAM_THRESHOLD = 100\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(380, 512)\n",
    "    self.fc2 = nn.Linear(512, 256)\n",
    "    self.fc3 = nn.Linear(256, 128)\n",
    "    self.fc4 = nn.Linear(128, 64)\n",
    "    self.fc5 = nn.Linear(64, 1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc4(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc5(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp: single experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a18f9f48f0c4b9d8355e2c8c96e1e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] win_cnt: 60 | score: 87 | fake score: 217.5 | asid: 7 | loss: 10187.17 | explore: 101 | exploit: 0\n",
      "[2] win_cnt: 68 | score: 97 | fake score: 190.0 | asid: 18 | loss: 215.91 | explore: 100 | exploit: 0\n",
      "[3] win_cnt: 59 | score: 94 | fake score: 245.0 | asid: 19 | loss: 651.51 | explore: 99 | exploit: 1\n",
      "[4] win_cnt: 62 | score: 93 | fake score: 250.5 | asid: 34 | loss: 364.78 | explore: 94 | exploit: 6\n",
      "[5] win_cnt: 55 | score: 66 | fake score: 138.5 | asid: 36 | loss: 226.03 | explore: 90 | exploit: 10\n",
      "[6] win_cnt: 51 | score: 76 | fake score: 186.0 | asid: 45 | loss: 306.03 | explore: 81 | exploit: 19\n",
      "[7] win_cnt: 57 | score: 84 | fake score: 162.5 | asid: 47 | loss: 183.39 | explore: 79 | exploit: 21\n",
      "[8] win_cnt: 47 | score: 63 | fake score: 141.0 | asid: 53 | loss: 152.54 | explore: 75 | exploit: 25\n",
      "[9] win_cnt: 42 | score: 60 | fake score: 181.0 | asid: 64 | loss: 106.37 | explore: 79 | exploit: 21\n",
      "[10] win_cnt: 47 | score: 58 | fake score: 158.0 | asid: 74 | loss: 157.06 | explore: 71 | exploit: 29\n",
      "[11] win_cnt: 40 | score: 58 | fake score: 144.5 | asid: 86 | loss: 123.82 | explore: 58 | exploit: 42\n",
      "[12] win_cnt: 55 | score: 92 | fake score: 211.0 | asid: 94 | loss: 248.51 | explore: 73 | exploit: 27\n",
      "[13] win_cnt: 56 | score: 71 | fake score: 153.0 | asid: 98 | loss: 84.06 | explore: 65 | exploit: 35\n",
      "[14] win_cnt: 59 | score: 89 | fake score: 230.0 | asid: 104 | loss: 78.42 | explore: 70 | exploit: 30\n",
      "[15] win_cnt: 52 | score: 69 | fake score: 201.0 | asid: 108 | loss: 172.16 | explore: 73 | exploit: 27\n",
      "[16] win_cnt: 49 | score: 72 | fake score: 162.0 | asid: 121 | loss: 74.01 | explore: 62 | exploit: 38\n",
      "[18] win_cnt: 58 | score: 96 | fake score: 207.0 | asid: 140 | loss: 97.80 | explore: 62 | exploit: 38\n",
      "[19] win_cnt: 51 | score: 60 | fake score: 128.5 | asid: 145 | loss: 73.35 | explore: 67 | exploit: 33\n",
      "[20] win_cnt: 58 | score: 82 | fake score: 162.5 | asid: 153 | loss: 74.05 | explore: 59 | exploit: 41\n",
      "[21] win_cnt: 60 | score: 86 | fake score: 167.0 | asid: 161 | loss: 77.74 | explore: 64 | exploit: 36\n",
      "[22] win_cnt: 68 | score: 121 | fake score: 289.0 | asid: 170 | loss: 62.07 | explore: 53 | exploit: 47\n",
      "[23] win_cnt: 64 | score: 87 | fake score: 157.0 | asid: 179 | loss: 69.14 | explore: 48 | exploit: 52\n",
      "[24] win_cnt: 59 | score: 96 | fake score: 177.0 | asid: 187 | loss: 68.92 | explore: 64 | exploit: 36\n",
      "[25] win_cnt: 68 | score: 105 | fake score: 200.0 | asid: 191 | loss: 84.71 | explore: 58 | exploit: 42\n",
      "[26] win_cnt: 57 | score: 79 | fake score: 145.0 | asid: 199 | loss: 73.83 | explore: 53 | exploit: 47\n",
      "[27] win_cnt: 63 | score: 106 | fake score: 214.5 | asid: 209 | loss: 71.37 | explore: 48 | exploit: 52\n",
      "[28] win_cnt: 66 | score: 94 | fake score: 160.0 | asid: 214 | loss: 70.14 | explore: 56 | exploit: 44\n",
      "[29] win_cnt: 65 | score: 104 | fake score: 268.0 | asid: 228 | loss: 66.70 | explore: 60 | exploit: 40\n",
      "[30] win_cnt: 60 | score: 105 | fake score: 353.0 | asid: 235 | loss: 63.51 | explore: 60 | exploit: 40\n",
      "[31] win_cnt: 56 | score: 86 | fake score: 205.5 | asid: 244 | loss: 75.82 | explore: 55 | exploit: 45\n",
      "[32] win_cnt: 60 | score: 97 | fake score: 210.5 | asid: 251 | loss: 69.37 | explore: 61 | exploit: 39\n",
      "[33] win_cnt: 53 | score: 93 | fake score: 269.5 | asid: 259 | loss: 81.20 | explore: 57 | exploit: 43\n",
      "[34] win_cnt: 69 | score: 107 | fake score: 184.0 | asid: 260 | loss: 70.36 | explore: 41 | exploit: 59\n",
      "[35] win_cnt: 46 | score: 60 | fake score: 160.0 | asid: 268 | loss: 70.27 | explore: 58 | exploit: 42\n",
      "[36] win_cnt: 53 | score: 73 | fake score: 184.5 | asid: 276 | loss: 78.57 | explore: 45 | exploit: 55\n",
      "[37] win_cnt: 46 | score: 74 | fake score: 228.0 | asid: 279 | loss: 84.57 | explore: 52 | exploit: 48\n",
      "[38] win_cnt: 43 | score: 56 | fake score: 162.0 | asid: 289 | loss: 70.61 | explore: 56 | exploit: 44\n",
      "[39] win_cnt: 51 | score: 71 | fake score: 190.5 | asid: 297 | loss: 60.58 | explore: 44 | exploit: 56\n",
      "[40] win_cnt: 61 | score: 111 | fake score: 276.5 | asid: 304 | loss: 65.14 | explore: 53 | exploit: 47\n",
      "[41] win_cnt: 49 | score: 76 | fake score: 251.5 | asid: 306 | loss: 207.47 | explore: 44 | exploit: 56\n",
      "[42] win_cnt: 54 | score: 85 | fake score: 203.5 | asid: 315 | loss: 58.38 | explore: 38 | exploit: 62\n",
      "[43] win_cnt: 50 | score: 69 | fake score: 136.5 | asid: 318 | loss: 60.15 | explore: 53 | exploit: 47\n",
      "[44] win_cnt: 51 | score: 71 | fake score: 208.0 | asid: 328 | loss: 65.25 | explore: 48 | exploit: 52\n",
      "[45] win_cnt: 64 | score: 125 | fake score: 269.0 | asid: 336 | loss: 63.92 | explore: 54 | exploit: 46\n",
      "[46] win_cnt: 49 | score: 64 | fake score: 190.0 | asid: 343 | loss: 63.59 | explore: 46 | exploit: 54\n",
      "[47] win_cnt: 60 | score: 96 | fake score: 188.0 | asid: 345 | loss: 60.60 | explore: 43 | exploit: 57\n",
      "[48] win_cnt: 60 | score: 85 | fake score: 194.5 | asid: 350 | loss: 58.55 | explore: 49 | exploit: 51\n",
      "[49] win_cnt: 60 | score: 91 | fake score: 224.0 | asid: 354 | loss: 52.83 | explore: 52 | exploit: 48\n",
      "[50] win_cnt: 69 | score: 99 | fake score: 193.0 | asid: 359 | loss: 54.71 | explore: 52 | exploit: 48\n",
      "[51] win_cnt: 63 | score: 135 | fake score: 313.0 | asid: 361 | loss: 65.02 | explore: 47 | exploit: 53\n",
      "[52] win_cnt: 56 | score: 74 | fake score: 163.5 | asid: 372 | loss: 62.17 | explore: 47 | exploit: 53\n",
      "[53] win_cnt: 57 | score: 82 | fake score: 162.5 | asid: 385 | loss: 64.22 | explore: 39 | exploit: 61\n",
      "[54] win_cnt: 53 | score: 73 | fake score: 154.0 | asid: 392 | loss: 72.04 | explore: 46 | exploit: 54\n",
      "[55] win_cnt: 61 | score: 110 | fake score: 212.5 | asid: 402 | loss: 66.92 | explore: 56 | exploit: 44\n",
      "[56] win_cnt: 58 | score: 85 | fake score: 196.5 | asid: 410 | loss: 67.34 | explore: 42 | exploit: 58\n",
      "[57] win_cnt: 66 | score: 108 | fake score: 261.5 | asid: 414 | loss: 52.37 | explore: 48 | exploit: 52\n",
      "[58] win_cnt: 62 | score: 102 | fake score: 231.5 | asid: 416 | loss: 69.49 | explore: 46 | exploit: 54\n",
      "[59] win_cnt: 48 | score: 90 | fake score: 191.0 | asid: 427 | loss: 70.02 | explore: 42 | exploit: 58\n",
      "[60] win_cnt: 55 | score: 82 | fake score: 165.5 | asid: 437 | loss: 66.23 | explore: 48 | exploit: 52\n",
      "[61] win_cnt: 46 | score: 67 | fake score: 147.5 | asid: 447 | loss: 71.89 | explore: 45 | exploit: 55\n",
      "[62] win_cnt: 58 | score: 113 | fake score: 264.5 | asid: 454 | loss: 65.12 | explore: 38 | exploit: 62\n",
      "[63] win_cnt: 51 | score: 78 | fake score: 219.0 | asid: 466 | loss: 72.65 | explore: 41 | exploit: 59\n",
      "[64] win_cnt: 47 | score: 69 | fake score: 142.0 | asid: 471 | loss: 74.09 | explore: 39 | exploit: 61\n",
      "[65] win_cnt: 55 | score: 83 | fake score: 186.0 | asid: 476 | loss: 61.93 | explore: 46 | exploit: 54\n",
      "[66] win_cnt: 61 | score: 101 | fake score: 204.5 | asid: 483 | loss: 65.30 | explore: 39 | exploit: 61\n",
      "[67] win_cnt: 56 | score: 99 | fake score: 196.5 | asid: 489 | loss: 72.54 | explore: 43 | exploit: 57\n",
      "[68] win_cnt: 60 | score: 82 | fake score: 196.5 | asid: 497 | loss: 78.96 | explore: 50 | exploit: 50\n",
      "[69] win_cnt: 56 | score: 70 | fake score: 150.5 | asid: 503 | loss: 71.32 | explore: 44 | exploit: 56\n",
      "[70] win_cnt: 53 | score: 75 | fake score: 149.0 | asid: 510 | loss: 59.69 | explore: 53 | exploit: 47\n",
      "[71] win_cnt: 59 | score: 83 | fake score: 196.0 | asid: 524 | loss: 62.37 | explore: 41 | exploit: 59\n",
      "[72] win_cnt: 52 | score: 63 | fake score: 148.0 | asid: 534 | loss: 65.39 | explore: 44 | exploit: 56\n",
      "[73] win_cnt: 62 | score: 96 | fake score: 258.5 | asid: 542 | loss: 73.87 | explore: 40 | exploit: 60\n",
      "[74] win_cnt: 44 | score: 81 | fake score: 202.5 | asid: 550 | loss: 68.08 | explore: 41 | exploit: 59\n",
      "[75] win_cnt: 47 | score: 61 | fake score: 128.0 | asid: 556 | loss: 71.60 | explore: 46 | exploit: 54\n",
      "[76] win_cnt: 64 | score: 118 | fake score: 305.5 | asid: 565 | loss: 63.58 | explore: 45 | exploit: 55\n",
      "[77] win_cnt: 61 | score: 96 | fake score: 238.5 | asid: 573 | loss: 66.29 | explore: 51 | exploit: 49\n",
      "[78] win_cnt: 58 | score: 84 | fake score: 168.5 | asid: 579 | loss: 71.31 | explore: 38 | exploit: 62\n",
      "[79] win_cnt: 56 | score: 96 | fake score: 262.0 | asid: 584 | loss: 59.23 | explore: 48 | exploit: 52\n",
      "[80] win_cnt: 53 | score: 86 | fake score: 251.5 | asid: 590 | loss: 61.04 | explore: 49 | exploit: 51\n",
      "[81] win_cnt: 54 | score: 63 | fake score: 142.5 | asid: 596 | loss: 53.78 | explore: 36 | exploit: 64\n",
      "[82] win_cnt: 57 | score: 90 | fake score: 225.5 | asid: 603 | loss: 67.02 | explore: 44 | exploit: 56\n",
      "[83] win_cnt: 38 | score: 57 | fake score: 159.5 | asid: 612 | loss: 59.27 | explore: 36 | exploit: 64\n",
      "[84] win_cnt: 78 | score: 140 | fake score: 276.0 | asid: 618 | loss: 69.74 | explore: 41 | exploit: 59\n",
      "[85] win_cnt: 57 | score: 115 | fake score: 242.5 | asid: 624 | loss: 57.94 | explore: 45 | exploit: 55\n",
      "[86] win_cnt: 44 | score: 66 | fake score: 188.5 | asid: 636 | loss: 58.51 | explore: 42 | exploit: 58\n",
      "[87] win_cnt: 53 | score: 89 | fake score: 221.5 | asid: 645 | loss: 53.74 | explore: 37 | exploit: 63\n",
      "[88] win_cnt: 48 | score: 69 | fake score: 184.0 | asid: 658 | loss: 52.41 | explore: 42 | exploit: 58\n",
      "[89] win_cnt: 53 | score: 86 | fake score: 338.0 | asid: 664 | loss: 51.70 | explore: 50 | exploit: 50\n",
      "[90] win_cnt: 66 | score: 114 | fake score: 254.5 | asid: 667 | loss: 48.70 | explore: 35 | exploit: 65\n",
      "[91] win_cnt: 60 | score: 90 | fake score: 307.5 | asid: 673 | loss: 55.58 | explore: 41 | exploit: 59\n",
      "[92] win_cnt: 42 | score: 56 | fake score: 202.0 | asid: 681 | loss: 56.13 | explore: 38 | exploit: 62\n",
      "[93] win_cnt: 53 | score: 102 | fake score: 205.0 | asid: 693 | loss: 50.83 | explore: 46 | exploit: 54\n",
      "[94] win_cnt: 62 | score: 100 | fake score: 165.0 | asid: 694 | loss: 65.83 | explore: 47 | exploit: 53\n",
      "[95] win_cnt: 70 | score: 111 | fake score: 171.0 | asid: 697 | loss: 67.36 | explore: 36 | exploit: 64\n",
      "[96] win_cnt: 56 | score: 99 | fake score: 236.5 | asid: 705 | loss: 72.58 | explore: 34 | exploit: 66\n",
      "[97] win_cnt: 54 | score: 94 | fake score: 246.5 | asid: 714 | loss: 66.29 | explore: 47 | exploit: 53\n",
      "[98] win_cnt: 49 | score: 63 | fake score: 159.5 | asid: 725 | loss: 58.49 | explore: 42 | exploit: 58\n",
      "[99] win_cnt: 40 | score: 64 | fake score: 165.0 | asid: 733 | loss: 58.57 | explore: 38 | exploit: 62\n",
      "[100] win_cnt: 46 | score: 61 | fake score: 218.5 | asid: 743 | loss: 49.55 | explore: 39 | exploit: 61\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# EPS_baseline_rsum_x\n",
    "\n",
    "- EE\n",
    "  - VDBE(0.5, 0.1)\n",
    "  - Decay(0.99, step_decay=0.92)\n",
    "- Structure: vanilla / target / double\n",
    "'''\n",
    "\n",
    "exp_replay = ReplayBuffer(max_memory=MAX_MEMORY)\n",
    "epsilon = Decay(0.99, step_decay=0.92)\n",
    "dqn_test = DQN('vanilla', exp_replay, epsilon, NUM_EPISODE, BATCH_SIZE, \n",
    "               LR, SWITCH_PARAM_THRESHOLD, single_reward=False)\n",
    "dqn_test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_test_attrs = {\n",
    "  'win_list': dqn_test.win_list,\n",
    "  'score_list': dqn_test.score_list,\n",
    "  'fake_list': dqn_test.fake_list,\n",
    "  'loss_list': dqn_test.loss_list,\n",
    "  'EE': ['Decay', 0.99, 0.92]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Experiments Results/EEPS_baseline_rsum_x2.pkl', 'wb') as file_pi:\n",
    "  pickle.dump(dqn_test_attrs, file_pi, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "res = [a/((b - a)*2+a) for a, b in zip(dqn_test.score_list, dqn_test.fake_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dqn_test_attrs1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ea797fecfb0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#   plt.axvline(x = l, color = 'red')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EPS target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn_test_attrs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'User as VDBE index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'100 step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dqn_test_attrs1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(EPS_target_rsum_x_positive.ep_score_list, label='hit')\n",
    "# plt.plot(EPS_target_rsum_x_positive.avg_hit_list, label='res')\n",
    "# plt.plot(dqn_test.win_list, label='Score')\n",
    "# plt.plot(res, label='Score')\n",
    "# for l in re:\n",
    "#   print(l)\n",
    "#   plt.axvline(x = l, color = 'red')\n",
    "plt.plot(pd.Series(dqn_test.score_list).rolling(30).mean(), label='EPS target')\n",
    "plt.plot(pd.Series(dqn_test_attrs1['score_list']).rolling(30).mean(), label='User as VDBE index')\n",
    "plt.xlabel('100 step')\n",
    "plt.ylabel('score')\n",
    "plt.title('VDBE and Epsilon-decay on Target Network')\n",
    "# plt.ylim([0.4, 0.6])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_test_attrs1 = pd.read_pickle('../Experiments Results/VDBE_target_rsum_asid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open('../Experiments Results/target_vdbe_score_list.pkl', 'wb') as f:\n",
    "  pickle.dump(dqn_test.score_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "  \n",
    "# with open('../Models/expanded_noep_target_fakescore_8w_vdbe.pkl', 'wb') as file_pi:\n",
    "#   pickle.dump(dqn_test, file_pi, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DQN__agent_predict',\n",
       " '_DQN__choose_actions',\n",
       " '_DQN__train_agent_batch',\n",
       " '_DQN__user_episode_context',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_print_status',\n",
       " 'action_ids',\n",
       " 'asid',\n",
       " 'batch_size',\n",
       " 'candidate_actions',\n",
       " 'current_state',\n",
       " 'current_stream',\n",
       " 'epsilon',\n",
       " 'eval_net',\n",
       " 'exp_replay',\n",
       " 'exploit',\n",
       " 'explore',\n",
       " 'fake_list',\n",
       " 'fake_score',\n",
       " 'final_stream',\n",
       " 'full_input',\n",
       " 'learn_step_counter',\n",
       " 'loss',\n",
       " 'loss_fn',\n",
       " 'loss_list',\n",
       " 'num_episode',\n",
       " 'optimizer',\n",
       " 'q_value',\n",
       " 'reward',\n",
       " 'score',\n",
       " 'score_list',\n",
       " 'single_reward',\n",
       " 'stream_items',\n",
       " 'stream_list',\n",
       " 'structure',\n",
       " 'switch_param_threshold',\n",
       " 'target_net',\n",
       " 'train',\n",
       " 'user_all_streams',\n",
       " 'win_cnt',\n",
       " 'win_list']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dqn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":{\"identifier\": \"mzc_NCHM2O5IRDBJEESSSXKZJ3AKHYeeeeee\"},\"code\": 0}\n"
     ]
    }
   ],
   "source": [
    "print('{\"message\":{\"identifier\": \"mzc_NCHM2O5IRDBJEESSSXKZJ3AKHYeeeeee\"},\"code\": 0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": \"OK\", \"code\": 0}\n"
     ]
    }
   ],
   "source": [
    "print('{\"message\": \"OK\", \"code\": 0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1000057940522534',\n",
       " '1000149184139055',\n",
       " '1000250653732283',\n",
       " '1000409986993290',\n",
       " '1000423206992036',\n",
       " '1000553193805792',\n",
       " '1000589583850341',\n",
       " '1000633920390718',\n",
       " '1000957906997529',\n",
       " '1000963976758847',\n",
       " '1001080880276189',\n",
       " '1001324550069084',\n",
       " '100136929093933',\n",
       " '1001431227072878',\n",
       " '1001659963549176',\n",
       " '100167471891988',\n",
       " '1001757413527281',\n",
       " '1001893563877122',\n",
       " '1001894990260384',\n",
       " '100195065450589',\n",
       " '100203608791887',\n",
       " '1002038786835392',\n",
       " '100212032319094',\n",
       " '1002210203484869',\n",
       " '1002312599964580',\n",
       " '1002379003572798',\n",
       " '100241592368627',\n",
       " '1002522596786391',\n",
       " '100261762545667',\n",
       " '1002683636869020',\n",
       " '100282318494432',\n",
       " '1002830366844609',\n",
       " '100289405694390',\n",
       " '100300209255064',\n",
       " '100300478719313',\n",
       " '1003123449898961',\n",
       " '1003319080133058',\n",
       " '100333772275481',\n",
       " '100334462314361',\n",
       " '1003455763170860',\n",
       " '1003508910067984',\n",
       " '1003517779858218',\n",
       " '100353798789259',\n",
       " '1003692537041261',\n",
       " '100376219187419',\n",
       " '1003925263457178',\n",
       " '1003937330048114',\n",
       " '100394815713642',\n",
       " '100405662291810',\n",
       " '100408985683868',\n",
       " '100415871683576',\n",
       " '100417648845561',\n",
       " '100434472210980',\n",
       " '1004371873104504',\n",
       " '1004384703347194',\n",
       " '100442675510468',\n",
       " '1004501586563412',\n",
       " '1004506119890038',\n",
       " '1004576646975515',\n",
       " '1004582000338650',\n",
       " '1004590483233195',\n",
       " '1004811646752885',\n",
       " '100484055230918',\n",
       " '100488951649399',\n",
       " '1004935853213240',\n",
       " '100498748585690',\n",
       " '100507838841788',\n",
       " '1005282543157629',\n",
       " '1005316436473974',\n",
       " '1005331043257440',\n",
       " '1005378936570802',\n",
       " '100544505781471',\n",
       " '1005576513218314',\n",
       " '100564995455083',\n",
       " '100566869194136',\n",
       " '100568329264410',\n",
       " '1005706236554477',\n",
       " '100579125678617',\n",
       " '1005815463083130',\n",
       " '100586001795909',\n",
       " '1005911546905018',\n",
       " '100594925755639',\n",
       " '100618125574955',\n",
       " '1006230996512865',\n",
       " '1006256816865923',\n",
       " '100626538726682',\n",
       " '1006324949825303',\n",
       " '100639892449630',\n",
       " '100656815260301',\n",
       " '100660442062056',\n",
       " '1006819596402898',\n",
       " '100694125844647',\n",
       " '100712575927187',\n",
       " '100715925523700',\n",
       " '100730328427540',\n",
       " '100739922362784',\n",
       " '100743518660135',\n",
       " '1007457626381236',\n",
       " '100748999008564',\n",
       " '100760522403276',\n",
       " '1007801872937352',\n",
       " '100786099099725',\n",
       " '1007869389750719',\n",
       " '100793665575072',\n",
       " '100795991790523',\n",
       " '1008100399591964',\n",
       " '1008107766316448',\n",
       " '100815355238107',\n",
       " '1008154509580059',\n",
       " '1008197699547696',\n",
       " '1008220529630688',\n",
       " '1008409179559335',\n",
       " '100851832464368',\n",
       " '1008549156151035',\n",
       " '1008576482926325',\n",
       " '1008612609497116',\n",
       " '1008653156256689',\n",
       " '100872422087864',\n",
       " '100874171930526',\n",
       " '1008796359568510',\n",
       " '1008911812936734',\n",
       " '1008990492874306',\n",
       " '1009088289514044',\n",
       " '100915778085987',\n",
       " '100916878946891',\n",
       " '1009238746618004',\n",
       " '100937459102884',\n",
       " '1009417509658642',\n",
       " '100952299146069',\n",
       " '1009611342820617',\n",
       " '1009709546512532',\n",
       " '1009739359834655',\n",
       " '1009825849356013',\n",
       " '100983452550858',\n",
       " '1009855799220212',\n",
       " '100988738100818',\n",
       " '100988902203103',\n",
       " '100992348662751',\n",
       " '1010009225872210',\n",
       " '101002242375013',\n",
       " '101006135252281',\n",
       " '10102610182875201',\n",
       " '101028892082112',\n",
       " '101028985814442',\n",
       " '101032142172979',\n",
       " '101037582293334',\n",
       " '1010392722631249',\n",
       " '1010529825976452',\n",
       " '1010551959304987',\n",
       " '1010566205996072',\n",
       " '1010658502453128',\n",
       " '1010743679342167',\n",
       " '101074482489219',\n",
       " '1010814016432055',\n",
       " '101098488962825',\n",
       " '1011078082710863',\n",
       " '1011133252408459',\n",
       " '101136852225699',\n",
       " '101137031941899',\n",
       " '101141772344992',\n",
       " '1011542435875087',\n",
       " '1011592612531787',\n",
       " '101160222247830',\n",
       " '101160575631717',\n",
       " '1011610106301230',\n",
       " '101167522075464',\n",
       " '101168725579774',\n",
       " '1011769282532553',\n",
       " '10119527383433884',\n",
       " '1012097309243166',\n",
       " '1012246455823962',\n",
       " '101227132467850',\n",
       " '1012324625935418',\n",
       " '1012374109257335',\n",
       " '1012381555788472',\n",
       " '1012551735860059',\n",
       " '101268875509433',\n",
       " '1012744095849879',\n",
       " '1012870162499237',\n",
       " '101289065206490',\n",
       " '1013059582516648',\n",
       " '101307595721751',\n",
       " '1013079789075407',\n",
       " '1013120272470222',\n",
       " '1013171225521115',\n",
       " '1013412688853534',\n",
       " '1013413219127947',\n",
       " '1013467889076068',\n",
       " '101348695506348',\n",
       " '1013499169038088',\n",
       " '1013518552317403',\n",
       " '1013550975509206',\n",
       " '1013610309095905',\n",
       " '101363432301453',\n",
       " '101367718678070',\n",
       " '1013699366119806',\n",
       " '101370565677769',\n",
       " '1013781729013904',\n",
       " '1013828405615450',\n",
       " '1013955672298953',\n",
       " '1013966479437643',\n",
       " '101397362199698',\n",
       " '1013982552146156',\n",
       " '1014065432401412',\n",
       " '1014117522261504',\n",
       " '101424395549761',\n",
       " '101424992307282',\n",
       " '1014292045442363',\n",
       " '1014331302351061',\n",
       " '101435775496611',\n",
       " '1014381042338836',\n",
       " '1014396379014252',\n",
       " '1014416932265484',\n",
       " '101456408931574',\n",
       " '101464425193991',\n",
       " '1014743209299864',\n",
       " '101482008623188',\n",
       " '1014839685739860',\n",
       " '1014881255572447',\n",
       " '101506092355494',\n",
       " '101512045325742',\n",
       " '1015298012223079',\n",
       " '1015335555654930',\n",
       " '101537165346438',\n",
       " '1015451758837135',\n",
       " '10155008652267609',\n",
       " '10155621520705738',\n",
       " '10155716388258584',\n",
       " '10155820552814159',\n",
       " '1015586702186952',\n",
       " '10155874157410857',\n",
       " '10155882893933078',\n",
       " '10155904392666949',\n",
       " '10155935429525210',\n",
       " '10156055694432202',\n",
       " '10156090996671851',\n",
       " '10156121632346158',\n",
       " '10156168699747735',\n",
       " '10156180358042739',\n",
       " '1015618661980594',\n",
       " '10156187387041750',\n",
       " '10156249890516845',\n",
       " '10156257247876720',\n",
       " '10156264022381193',\n",
       " '10156305764593177',\n",
       " '10156317404707321',\n",
       " '10156362418032379',\n",
       " '10156367367908915',\n",
       " '10156367969874142',\n",
       " '10156370012805826',\n",
       " '10156373239704246',\n",
       " '10156392589676058',\n",
       " '10156422057805017',\n",
       " '10156427957291829',\n",
       " '10156435570760857',\n",
       " '10156454782795728',\n",
       " '10156490102316987',\n",
       " '10156499072907211',\n",
       " '10156512267787202',\n",
       " '10156514656676047',\n",
       " '10156567230832471',\n",
       " '10156608370772633',\n",
       " '10156627462291841',\n",
       " '10156628193028111',\n",
       " '10156647334473424',\n",
       " '10156655417956525',\n",
       " '10156658546577898',\n",
       " '10156658656606379',\n",
       " '10156664157041441',\n",
       " '10156667304037635',\n",
       " '10156675970066583',\n",
       " '10156686037558672',\n",
       " '10156698282732087',\n",
       " '10156712993121078',\n",
       " '10156719222271569',\n",
       " '10156720632514077',\n",
       " '10156749186671752',\n",
       " '10156760091836448',\n",
       " '10156763664934667',\n",
       " '10156790257457592',\n",
       " '10156792800539211',\n",
       " '10156814451368191',\n",
       " '10156831001161321',\n",
       " '10156849886451356',\n",
       " '10156852789217747',\n",
       " '10156859770922001',\n",
       " '10156898701249280',\n",
       " '10156907287988453',\n",
       " '10156908576683789',\n",
       " '10156913391009651',\n",
       " '10156914590800903',\n",
       " '10156931078248309',\n",
       " '10156938084007121',\n",
       " '10156940994678017',\n",
       " '10156941611502727',\n",
       " '10156952804480470',\n",
       " '10156971495140466',\n",
       " '10156987092386848',\n",
       " '10156993438432896',\n",
       " '10156999896767215',\n",
       " '10157000434841653',\n",
       " '10157001174716384',\n",
       " '10157002112554895',\n",
       " '10157009182395666',\n",
       " '10157013806548443',\n",
       " '10157018751374626',\n",
       " '10157032901581375',\n",
       " '10157034363283602',\n",
       " '10157034975214212',\n",
       " '10157038375945659',\n",
       " '10157046666558406',\n",
       " '10157046986193138',\n",
       " '10157047770858702',\n",
       " '10157054193757075',\n",
       " '10157062848143099',\n",
       " '10157064219251596',\n",
       " '10157072756449033',\n",
       " '10157076678895143',\n",
       " '10157077543087396',\n",
       " '10157078785654389',\n",
       " '10157079986312186',\n",
       " '10157082321110894',\n",
       " '10157088485196813',\n",
       " '10157100681346059',\n",
       " '10157104655051482',\n",
       " '10157112293466748',\n",
       " '10157115831027749',\n",
       " '10157116974564668',\n",
       " '10157118523846801',\n",
       " '10157125989907535',\n",
       " '10157127314664822',\n",
       " '10157137102657401',\n",
       " '10157139324306782',\n",
       " '10157145524335000',\n",
       " '10157156689954906',\n",
       " '10157157955004354',\n",
       " '10157165437731161',\n",
       " '10157167750455470',\n",
       " '10157169149901735',\n",
       " '10157169648147073',\n",
       " '10157169709134038',\n",
       " '10157179688292736',\n",
       " '10157184667723892',\n",
       " '10157184711703962',\n",
       " '10157185655229889',\n",
       " '10157186093771960',\n",
       " '10157191040407397',\n",
       " '10157198920786499',\n",
       " '10157211745786296',\n",
       " '10157224528246496',\n",
       " '10157227411530878',\n",
       " '10157234811231820',\n",
       " '10157245811307966',\n",
       " '10157253974187701',\n",
       " '10157254463662196',\n",
       " '10157256150909627',\n",
       " '10157261025976311',\n",
       " '10157264103697315',\n",
       " '10157264179477483',\n",
       " '10157265637227820',\n",
       " '10157275493818791',\n",
       " '10157275494746750',\n",
       " '10157287013628208',\n",
       " '10157297066978041',\n",
       " '10157301394219795',\n",
       " '10157305422548813',\n",
       " '10157311054386752',\n",
       " '10157314549946615',\n",
       " '1015731592589163',\n",
       " '10157329048463656',\n",
       " '10157329056136612',\n",
       " '10157331072071657',\n",
       " '10157334378682011',\n",
       " '10157338562499037',\n",
       " '10157339088748579',\n",
       " '10157344487272153',\n",
       " '10157350448228738',\n",
       " '10157357662373363',\n",
       " '10157358108546956',\n",
       " '10157358708626823',\n",
       " '10157374127463198',\n",
       " '10157374656372555',\n",
       " '10157375051254849',\n",
       " '10157390763181505',\n",
       " '10157401724859736',\n",
       " '10157405221222030',\n",
       " '10157405745294021',\n",
       " '10157405806829332',\n",
       " '10157413001792205',\n",
       " '10157413148209939',\n",
       " '10157414454584108',\n",
       " '10157415455624146',\n",
       " '10157416386982612',\n",
       " '10157422045186921',\n",
       " '10157428646936494',\n",
       " '10157430542599790',\n",
       " '10157434475662369',\n",
       " '10157436399111784',\n",
       " '10157441336939825',\n",
       " '10157441464171765',\n",
       " '10157452113119005',\n",
       " '10157470508552140',\n",
       " '10157477624879998',\n",
       " '10157477761327312',\n",
       " '10157484514454779',\n",
       " '10157488890469926',\n",
       " '10157488948466578',\n",
       " '10157491745766285',\n",
       " '10157494999318229',\n",
       " '10157495022666816',\n",
       " '10157496392258746',\n",
       " '10157498953929133',\n",
       " '10157499946202116',\n",
       " '10157503536516569',\n",
       " '10157504804962243',\n",
       " '10157508181806921',\n",
       " '10157510885628101',\n",
       " '10157512938234738',\n",
       " '10157518564414926',\n",
       " '10157537959764290',\n",
       " '10157540110006880',\n",
       " '10157544306991250',\n",
       " '10157545220357247',\n",
       " '10157545454663350',\n",
       " '10157558597081358',\n",
       " '10157566729920959',\n",
       " '10157569081000751',\n",
       " '10157569598814656',\n",
       " '10157577208005197',\n",
       " '10157578855739511',\n",
       " '10157584402002186',\n",
       " '10157587155865810',\n",
       " '10157587514937829',\n",
       " '10157590873834792',\n",
       " '10157592223892043',\n",
       " '10157593723369643',\n",
       " '10157603150151252',\n",
       " '10157603466026548',\n",
       " '10157615000522469',\n",
       " '10157621707709147',\n",
       " '10157621959304119',\n",
       " '10157621971659582',\n",
       " '10157624029571075',\n",
       " '10157624945886591',\n",
       " '10157630373886229',\n",
       " '10157636618284178',\n",
       " '10157645548754053',\n",
       " '10157650225761444',\n",
       " '10157654751654927',\n",
       " '10157655306693467',\n",
       " '10157655618653937',\n",
       " '10157655640368201',\n",
       " '10157656903197263',\n",
       " '10157657554137416',\n",
       " '10157665742764828',\n",
       " '10157671091079197',\n",
       " '10157671197654044',\n",
       " '10157672686863783',\n",
       " '10157678253301739',\n",
       " '10157680564136370',\n",
       " '10157680596575407',\n",
       " '10157682356577101',\n",
       " '10157687131666298',\n",
       " '10157687406988967',\n",
       " '10157691240478243',\n",
       " '10157696144135889',\n",
       " '10157703585153556',\n",
       " '10157708603894312',\n",
       " '10157709766041486',\n",
       " '10157711956709865',\n",
       " '10157719800322492',\n",
       " '10157724653453556',\n",
       " '10157725408348950',\n",
       " '10157742110168123',\n",
       " '10157742190781722',\n",
       " '10157743024274694',\n",
       " '10157744008363074',\n",
       " '10157745249553915',\n",
       " '10157746144027900',\n",
       " '10157747033967169',\n",
       " '10157754684689261',\n",
       " '10157755690527361',\n",
       " '10157759424762823',\n",
       " '10157760763332550',\n",
       " '10157764560824788',\n",
       " '10157765760846852',\n",
       " '10157766363720889',\n",
       " '10157770282992126',\n",
       " '10157772617094547',\n",
       " '10157774418418651',\n",
       " '10157788514894070',\n",
       " '10157797526588049',\n",
       " '10157808428303715',\n",
       " '10157810130726453',\n",
       " '10157819037224156',\n",
       " '10157826215005892',\n",
       " '10157827353251274',\n",
       " '10157827865255222',\n",
       " '10157829342720925',\n",
       " '10157833954294421',\n",
       " '10157834893334654',\n",
       " '10157836227438371',\n",
       " '10157842788622934',\n",
       " '1015784358597968',\n",
       " '10157849134032080',\n",
       " '10157859198224488',\n",
       " '10157860422581920',\n",
       " '10157862269386591',\n",
       " '10157863916452350',\n",
       " '10157867754738542',\n",
       " '10157869817850762',\n",
       " '10157872275121278',\n",
       " '10157875089371912',\n",
       " '10157875155365988',\n",
       " '10157879224123186',\n",
       " '10157889335694519',\n",
       " '10157902401237333',\n",
       " '10157903512619769',\n",
       " '10157904591062001',\n",
       " '10157907040867969',\n",
       " '10157907183117981',\n",
       " '10157914625934200',\n",
       " '10157915049405197',\n",
       " '10157924341272358',\n",
       " '10157924879157179',\n",
       " '10157927323714459',\n",
       " '10157928545300996',\n",
       " '10157930951925678',\n",
       " '10157936234643286',\n",
       " '10157938330591400',\n",
       " '10157942301586997',\n",
       " '10157952011432089',\n",
       " '10157962803330844',\n",
       " '10157967970184035',\n",
       " '10157971462972690',\n",
       " '10157973135255470',\n",
       " '10157974403826952',\n",
       " '10157974645250358',\n",
       " '10157989024383217',\n",
       " '10157994209333839',\n",
       " '10157996342664874',\n",
       " '10157997393477319',\n",
       " '10157998866890688',\n",
       " '10157999828942277',\n",
       " '10158004204226839',\n",
       " '10158006169325824',\n",
       " '10158006732579843',\n",
       " '10158008850931169',\n",
       " '10158012600551705',\n",
       " '10158014698254302',\n",
       " '10158020444659360',\n",
       " '10158022980246379',\n",
       " '10158037344973864',\n",
       " '10158038509851724',\n",
       " '10158042196024300',\n",
       " '10158045371355767',\n",
       " '10158060788468983',\n",
       " '10158066394313291',\n",
       " '10158066799004743',\n",
       " '10158071332433172',\n",
       " '10158075092392884',\n",
       " '10158079081242603',\n",
       " '10158084299497372',\n",
       " '10158086276813909',\n",
       " '10158087250923200',\n",
       " '10158087357973658',\n",
       " '10158090370526235',\n",
       " '10158096904740115',\n",
       " '10158103917749028',\n",
       " '10158104432639709',\n",
       " '10158107383849868',\n",
       " '10158108050093185',\n",
       " '10158109202913691',\n",
       " '10158110372153600',\n",
       " '10158119454328614',\n",
       " '10158122715183520',\n",
       " '10158128045662518',\n",
       " '10158130048413780',\n",
       " '10158135675714504',\n",
       " '10158136024773650',\n",
       " '10158151439122285',\n",
       " '10158151868454301',\n",
       " '10158154312637832',\n",
       " '10158156361229178',\n",
       " '10158161518132176',\n",
       " '10158169636816545',\n",
       " '10158179768841328',\n",
       " '10158183301014656',\n",
       " '10158189413532662',\n",
       " '10158202591294391',\n",
       " '10158214591324165',\n",
       " '10158223868462139',\n",
       " '10158224357244479',\n",
       " '10158226015137158',\n",
       " '10158231234778907',\n",
       " '10158233028227843',\n",
       " '10158235783573363',\n",
       " '10158239701284278',\n",
       " '10158247210144642',\n",
       " '10158257371068796',\n",
       " '10158264833909870',\n",
       " '10158267410144802',\n",
       " '10158277654134118',\n",
       " '10158278396982308',\n",
       " '10158279239688314',\n",
       " '10158279996772238',\n",
       " '10158280881902144',\n",
       " '10158282033459285',\n",
       " '10158293696566304',\n",
       " '10158302856333493',\n",
       " '10158305898347689',\n",
       " '10158306575364005',\n",
       " '10158308704202045',\n",
       " '10158311518193632',\n",
       " '10158322456598491',\n",
       " '10158323728916727',\n",
       " '10158325603539267',\n",
       " '10158328719582630',\n",
       " '10158328733122906',\n",
       " '10158332989873956',\n",
       " '10158334622374545',\n",
       " '10158342327119086',\n",
       " '10158344310589026',\n",
       " '10158350820803563',\n",
       " '10158352566851385',\n",
       " '10158352979996186',\n",
       " '10158355854907752',\n",
       " '101583605110111',\n",
       " '10158361118887968',\n",
       " '10158367012314277',\n",
       " '10158367391763988',\n",
       " '10158368499013809',\n",
       " '10158369765435749',\n",
       " '10158373820007496',\n",
       " '10158374053652192',\n",
       " '10158374247419011',\n",
       " '10158374472653750',\n",
       " '10158374967951422',\n",
       " '10158375927429354',\n",
       " '10158383540523713',\n",
       " '10158384748547863',\n",
       " '10158384771319722',\n",
       " '10158389929739265',\n",
       " '10158391249515825',\n",
       " '10158399401681807',\n",
       " '10158404943545758',\n",
       " '10158406542578693',\n",
       " '10158410034546445',\n",
       " '10158411783582858',\n",
       " '10158416981366938',\n",
       " '10158423332777902',\n",
       " '10158426445433436',\n",
       " '10158429387578109',\n",
       " '10158434302321427',\n",
       " '10158437427725890',\n",
       " '10158439625849484',\n",
       " '10158445603437403',\n",
       " '10158446007988411',\n",
       " '10158452116447792',\n",
       " '10158455986731505',\n",
       " '10158459593354908',\n",
       " '10158459992774902',\n",
       " '10158460194664544',\n",
       " '10158463439058566',\n",
       " '10158467453986649',\n",
       " '10158470309063405',\n",
       " '10158477302501229',\n",
       " '10158478277803184',\n",
       " '10158486434746954',\n",
       " '10158486586488832',\n",
       " '10158495348729841',\n",
       " '10158495904663462',\n",
       " '10158499468849683',\n",
       " '10158506002963281',\n",
       " '10158510884822270',\n",
       " '10158513373675809',\n",
       " '10158515137285446',\n",
       " '10158522759868992',\n",
       " '10158522922418893',\n",
       " '10158526060649076',\n",
       " '10158526519817859',\n",
       " '10158530911312346',\n",
       " '10158534868112830',\n",
       " '10158540648183379',\n",
       " '10158544932839685',\n",
       " '10158546973330168',\n",
       " '10158548602769744',\n",
       " '10158552743983430',\n",
       " '101585545480799',\n",
       " '10158559126573544',\n",
       " '10158562524669425',\n",
       " '10158565761779185',\n",
       " '10158565883129828',\n",
       " '10158568322333400',\n",
       " '10158569105093629',\n",
       " '10158572914561162',\n",
       " '10158573497883349',\n",
       " '10158574462257472',\n",
       " '10158591839092159',\n",
       " '10158592494734640',\n",
       " '10158598029547392',\n",
       " '10158600005649888',\n",
       " '10158603452056670',\n",
       " '10158608190383664',\n",
       " '10158611999102969',\n",
       " '10158613980960682',\n",
       " '10158617429287943',\n",
       " '10158618180198120',\n",
       " '10158622746939369',\n",
       " '10158626703191412',\n",
       " '10158636415646392',\n",
       " '10158636750279505',\n",
       " '10158641270816405',\n",
       " '10158641772512442',\n",
       " '10158646015422415',\n",
       " '10158647260965844',\n",
       " '10158651673804303',\n",
       " '10158662224854475',\n",
       " '10158679343363624',\n",
       " '10158680357993736',\n",
       " '10158688815476141',\n",
       " '10158692880517652',\n",
       " '10158694277071570',\n",
       " '10158695438961122',\n",
       " '10158701345538322',\n",
       " '10158702429659231',\n",
       " '10158709815509304',\n",
       " '10158718164899387',\n",
       " '10158719633128713',\n",
       " '10158730341764446',\n",
       " '10158737927399690',\n",
       " '10158738838284989',\n",
       " '10158741961344705',\n",
       " '10158765639559655',\n",
       " '10158767467780926',\n",
       " '10158767522332034',\n",
       " '10158770803619337',\n",
       " '10158774166289153',\n",
       " '10158778880637641',\n",
       " '10158792004042390',\n",
       " '10158793998614812',\n",
       " '10158795879625115',\n",
       " '10158799478529444',\n",
       " '10158801668304738']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
